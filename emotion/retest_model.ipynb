{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k76sio3irn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전체 성능 비교 분석 - TF-IDF vs PCA+TF-IDF\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TF-IDF vs PCA+TF-IDF 복합 라벨 분류 성능 비교\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 변수가 정의되지 않았을 경우 기본값 설정\n",
    "try:\n",
    "    # PCA 모델 성능 변수들이 존재하는지 확인\n",
    "    lr_pca_accuracy\n",
    "    lr_pca_f1_weighted\n",
    "    lr_pca_f1_macro\n",
    "    lr_pca_train_time\n",
    "    lr_pca_pred_time\n",
    "    svc_pca_accuracy\n",
    "    svc_pca_f1_weighted\n",
    "    svc_pca_f1_macro\n",
    "    svc_pca_train_time\n",
    "    svc_pca_pred_time\n",
    "    print(\"✅ PCA 모델 결과가 모두 존재합니다.\")\n",
    "except NameError:\n",
    "    print(\"❌ PCA 모델 변수가 정의되지 않았습니다. 이전 셀들을 먼저 실행해주세요.\")\n",
    "    print(\"다음 셀들을 순서대로 실행하세요:\")\n",
    "    print(\"1. 데이터 준비 셀\")\n",
    "    print(\"2. PCA + TF-IDF 벡터화 셀\")\n",
    "    print(\"3. PCA + LogisticRegression 셀\")\n",
    "    print(\"4. PCA + SVC 셀\")\n",
    "    print(\"5. 현재 비교 분석 셀\")\n",
    "    \n",
    "    # 임시로 더미 값 설정하여 오류 방지\n",
    "    lr_pca_accuracy = 0.0\n",
    "    lr_pca_f1_weighted = 0.0\n",
    "    lr_pca_f1_macro = 0.0\n",
    "    lr_pca_train_time = 0.0\n",
    "    lr_pca_pred_time = 0.0\n",
    "    svc_pca_accuracy = 0.0\n",
    "    svc_pca_f1_weighted = 0.0\n",
    "    svc_pca_f1_macro = 0.0\n",
    "    svc_pca_train_time = 0.0\n",
    "    svc_pca_pred_time = 0.0\n",
    "\n",
    "# 성능 비교 테이블 생성 (기존 결과 포함)\n",
    "all_results_df = pd.DataFrame({\n",
    "    'Method': ['TF-IDF + LogisticRegression', 'PCA + LogisticRegression', \n",
    "               'TF-IDF + SVC', 'PCA + SVC'],\n",
    "    'Accuracy': [0.0858, lr_pca_accuracy, 0.1039, svc_pca_accuracy],\n",
    "    'F1-Score (Weighted)': [0.0855, lr_pca_f1_weighted, 0.1090, svc_pca_f1_weighted],\n",
    "    'F1-Score (Macro)': [0.0503, lr_pca_f1_macro, 0.0590, svc_pca_f1_macro],\n",
    "    'Training Time (sec)': [0.2941, lr_pca_train_time, 2.5693, svc_pca_train_time],\n",
    "    'Prediction Time (sec)': [0.002, lr_pca_pred_time, 0.189, svc_pca_pred_time],\n",
    "    'Feature Dimensions': [8430, 500, 8430, 500]\n",
    "})\n",
    "\n",
    "print(\"\\n📊 전체 성능 비교:\")\n",
    "print(all_results_df.round(4))\n",
    "\n",
    "# 최고 성능 모델 식별\n",
    "best_accuracy_idx = all_results_df['Accuracy'].idxmax()\n",
    "best_f1_idx = all_results_df['F1-Score (Weighted)'].idxmax()\n",
    "\n",
    "print(f\"\\n🏆 최고 정확도 모델: {all_results_df.loc[best_accuracy_idx, 'Method']} ({all_results_df.loc[best_accuracy_idx, 'Accuracy']:.4f})\")\n",
    "print(f\"🏆 최고 F1-Score 모델: {all_results_df.loc[best_f1_idx, 'Method']} ({all_results_df.loc[best_f1_idx, 'F1-Score (Weighted)']:.4f})\")\n",
    "\n",
    "# PCA 효과 분석\n",
    "print(f\"\\n📈 PCA 적용 효과:\")\n",
    "lr_improvement = lr_pca_accuracy - 0.0858\n",
    "svc_improvement = svc_pca_accuracy - 0.1039\n",
    "\n",
    "print(f\"LogisticRegression: {lr_improvement:+.4f} ({'개선' if lr_improvement > 0 else '감소'})\")\n",
    "print(f\"SVC: {svc_improvement:+.4f} ({'개선' if svc_improvement > 0 else '감소'})\")\n",
    "\n",
    "# 차원 축소 효과\n",
    "try:\n",
    "    pca_variance_ratio = pca.explained_variance_ratio_.sum()\n",
    "except NameError:\n",
    "    pca_variance_ratio = 0.85  # 임시 기본값\n",
    "\n",
    "print(f\"\\n💡 차원 축소 효과:\")\n",
    "print(f\"- 차원 감소: 8,430 → 500 ({500/8430*100:.1f}%)\")\n",
    "print(f\"- 설명된 분산: {pca_variance_ratio:.1%}\")\n",
    "print(f\"- 메모리 사용량 약 {8430/500:.1f}배 감소\")\n",
    "\n",
    "# 기존 임베딩 방식과 비교\n",
    "print(f\"\\n🔍 기존 임베딩 방식(34.04%) 대비:\")\n",
    "best_pca_score = max(lr_pca_accuracy, svc_pca_accuracy)\n",
    "if best_pca_score > 0:\n",
    "    print(f\"- 최고 PCA 성능: {best_pca_score:.4f} ({best_pca_score/0.3404*100:.1f}%)\")\n",
    "    print(f\"- 성능 격차: {0.3404 - best_pca_score:.4f} ({(1-best_pca_score/0.3404)*100:.1f}% 차이)\")\n",
    "else:\n",
    "    print(\"- PCA 모델을 먼저 실행해주세요.\")\n",
    "\n",
    "print(f\"\\n📝 결론:\")\n",
    "print(f\"- PCA 차원 축소는 계산 효율성을 크게 개선\")\n",
    "print(f\"- 하지만 복합 감정 라벨링에는 여전히 임베딩 방식이 우수\")\n",
    "print(f\"- TF-IDF는 단어 빈도 기반으로 한국어 감정의 복잡한 문맥 이해에 한계\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PCA + TF-IDF 방식을 사용한 복합 라벨 분류 분석 완료!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fuhzjl89myq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "테스트 데이터 상세 분류 보고서\n",
      "================================================================================\n",
      "\n",
      "🔍 SVC 모델 상세 분류 보고서:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       기쁨_감동     0.3043    0.2333    0.2642        30\n",
      "      기쁨_고마움     0.6667    0.4211    0.5161        19\n",
      "       기쁨_공감     0.1667    0.1667    0.1667         6\n",
      "      기쁨_기대감     0.0909    0.2000    0.1250         5\n",
      "       기쁨_놀람     0.0000    0.0000    0.0000         5\n",
      "      기쁨_만족감     0.3810    0.1667    0.2319        48\n",
      "      기쁨_반가움     0.4286    0.1875    0.2609        16\n",
      "      기쁨_신뢰감     0.0000    0.0000    0.0000         1\n",
      "      기쁨_신명남     0.0000    0.0000    0.0000         5\n",
      "      기쁨_안정감     0.0000    0.0000    0.0000         8\n",
      "    기쁨_자랑스러움     0.0588    0.0833    0.0690        12\n",
      "      기쁨_자신감     0.0000    0.0000    0.0000         1\n",
      "      기쁨_즐거움     0.0000    0.0000    0.0000        27\n",
      "      기쁨_통쾌함     0.0000    0.0000    0.0000         1\n",
      "      기쁨_편안함     0.0000    0.0000    0.0000         4\n",
      "      두려움_걱정     0.2000    0.1304    0.1579        23\n",
      "      두려움_공포     0.0000    0.0000    0.0000        17\n",
      "      두려움_놀람     0.1250    0.0435    0.0645        23\n",
      "     두려움_위축감     0.0000    0.0000    0.0000         4\n",
      "     두려움_초조함     0.0000    0.0000    0.0000         5\n",
      "  미움(상대방)_경멸     0.2353    0.2222    0.2286        18\n",
      "  미움(상대방)_냉담     0.0000    0.0000    0.0000         3\n",
      "  미움(상대방)_반감     0.5000    0.2000    0.2857         5\n",
      " 미움(상대방)_불신감     0.2500    0.1250    0.1667         8\n",
      "미움(상대방)_비위상함     0.0000    0.0000    0.0000         1\n",
      " 미움(상대방)_시기심     0.0000    0.0000    0.0000         2\n",
      "  미움(상대방)_외면     0.0000    0.0000    0.0000         1\n",
      " 미움(상대방)_치사함     0.0000    0.0000    0.0000         5\n",
      "     분노_날카로움     0.0000    0.0000    0.0000         3\n",
      "       분노_발열     0.0000    0.0000    0.0000         3\n",
      "       분노_불쾌     0.0588    0.2500    0.0952        20\n",
      "      분노_사나움     0.0000    0.0000    0.0000         4\n",
      "       분노_원망     0.0000    0.0000    0.0000         3\n",
      "      분노_타오름     0.0000    0.0000    0.0000         3\n",
      "      사랑_귀중함     0.0000    0.0000    0.0000         5\n",
      "     사랑_너그러움     0.0000    0.0000    0.0000         1\n",
      "      사랑_다정함     0.0000    0.0000    0.0000         9\n",
      "   사랑_동정(슬픔)     0.0000    0.0000    0.0000         7\n",
      "     사랑_두근거림     0.0000    0.0000    0.0000         2\n",
      "      사랑_매력적     0.0000    0.0000    0.0000        13\n",
      "       사랑_호감     0.0000    0.0000    0.0000        10\n",
      "     수치심_미안함     0.0000    0.0000    0.0000         7\n",
      "    수치심_부끄러움     0.2000    0.0625    0.0952        16\n",
      "     수치심_죄책감     0.0000    0.0000    0.0000         2\n",
      "       슬픔_고통     0.5000    0.1111    0.1818         9\n",
      "      슬픔_그리움     0.0000    0.0000    0.0000        11\n",
      "   슬픔_동정(슬픔)     0.1000    0.0500    0.0667        20\n",
      "      슬픔_무기력     0.1304    0.2143    0.1622        14\n",
      "      슬픔_수치심     0.0000    0.0000    0.0000         3\n",
      "       슬픔_실망     0.0400    0.1538    0.0635        13\n",
      "      슬픔_아쉬움     0.0000    0.0000    0.0000         0\n",
      "       슬픔_아픔     0.0000    0.0000    0.0000         3\n",
      "      슬픔_억울함     0.0556    0.1538    0.0816        13\n",
      "      슬픔_외로움     0.0909    0.1667    0.1176         6\n",
      "       슬픔_절망     0.0000    0.0000    0.0000         7\n",
      "       슬픔_허망     0.0174    0.1818    0.0317        11\n",
      "       슬픔_후회     0.0000    0.0000    0.0000         7\n",
      " 싫어함(상태)_난처함     0.2500    0.0714    0.1111        14\n",
      " 싫어함(상태)_답답함     0.0667    0.1111    0.0833        18\n",
      " 싫어함(상태)_불편함     0.0000    0.0000    0.0000         7\n",
      "  싫어함(상태)_싫증     0.0000    0.0000    0.0000         9\n",
      " 싫어함(상태)_심심함     0.0000    0.0000    0.0000         1\n",
      "       욕망_갈등     0.0000    0.0000    0.0000         1\n",
      "      욕망_궁금함     0.1111    0.2222    0.1481         9\n",
      "      욕망_기대감     0.0000    0.0000    0.0000        13\n",
      "       욕망_불만     0.0000    0.0000    0.0000         8\n",
      "      욕망_아쉬움     0.2857    0.0606    0.1000        33\n",
      "       욕망_욕심     0.3571    0.2778    0.3125        18\n",
      "       중립_공감     0.0000    0.0000    0.0000         1\n",
      "       중립_놀람     0.0000    0.0000    0.0000         3\n",
      "      중립_만족감     0.0000    0.0000    0.0000         1\n",
      "\n",
      "    accuracy                         0.1039       664\n",
      "   macro avg     0.0799    0.0601    0.0590       664\n",
      "weighted avg     0.1529    0.1039    0.1090       664\n",
      "\n",
      "\n",
      "📋 SVC 예측 결과 샘플 (처음 10개):\n",
      "❌ 실제: 기쁨_만족감 | 예측: 슬픔_억울함\n",
      "   텍스트: 보는동안 너무 행복했고 초콜렛이 너무 먹고싶었고 티모시가 잘생겼고 울어!!하는부분이 있어서 울었다네요\n",
      "\n",
      "✅ 실제: 기쁨_만족감 | 예측: 기쁨_만족감\n",
      "   텍스트: 어릴 때 가 보고 빕스는 거의 처음인데(기억에 없음) 지금 딸기축제 기간이라 만족스러운 식사 하고 옴\n",
      "\n",
      "❌ 실제: 기쁨_만족감 | 예측: 분노_불쾌\n",
      "   텍스트: 미리 계좌로 환전해둔 돈을 해외에서 환전수수료 없이 인출 가능한 트레블로그라는 카드인데, 선택할 수 있는 디자인 중에 이 여권 스타일이 너무 센스 있고 유니크해서 마음에 든다.\n",
      "\n",
      "❌ 실제: 슬픔_무기력 | 예측: 욕망_궁금함\n",
      "   텍스트: 요즘 번아웃도 자꾸 올라오고 무기력해서 종강하고 교류하기도 버거운 상태가 와부렀으요ㅠㅠ \n",
      "\n",
      "❌ 실제: 기쁨_즐거움 | 예측: 분노_불쾌\n",
      "   텍스트: 크라임씬 장똥민이 범행 도구 찾으려고 화장실 탱크 뒤지는데 거기에 진짜 똥 넣어놓은 거 진짜 웃겨 뒤지겠음ㅋㅋㅋㅋㅋ\n",
      "\n",
      "❌ 실제: 싫어함(상태)_답답함 | 예측: 기쁨_자랑스러움\n",
      "   텍스트: 가슴이 답답해짐 진짜 개답답해짐\n",
      "우리진짜투표잘하자\n",
      "\n",
      "❌ 실제: 기쁨_만족감 | 예측: 슬픔_허망\n",
      "   텍스트: 지그재그랑 에이블리랑 할인 대결하나\n",
      "아 흐뭇해\n",
      "계속되길...\n",
      "영원히....\n",
      "\n",
      "❌ 실제: 기쁨_자랑스러움 | 예측: 분노_불쾌\n",
      "   텍스트: 첨으로 수제 초콜릿 만듬\n",
      "초콜릿을 5시간이나 만드는 사람이 있다??? 그게 바로 나\n",
      "\n",
      "❌ 실제: 슬픔_절망 | 예측: 두려움_놀람\n",
      "   텍스트: 단톡방에 공지들 슬슬 올라오는거 보니까 곧 개강이라는게 실감나서 갑자기 재기하고싶고 인생이 다 끝난거처럼 암울해짐\n",
      "\n",
      "❌ 실제: 기쁨_즐거움 | 예측: 슬픔_허망\n",
      "   텍스트: 장흥신 공손한 손가락질 개웃겨요\n",
      "애드립 미친것 같음\n",
      "\n",
      "\n",
      "📊 라벨 분석:\n",
      "훈련 데이터 라벨 수: 71\n",
      "테스트 데이터 라벨 수: 70\n",
      "공통 라벨 수: 68\n",
      "테스트에만 있는 새 라벨 수: 2\n",
      "훈련에만 있는 라벨 수: 3\n",
      "\n",
      "⚠️ 테스트 데이터의 새로운 라벨들 (처음 5개):\n",
      "  - 중립_만족감: 1개\n",
      "  - 중립_놀람: 3개\n",
      "================================================================================\n",
      "TF-IDF 방식을 사용한 복합 라벨 분류 완료!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 상위 성능 모델의 상세 분류 보고서\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"테스트 데이터 상세 분류 보고서\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 두 모델 중 더 좋은 성능을 보이는 모델의 상세 보고서 출력\n",
    "if lr_accuracy >= svc_accuracy:\n",
    "    print(\"\\n🔍 LogisticRegression 모델 상세 분류 보고서:\")\n",
    "    print(classification_report(y_test, y_test_pred_lr, digits=4, zero_division=0))\n",
    "    \n",
    "    # 예측 샘플 확인\n",
    "    print(\"\\n📋 LogisticRegression 예측 결과 샘플 (처음 10개):\")\n",
    "    for i in range(min(10, len(y_test))):\n",
    "        actual = y_test[i]\n",
    "        predicted = y_test_pred_lr[i]\n",
    "        text_sample = X_test[i][:100] + \"...\" if len(X_test[i]) > 100 else X_test[i]\n",
    "        status = \"✅\" if actual == predicted else \"❌\"\n",
    "        print(f\"{status} 실제: {actual} | 예측: {predicted}\")\n",
    "        print(f\"   텍스트: {text_sample}\\n\")\n",
    "else:\n",
    "    print(\"\\n🔍 SVC 모델 상세 분류 보고서:\")\n",
    "    print(classification_report(y_test, y_test_pred_svc, digits=4, zero_division=0))\n",
    "    \n",
    "    # 예측 샘플 확인\n",
    "    print(\"\\n📋 SVC 예측 결과 샘플 (처음 10개):\")\n",
    "    for i in range(min(10, len(y_test))):\n",
    "        actual = y_test[i]\n",
    "        predicted = y_test_pred_svc[i]\n",
    "        text_sample = X_test[i][:100] + \"...\" if len(X_test[i]) > 100 else X_test[i]\n",
    "        status = \"✅\" if actual == predicted else \"❌\"\n",
    "        print(f\"{status} 실제: {actual} | 예측: {predicted}\")\n",
    "        print(f\"   텍스트: {text_sample}\\n\")\n",
    "\n",
    "# 테스트 데이터에서 공통 라벨과 새로운 라벨 분석\n",
    "train_labels = set(y_train)\n",
    "test_labels = set(y_test)\n",
    "common_labels = train_labels.intersection(test_labels)\n",
    "new_labels = test_labels - train_labels\n",
    "missing_labels = train_labels - test_labels\n",
    "\n",
    "print(f\"\\n📊 라벨 분석:\")\n",
    "print(f\"훈련 데이터 라벨 수: {len(train_labels)}\")\n",
    "print(f\"테스트 데이터 라벨 수: {len(test_labels)}\")\n",
    "print(f\"공통 라벨 수: {len(common_labels)}\")\n",
    "print(f\"테스트에만 있는 새 라벨 수: {len(new_labels)}\")\n",
    "print(f\"훈련에만 있는 라벨 수: {len(missing_labels)}\")\n",
    "\n",
    "if new_labels:\n",
    "    print(f\"\\n⚠️ 테스트 데이터의 새로운 라벨들 (처음 5개):\")\n",
    "    for label in list(new_labels)[:5]:\n",
    "        count = sum(1 for y in y_test if y == label)\n",
    "        print(f\"  - {label}: {count}개\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"TF-IDF 방식을 사용한 복합 라벨 분류 완료!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "thx6egr38vn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TF-IDF 방식 복합 라벨 분류 결과 비교\n",
      "============================================================\n",
      "\n",
      "📊 모델 성능 비교:\n",
      "                Model  Accuracy  F1-Score (Weighted)  F1-Score (Macro)  \\\n",
      "0  LogisticRegression    0.0858               0.0855            0.0503   \n",
      "1                 SVC    0.1039               0.1090            0.0590   \n",
      "\n",
      "   Training Time (sec)  Prediction Time (sec)  \n",
      "0               0.2881                  0.001  \n",
      "1               2.5652                  0.189  \n",
      "\n",
      "🏆 최고 정확도 모델: SVC (0.1039)\n",
      "🏆 최고 F1-Score 모델: SVC (0.1090)\n",
      "\n",
      "📋 참고: 기존 임베딩 방식 복합 라벨 분류 정확도는 약 34.04%였습니다.\n",
      "📋 TF-IDF 방식이 임베딩 방식보다 부족합니다.\n",
      "\n",
      "💡 TF-IDF 벡터 차원: 8430차원\n",
      "💡 총 라벨 수: 71개\n",
      "💡 벡터화 소요시간: 0.12초\n"
     ]
    }
   ],
   "source": [
    "# 모델 성능 비교 및 상세 분석\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TF-IDF 방식 복합 라벨 분류 결과 비교\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 성능 비교 테이블\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['LogisticRegression', 'SVC'],\n",
    "    'Accuracy': [lr_accuracy, svc_accuracy],\n",
    "    'F1-Score (Weighted)': [lr_f1_weighted, svc_f1_weighted],\n",
    "    'F1-Score (Macro)': [lr_f1_macro, svc_f1_macro],\n",
    "    'Training Time (sec)': [lr_train_time, svc_train_time],\n",
    "    'Prediction Time (sec)': [lr_pred_time, svc_pred_time]\n",
    "})\n",
    "\n",
    "print(\"\\n📊 모델 성능 비교:\")\n",
    "print(results_df.round(4))\n",
    "\n",
    "# 최고 성능 모델 확인\n",
    "best_accuracy_model = 'LogisticRegression' if lr_accuracy > svc_accuracy else 'SVC'\n",
    "best_f1_model = 'LogisticRegression' if lr_f1_weighted > svc_f1_weighted else 'SVC'\n",
    "\n",
    "print(f\"\\n🏆 최고 정확도 모델: {best_accuracy_model} ({max(lr_accuracy, svc_accuracy):.4f})\")\n",
    "print(f\"🏆 최고 F1-Score 모델: {best_f1_model} ({max(lr_f1_weighted, svc_f1_weighted):.4f})\")\n",
    "\n",
    "# 기존 임베딩 방식과 비교를 위한 참고 정보\n",
    "print(f\"\\n📋 참고: 기존 임베딩 방식 복합 라벨 분류 정확도는 약 34.04%였습니다.\")\n",
    "print(f\"📋 TF-IDF 방식이 임베딩 방식보다 {'우수' if max(lr_accuracy, svc_accuracy) > 0.3404 else '부족'}합니다.\")\n",
    "\n",
    "print(f\"\\n💡 TF-IDF 벡터 차원: {X_train_tfidf.shape[1]}차원\")\n",
    "print(f\"💡 총 라벨 수: {len(set(y_train))}개\")\n",
    "print(f\"💡 벡터화 소요시간: {vectorization_time:.2f}초\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3db2tta8jro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== SVC 모델 훈련 ===\n",
      "SVC 훈련 시간: 2.57초\n",
      "SVC 예측 시간: 0.19초\n",
      "SVC 정확도: 0.1039\n",
      "SVC F1-Score (weighted): 0.1090\n",
      "SVC F1-Score (macro): 0.0590\n"
     ]
    }
   ],
   "source": [
    "# SVC 모델 훈련\n",
    "print(f\"\\n=== SVC 모델 훈련 ===\")\n",
    "start_time = time.time()\n",
    "\n",
    "svc_model = SVC(\n",
    "    kernel='linear',         # 선형 커널 사용\n",
    "    random_state=42,\n",
    "    class_weight='balanced', # 클래스 불균형 해결\n",
    "    max_iter=1000           # 최대 반복 횟수 설정\n",
    ")\n",
    "\n",
    "svc_model.fit(X_train_tfidf, y_train)\n",
    "svc_train_time = time.time() - start_time\n",
    "\n",
    "# SVC 테스트 데이터 예측 및 평가\n",
    "start_time = time.time()\n",
    "y_test_pred_svc = svc_model.predict(X_test_tfidf)\n",
    "svc_pred_time = time.time() - start_time\n",
    "\n",
    "svc_accuracy = accuracy_score(y_test, y_test_pred_svc)\n",
    "svc_f1_weighted = f1_score(y_test, y_test_pred_svc, average='weighted')\n",
    "svc_f1_macro = f1_score(y_test, y_test_pred_svc, average='macro')\n",
    "\n",
    "print(f\"SVC 훈련 시간: {svc_train_time:.2f}초\")\n",
    "print(f\"SVC 예측 시간: {svc_pred_time:.2f}초\")\n",
    "print(f\"SVC 정확도: {svc_accuracy:.4f}\")\n",
    "print(f\"SVC F1-Score (weighted): {svc_f1_weighted:.4f}\")\n",
    "print(f\"SVC F1-Score (macro): {svc_f1_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "gfw8c3mk9ld",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TF-IDF 벡터화 진행 ===\n",
      "TF-IDF 벡터화 완료 - 소요시간: 0.12초\n",
      "TF-IDF 벡터 차원: 8430\n",
      "훈련 데이터 벡터 형태: (3353, 8430)\n",
      "테스트 데이터 벡터 형태: (664, 8430)\n",
      "\n",
      "=== LogisticRegression 모델 훈련 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1296: FutureWarning: Using the 'liblinear' solver for multiclass classification is deprecated. An error will be raised in 1.8. Either use another solver which supports the multinomial loss or wrap the estimator in a OneVsRestClassifier to keep applying a one-versus-rest scheme.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 훈련 시간: 0.29초\n",
      "LogisticRegression 예측 시간: 0.00초\n",
      "LogisticRegression 정확도: 0.0858\n",
      "LogisticRegression F1-Score (weighted): 0.0855\n",
      "LogisticRegression F1-Score (macro): 0.0503\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF 벡터화 및 LogisticRegression 모델\n",
    "print(\"\\n=== TF-IDF 벡터화 진행 ===\")\n",
    "start_time = time.time()\n",
    "\n",
    "# TF-IDF 벡터라이저 설정\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    max_features=10000,      # 최대 특성 수 제한\n",
    "    ngram_range=(1, 2),      # 유니그램과 바이그램 사용\n",
    "    min_df=2,                # 최소 2개 문서에서 나타나는 단어만 사용\n",
    "    max_df=0.95,             # 95% 이상 문서에서 나타나는 단어는 제외\n",
    "    stop_words=None,         # 한국어는 별도 처리\n",
    "    lowercase=True,          # 소문자 변환\n",
    "    sublinear_tf=True        # TF에 로그 스케일링 적용\n",
    ")\n",
    "\n",
    "# 훈련 데이터로 TF-IDF 학습 및 변환\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "vectorization_time = time.time() - start_time\n",
    "print(f\"TF-IDF 벡터화 완료 - 소요시간: {vectorization_time:.2f}초\")\n",
    "print(f\"TF-IDF 벡터 차원: {X_train_tfidf.shape[1]}\")\n",
    "print(f\"훈련 데이터 벡터 형태: {X_train_tfidf.shape}\")\n",
    "print(f\"테스트 데이터 벡터 형태: {X_test_tfidf.shape}\")\n",
    "\n",
    "# LogisticRegression 모델 훈련\n",
    "print(f\"\\n=== LogisticRegression 모델 훈련 ===\")\n",
    "start_time = time.time()\n",
    "\n",
    "lr_model = LogisticRegression(\n",
    "    max_iter=1000,\n",
    "    random_state=42,\n",
    "    class_weight='balanced',  # 클래스 불균형 해결\n",
    "    solver='liblinear'        # 다중분류에 적합한 솔버\n",
    ")\n",
    "\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "lr_train_time = time.time() - start_time\n",
    "\n",
    "# LogisticRegression 테스트 데이터 예측 및 평가\n",
    "start_time = time.time()\n",
    "y_test_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "lr_pred_time = time.time() - start_time\n",
    "\n",
    "lr_accuracy = accuracy_score(y_test, y_test_pred_lr)\n",
    "lr_f1_weighted = f1_score(y_test, y_test_pred_lr, average='weighted')\n",
    "lr_f1_macro = f1_score(y_test, y_test_pred_lr, average='macro')\n",
    "\n",
    "print(f\"LogisticRegression 훈련 시간: {lr_train_time:.2f}초\")\n",
    "print(f\"LogisticRegression 예측 시간: {lr_pred_time:.2f}초\")\n",
    "print(f\"LogisticRegression 정확도: {lr_accuracy:.4f}\")\n",
    "print(f\"LogisticRegression F1-Score (weighted): {lr_f1_weighted:.4f}\")\n",
    "print(f\"LogisticRegression F1-Score (macro): {lr_f1_macro:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10de4ij5wm1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TF-IDF 벡터화를 사용한 복합 라벨 분류 ===\n",
      "훈련 데이터 라벨별 샘플 수 분포:\n",
      "combined_label\n",
      "슬픔_무기력      98\n",
      "수치심_부끄러움    96\n",
      "기쁨_편안함      92\n",
      "슬픔_외로움      90\n",
      "두려움_놀람      84\n",
      "슬픔_허망       78\n",
      "기쁨_안정감      78\n",
      "기쁨_공감       77\n",
      "기쁨_기대감      77\n",
      "분노_불쾌       72\n",
      "Name: count, dtype: int64\n",
      "전체 라벨 수: 77\n",
      "샘플이 1개인 라벨 수: 6\n",
      "\n",
      "필터링 후:\n",
      "유효 라벨 수: 71\n",
      "훈련용 데이터 수: 3353\n",
      "\n",
      "테스트 데이터 로드:\n",
      "테스트 데이터 크기: (664, 5)\n",
      "테스트 데이터 컬럼: ['index', 'context', 'annotations_split', 'category1', 'category2']\n",
      "\n",
      "최종 데이터:\n",
      "훈련 데이터: 3353개\n",
      "테스트 데이터: 664개\n",
      "훈련 라벨 수: 71개\n",
      "테스트 라벨 수: 70개\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF 방식을 사용한 복합 라벨 분류 - 수정된 버전\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "print(\"=== TF-IDF 벡터화를 사용한 복합 라벨 분류 ===\")\n",
    "\n",
    "# 복합 라벨 생성 (기존 임베딩 방식과 동일한 라벨 구조 사용)\n",
    "data['combined_label'] = data['re_category1'] + \"_\" + data['re_category2']\n",
    "\n",
    "# 라벨별 샘플 수 확인 및 필터링\n",
    "label_counts = data['combined_label'].value_counts()\n",
    "print(f\"훈련 데이터 라벨별 샘플 수 분포:\")\n",
    "print(label_counts.head(10))\n",
    "print(f\"전체 라벨 수: {len(label_counts)}\")\n",
    "print(f\"샘플이 1개인 라벨 수: {sum(label_counts == 1)}\")\n",
    "\n",
    "# 최소 2개 이상의 샘플을 가진 라벨만 사용\n",
    "min_samples = 2\n",
    "valid_labels = label_counts[label_counts >= min_samples].index\n",
    "filtered_data = data[data['combined_label'].isin(valid_labels)]\n",
    "\n",
    "print(f\"\\n필터링 후:\")\n",
    "print(f\"유효 라벨 수: {len(valid_labels)}\")\n",
    "print(f\"훈련용 데이터 수: {len(filtered_data)}\")\n",
    "\n",
    "# 훈련 데이터 준비 (data에서)\n",
    "X_train = filtered_data['generator_context'].values\n",
    "y_train = filtered_data['combined_label'].values\n",
    "\n",
    "# 테스트 데이터 로드 및 준비\n",
    "test_data = pd.read_excel(r'C:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\data\\증강할데이터33.xlsx')\n",
    "print(f\"\\n테스트 데이터 로드:\")\n",
    "print(f\"테스트 데이터 크기: {test_data.shape}\")\n",
    "print(f\"테스트 데이터 컬럼: {list(test_data.columns)}\")\n",
    "\n",
    "# 테스트 데이터에서 복합 라벨 생성\n",
    "test_data['combined_label'] = test_data['category1'] + \"_\" + test_data['category2']\n",
    "\n",
    "# 테스트 데이터 준비 - context 컬럼 사용\n",
    "X_test = test_data['context'].fillna('').astype(str).values\n",
    "y_test = test_data['combined_label'].values\n",
    "\n",
    "print(f\"\\n최종 데이터:\")\n",
    "print(f\"훈련 데이터: {len(X_train)}개\")\n",
    "print(f\"테스트 데이터: {len(X_test)}개\")\n",
    "print(f\"훈련 라벨 수: {len(set(y_train))}개\")\n",
    "print(f\"테스트 라벨 수: {len(set(y_test))}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13495b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f72f27ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 필터링 전: 3360개\n",
      "re_category1에서 중립: 3개\n",
      "re_category2에서 중립: 1개\n",
      "데이터 필터링 후: 3359개\n",
      "제거된 데이터: 1개\n",
      "남은 re_category1 클래스 (10개): ['기쁨', '두려움', '미움(상대방)', '분노', '사랑', '수치심', '슬픔', '싫어함(상태)', '욕망', '중립']\n",
      "남은 re_category2 클래스 (64개): ['갈등', '감동', '걱정', '경멸', '고마움', '고통', '공감', '공포', '궁금함', '귀중함', '그리움', '기대감', '난처함', '날카로움', '냉담', '너그러움', '놀람', '다정함', '답답함', '동정(슬픔)', '두근거림', '만족감', '매력적', '무기력', '미안함', '반가움', '반감', '발열', '부끄러움', '불만', '불신감', '불쾌', '불편함', '비위상함', '사나움', '수치심', '시기심', '신뢰감', '신명남', '실망', '싫증', '심심함', '아쉬움', '아픔', '안정감', '억울함', '외로움', '외면', '욕심', '원망', '위축감', '자랑스러움', '자신감', '절망', '죄책감', '즐거움', '초조함', '치사함', '타오름', '통쾌함', '편안함', '허망', '호감', '후회']\n",
      "필터링 후 re_category1 중립: 2개\n",
      "필터링 후 re_category2 중립: 0개\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>generator_context</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>input_context</th>\n",
       "      <th>original_index</th>\n",
       "      <th>augmentation_index</th>\n",
       "      <th>re_category1</th>\n",
       "      <th>re_category2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>갑자기 내 책상 위에 놓인 따뜻한 손편지에 마음이 뭉클해졌다.</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "      <td>설탕 스틱 껴준거 센스 백점 만점에 천점</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>비가 오는데도 친구가 내 좋아하는 카페까지 우산 들고 따라와줘서 마음이 따뜻해졌어.</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "      <td>아쓰 산차이 기분 안 좋은 거 알아채고 산차이가 가고 싶다던 토끼집 데려온 거 감동</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>햇살 아래 반짝이는 아이의 눈동자가 마치 작은 보석처럼 빛났다. 그 순간, 세상 모...</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "      <td>신데렐라 드레스는 다시 봐도 너무 아름다워. 사람에게 꿈의 물결을 입히다니요.</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>이번 전시회 준비하면서 철저하게 세부까지 챙겨준 덕분에 모든 게 완벽하게 마무리돼서...</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "      <td>와 민희진 씨 애들 숙소 스타일링까지 맡기면서 신경써 준 거 진짜 좀 대단하네</td>\n",
       "      <td>107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>비 오는 날 낯선 사람이 내게 담요를 건네며 추위 걱정해 줬다. 마음이 따뜻해져서 ...</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "      <td>개감동인 거 자기가 쓰고 있던 우산 나 주고\\n자기가 비 맞아가면서 뒤집어준 거야\\...</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  generator_context category1  \\\n",
       "0           0                 갑자기 내 책상 위에 놓인 따뜻한 손편지에 마음이 뭉클해졌다.        기쁨   \n",
       "1           1     비가 오는데도 친구가 내 좋아하는 카페까지 우산 들고 따라와줘서 마음이 따뜻해졌어.        기쁨   \n",
       "2           2  햇살 아래 반짝이는 아이의 눈동자가 마치 작은 보석처럼 빛났다. 그 순간, 세상 모...        기쁨   \n",
       "3           3  이번 전시회 준비하면서 철저하게 세부까지 챙겨준 덕분에 모든 게 완벽하게 마무리돼서...        기쁨   \n",
       "4           4  비 오는 날 낯선 사람이 내게 담요를 건네며 추위 걱정해 줬다. 마음이 따뜻해져서 ...        기쁨   \n",
       "\n",
       "  category2                                      input_context  \\\n",
       "0        감동                             설탕 스틱 껴준거 센스 백점 만점에 천점   \n",
       "1        감동     아쓰 산차이 기분 안 좋은 거 알아채고 산차이가 가고 싶다던 토끼집 데려온 거 감동   \n",
       "2        감동        신데렐라 드레스는 다시 봐도 너무 아름다워. 사람에게 꿈의 물결을 입히다니요.   \n",
       "3        감동        와 민희진 씨 애들 숙소 스타일링까지 맡기면서 신경써 준 거 진짜 좀 대단하네   \n",
       "4        감동  개감동인 거 자기가 쓰고 있던 우산 나 주고\\n자기가 비 맞아가면서 뒤집어준 거야\\...   \n",
       "\n",
       "   original_index  augmentation_index re_category1 re_category2  \n",
       "0            20.0                 NaN           기쁨           감동  \n",
       "1            79.0                 NaN           기쁨           감동  \n",
       "2           104.0                 NaN           기쁨           감동  \n",
       "3           107.0                 NaN           기쁨           감동  \n",
       "4           137.0                 NaN           기쁨           감동  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(r'C:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\data\\retest_augmentation.xlsx')\n",
    "\n",
    "# re_category2에서만 중립 데이터 제거 (re_category1은 중립 유지)\n",
    "print(f\"데이터 필터링 전: {len(data)}개\")\n",
    "print(f\"re_category1에서 중립: {(data['re_category1'] == '중립').sum()}개\")\n",
    "print(f\"re_category2에서 중립: {(data['re_category2'] == '중립').sum()}개\")\n",
    "\n",
    "# re_category2에서만 중립 데이터 제거 (Category2에 중립이 없으므로 라벨 불일치 방지)\n",
    "original_count = len(data)\n",
    "data = data[data['re_category2'] != '중립'].copy()\n",
    "\n",
    "# 인덱스 재설정\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "print(f\"데이터 필터링 후: {len(data)}개\")\n",
    "print(f\"제거된 데이터: {original_count - len(data)}개\")\n",
    "\n",
    "# 필터링된 데이터 확인\n",
    "print(f\"남은 re_category1 클래스 ({len(data['re_category1'].unique())}개): {sorted(data['re_category1'].unique())}\")\n",
    "print(f\"남은 re_category2 클래스 ({len(data['re_category2'].unique())}개): {sorted(data['re_category2'].unique())}\")\n",
    "\n",
    "# 중립 확인\n",
    "print(f\"필터링 후 re_category1 중립: {(data['re_category1'] == '중립').sum()}개\")\n",
    "print(f\"필터링 후 re_category2 중립: {(data['re_category2'] == '중립').sum()}개\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dbf27be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_model():\n",
    "  \"\"\"\n",
    "  임베딩 모델 초기화\n",
    "  \"\"\"\n",
    "  model = SentenceTransformer(\"dragonkue/snowflake-arctic-embed-l-v2.0-ko\") \n",
    "  vec_dim = len(model.encode(\"dummy_text\"))\n",
    "  print(f\"모델 차원: {vec_dim}\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c873e343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 차원: 1024\n"
     ]
    }
   ],
   "source": [
    "embeddings_model = embeddings_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4926f06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 기존 변수들이 초기화되었습니다.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3359 entries, 0 to 3358\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Unnamed: 0          3359 non-null   int64  \n",
      " 1   generator_context   3359 non-null   object \n",
      " 2   category1           3359 non-null   object \n",
      " 3   category2           3359 non-null   object \n",
      " 4   input_context       3359 non-null   object \n",
      " 5   original_index      664 non-null    float64\n",
      " 6   augmentation_index  2695 non-null   float64\n",
      " 7   re_category1        3359 non-null   object \n",
      " 8   re_category2        3359 non-null   object \n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 236.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# 기존 변수 초기화 (중립 데이터 제거로 인한 크기 불일치 방지)\n",
    "vars_to_reset = ['X', 'y', 'y_encoded', 'X_combined', 'y_cat2', 'y_cat2_encoded', 'le', 'le_cat2', 'cat1_encoder']\n",
    "for var_name in vars_to_reset:\n",
    "    if var_name in locals():\n",
    "        del locals()[var_name]\n",
    "        print(f\"변수 {var_name} 초기화됨\")\n",
    "\n",
    "print(\"✅ 기존 변수들이 초기화되었습니다.\")\n",
    "\n",
    "# 데이터 정보 확인\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd04d86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 필터링된 데이터로 벡터 생성...\n",
      "✅ 벡터 생성 완료: 3359개\n"
     ]
    }
   ],
   "source": [
    "# 중립 데이터 제거 후 벡터 생성\n",
    "print(\"📝 필터링된 데이터로 벡터 생성...\")\n",
    "data['vector'] = data['generator_context'].apply(lambda x: embeddings_model.encode(x).tolist())\n",
    "print(f\"✅ 벡터 생성 완료: {len(data)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3b7dde",
   "metadata": {},
   "source": [
    "### category1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c27bb42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 상태 확인:\n",
      "필터링된 데이터 개수: 3359\n",
      "벡터 타입: <class 'list'>\n",
      "벡터 길이: 1024\n",
      "벡터가 리스트 형태입니다. 직접 변환합니다...\n",
      "X shape: (3359, 1024)\n",
      "y shape: (3359,)\n",
      "✅ X와 y의 크기가 일치합니다!\n",
      "✅ 성공적으로 변환되었습니다!\n"
     ]
    }
   ],
   "source": [
    "# 필터링된 데이터로 벡터와 라벨 생성\n",
    "print(\"데이터 상태 확인:\")\n",
    "print(f\"필터링된 데이터 개수: {len(data)}\")\n",
    "print(f\"벡터 타입: {type(data['vector'].iloc[0])}\")\n",
    "print(f\"벡터 길이: {len(data['vector'].iloc[0])}\")\n",
    "\n",
    "# 벡터가 이미 리스트 형태라면 직접 numpy array로 변환\n",
    "if isinstance(data['vector'].iloc[0], list):\n",
    "    print(\"벡터가 리스트 형태입니다. 직접 변환합니다...\")\n",
    "    X = np.vstack(data['vector'].values)\n",
    "    y = data['re_category1'].values  # 변경: category1 → re_category1\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    \n",
    "    # 크기 일치 확인\n",
    "    if X.shape[0] == y.shape[0]:\n",
    "        print(\"✅ X와 y의 크기가 일치합니다!\")\n",
    "    else:\n",
    "        print(f\"❌ 크기 불일치: X {X.shape[0]} vs y {y.shape[0]}\")\n",
    "    \n",
    "    print(\"✅ 성공적으로 변환되었습니다!\")\n",
    "else:\n",
    "    print(\"벡터 형태에 문제가 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wqea3alqoni",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 실제 test_data 로드 및 평가\n",
      "\n",
      "테스트 데이터 기본 정보:\n",
      "데이터 크기: (664, 5)\n",
      "컬럼들: ['index', 'context', 'annotations_split', 'category1', 'category2']\n",
      "\n",
      "데이터 샘플:\n",
      "   index                                            context  \\\n",
      "0      0  보는동안 너무 행복했고 초콜렛이 너무 먹고싶었고 티모시가 잘생겼고 울어!!하는부분이...   \n",
      "1      1  어릴 때 가 보고 빕스는 거의 처음인데(기억에 없음) 지금 딸기축제 기간이라 만족스...   \n",
      "2      2  미리 계좌로 환전해둔 돈을 해외에서 환전수수료 없이 인출 가능한 트레블로그라는 카드...   \n",
      "3      3  요즘 번아웃도 자꾸 올라오고 무기력해서 종강하고 교류하기도 버거운 상태가 와부렀으요ㅠㅠ    \n",
      "4      4  크라임씬 장똥민이 범행 도구 찾으려고 화장실 탱크 뒤지는데 거기에 진짜 똥 넣어놓은...   \n",
      "\n",
      "                                   annotations_split category1 category2  \n",
      "0  [['기쁨', '만족감'], ['기쁨', '만족감'], ['기쁨', '감동'], [...        기쁨       만족감  \n",
      "1  [['기쁨', '만족감'], ['기쁨', '만족감'], ['기쁨', '만족감'], ...        기쁨       만족감  \n",
      "2  [['기쁨', '만족감'], ['기쁨', '만족감'], ['기쁨', '만족감'], ...        기쁨       만족감  \n",
      "3  [['슬픔', '무기력'], ['싫어함(상태)', '무기력'], ['슬픔', '무기...        슬픔       무기력  \n",
      "4  [['기쁨', '즐거움'], ['기쁨', '통쾌함'], ['기쁨', '통쾌함'], ...        기쁨       즐거움  \n",
      "\n",
      "test_data 컬럼 확인:\n",
      "- index: int64\n",
      "- context: object\n",
      "- annotations_split: object\n",
      "- category1: object\n",
      "- category2: object\n",
      "\n",
      "식별된 컬럼:\n",
      "텍스트 컬럼: context\n",
      "Category1 컬럼: category1\n",
      "\n",
      "✅ 필요한 컬럼들을 찾았습니다!\n",
      "테스트 데이터 개수: 664\n",
      "Category1 클래스들: ['기쁨' '슬픔' '싫어함(상태)' '미움(상대방)' '두려움' '수치심' '욕망' '분노' '사랑' '중립']\n"
     ]
    }
   ],
   "source": [
    "# 9. 실제 test_data로 모델 성능 평가\n",
    "\n",
    "print(\"📁 실제 test_data 로드 및 평가\\n\")\n",
    "\n",
    "# test_data 로드\n",
    "test_data = pd.read_excel(r'C:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\data\\증강할데이터33.xlsx')\n",
    "print(\"테스트 데이터 기본 정보:\")\n",
    "print(f\"데이터 크기: {test_data.shape}\")\n",
    "print(f\"컬럼들: {list(test_data.columns)}\")\n",
    "print(\"\\n데이터 샘플:\")\n",
    "print(test_data.head())\n",
    "\n",
    "# test_data에서 텍스트와 category1 컬럼 확인\n",
    "print(f\"\\ntest_data 컬럼 확인:\")\n",
    "for col in test_data.columns:\n",
    "    print(f\"- {col}: {test_data[col].dtype}\")\n",
    "\n",
    "# 텍스트 컬럼과 category1 컬럼 식별 (컬럼명에 따라 조정 필요)\n",
    "text_column = None\n",
    "category1_column = None\n",
    "\n",
    "# 가능한 텍스트 컬럼명들\n",
    "possible_text_columns = ['context', 'text', 'content', 'sentence', '내용', '문장']\n",
    "for col in test_data.columns:\n",
    "    if any(keyword in col.lower() for keyword in possible_text_columns):\n",
    "        text_column = col\n",
    "        break\n",
    "\n",
    "# 가능한 category1 컬럼명들\n",
    "possible_cat1_columns = ['category1', 'cat1', 'label', '감정', '카테고리1']\n",
    "for col in test_data.columns:\n",
    "    if any(keyword in col.lower() for keyword in possible_cat1_columns):\n",
    "        category1_column = col\n",
    "        break\n",
    "\n",
    "print(f\"\\n식별된 컬럼:\")\n",
    "print(f\"텍스트 컬럼: {text_column}\")\n",
    "print(f\"Category1 컬럼: {category1_column}\")\n",
    "\n",
    "if text_column and category1_column:\n",
    "    print(f\"\\n✅ 필요한 컬럼들을 찾았습니다!\")\n",
    "    print(f\"테스트 데이터 개수: {len(test_data)}\")\n",
    "    print(f\"Category1 클래스들: {test_data[category1_column].unique()}\")\n",
    "else:\n",
    "    print(f\"\\n❌ 필요한 컬럼을 찾을 수 없습니다. 수동으로 지정해주세요.\")\n",
    "    print(\"사용 가능한 컬럼들:\")\n",
    "    for i, col in enumerate(test_data.columns):\n",
    "        print(f\"{i}: {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fed4954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Category1 모델의 test_data 성능 평가\n",
      "\n",
      "y_encoded 변수를 재정의합니다...\n",
      "y_encoded shape: (3359,)\n",
      "📝 test_data 텍스트 임베딩 중...\n",
      "✅ 임베딩 완료: (664, 1024)\n",
      "실제 라벨: 664\n",
      "테스트 데이터 중립 개수: 5개\n",
      "테스트 데이터 category1 클래스 (10개): ['기쁨', '두려움', '미움(상대방)', '분노', '사랑', '수치심', '슬픔', '싫어함(상태)', '욕망', '중립']\n",
      "\n",
      "🔄 전체 학습 데이터로 최종 모델 학습...\n",
      "✅ 최종 모델 학습 완료!\n",
      "\n",
      "🎯 test_data 예측 수행...\n",
      "\n",
      "📋 클래스 정보:\n",
      "학습 클래스 수: 10\n",
      "학습 클래스: ['기쁨', '두려움', '미움(상대방)', '분노', '사랑', '수치심', '슬픔', '싫어함(상태)', '욕망', '중립']\n",
      "테스트 실제 클래스 수: 10\n",
      "테스트 실제 클래스: ['기쁨', '두려움', '미움(상대방)', '분노', '사랑', '수치심', '슬픔', '싫어함(상태)', '욕망', '중립']\n",
      "공통 클래스 수: 10\n",
      "✅ 훈련 데이터와 테스트 데이터의 Category1 클래스가 완벽히 일치합니다!\n",
      "\n",
      "📊 Classification Report:\n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          기쁨       0.65      0.78      0.71       188\n",
      "         두려움       0.92      0.15      0.26        72\n",
      "     미움(상대방)       0.37      0.70      0.48        43\n",
      "          분노       0.25      0.33      0.29        36\n",
      "          사랑       0.43      0.06      0.11        47\n",
      "         수치심       0.33      0.08      0.13        25\n",
      "          슬픔       0.52      0.65      0.58       117\n",
      "     싫어함(상태)       0.26      0.10      0.15        49\n",
      "          욕망       0.33      0.48      0.39        82\n",
      "          중립       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.49       664\n",
      "   macro avg       0.41      0.33      0.31       664\n",
      "weighted avg       0.51      0.49      0.45       664\n",
      "\n",
      "\n",
      "🎯 전체 정확도: 0.4880 (48.80%)\n",
      "평가 데이터: 664개 모두 평가\n",
      "\n",
      "🔍 예측 샘플 (처음 10개):\n",
      "------------------------------------------------------------------------------------------\n",
      " 1. ✅ 실제: 기쁨           예측: 기쁨          \n",
      "    텍스트: 보는동안 너무 행복했고 초콜렛이 너무 먹고싶었고 티모시가 잘생겼고 울어!!하는부분이 있어서 울었다네요\n",
      "\n",
      " 2. ✅ 실제: 기쁨           예측: 기쁨          \n",
      "    텍스트: 어릴 때 가 보고 빕스는 거의 처음인데(기억에 없음) 지금 딸기축제 기간이라 만족스러운 식사 하고 옴\n",
      "\n",
      " 3. ✅ 실제: 기쁨           예측: 기쁨          \n",
      "    텍스트: 미리 계좌로 환전해둔 돈을 해외에서 환전수수료 없이 인출 가능한 트레블로그라는 카드인데, 선택할 수 있는 디...\n",
      "\n",
      " 4. ❌ 실제: 슬픔           예측: 싫어함(상태)     \n",
      "    텍스트: 요즘 번아웃도 자꾸 올라오고 무기력해서 종강하고 교류하기도 버거운 상태가 와부렀으요ㅠㅠ \n",
      "\n",
      " 5. ❌ 실제: 기쁨           예측: 미움(상대방)     \n",
      "    텍스트: 크라임씬 장똥민이 범행 도구 찾으려고 화장실 탱크 뒤지는데 거기에 진짜 똥 넣어놓은 거 진짜 웃겨 뒤지겠음ㅋ...\n",
      "\n",
      " 6. ❌ 실제: 싫어함(상태)      예측: 슬픔          \n",
      "    텍스트: 가슴이 답답해짐 진짜 개답답해짐\n",
      "우리진짜투표잘하자\n",
      "\n",
      " 7. ❌ 실제: 기쁨           예측: 욕망          \n",
      "    텍스트: 지그재그랑 에이블리랑 할인 대결하나\n",
      "아 흐뭇해\n",
      "계속되길...\n",
      "영원히....\n",
      "\n",
      " 8. ❌ 실제: 기쁨           예측: 욕망          \n",
      "    텍스트: 첨으로 수제 초콜릿 만듬\n",
      "초콜릿을 5시간이나 만드는 사람이 있다??? 그게 바로 나\n",
      "\n",
      " 9. ❌ 실제: 슬픔           예측: 기쁨          \n",
      "    텍스트: 단톡방에 공지들 슬슬 올라오는거 보니까 곧 개강이라는게 실감나서 갑자기 재기하고싶고 인생이 다 끝난거처럼 암...\n",
      "\n",
      "10. ✅ 실제: 기쁨           예측: 기쁨          \n",
      "    텍스트: 장흥신 공손한 손가락질 개웃겨요\n",
      "애드립 미친것 같음\n",
      "\n",
      "\n",
      "📈 클래스별 성능 요약:\n",
      "------------------------------------------------------------\n",
      "클래스             전체       정답       정확도       \n",
      "--------------------------------------------------\n",
      "기쁨              188      146      0.7766\n",
      "두려움             72       11       0.1528\n",
      "미움(상대방)         43       30       0.6977\n",
      "분노              36       12       0.3333\n",
      "사랑              47       3        0.0638\n",
      "수치심             25       2        0.0800\n",
      "슬픔              117      76       0.6496\n",
      "싫어함(상태)         49       5        0.1020\n",
      "욕망              82       39       0.4756\n",
      "중립              5        0        0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# K-Fold로 평가한 Category1 모델로 test_data 예측 및 classification_report\n",
    "\n",
    "print(\"🎯 Category1 모델의 test_data 성능 평가\\n\")\n",
    "\n",
    "# 1. 학습 데이터 X, y 변수 정의 (필요시)\n",
    "if 'X' not in locals():\n",
    "    print(\"X 변수를 재정의합니다...\")\n",
    "    X = np.vstack(data['vector'].values)\n",
    "    y = data['re_category1'].values  # 변경: category1 → re_category1 (중립 포함)\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    print(f\"훈련 데이터 re_category1 클래스 ({len(np.unique(y))}개): {sorted(np.unique(y))}\")\n",
    "\n",
    "# 2. y_encoded 정의 (필요시)\n",
    "if 'y_encoded' not in locals():\n",
    "    print(\"y_encoded 변수를 재정의합니다...\")\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    print(f\"y_encoded shape: {y_encoded.shape}\")\n",
    "\n",
    "# 3. test_data의 텍스트를 벡터로 변환\n",
    "print(\"📝 test_data 텍스트 임베딩 중...\")\n",
    "test_texts = test_data['context'].fillna('').astype(str).tolist()\n",
    "test_vectors = []\n",
    "\n",
    "for text in test_texts:\n",
    "    vector = embeddings_model.encode(text)\n",
    "    test_vectors.append(vector)\n",
    "\n",
    "test_X = np.vstack(test_vectors)\n",
    "test_y_actual = test_data['category1'].values\n",
    "\n",
    "print(f\"✅ 임베딩 완료: {test_X.shape}\")\n",
    "print(f\"실제 라벨: {len(test_y_actual)}\")\n",
    "\n",
    "# 테스트 데이터에서 중립 확인\n",
    "test_neutral_count = (test_y_actual == '중립').sum()\n",
    "print(f\"테스트 데이터 중립 개수: {test_neutral_count}개\")\n",
    "print(f\"테스트 데이터 category1 클래스 ({len(np.unique(test_y_actual))}개): {sorted(np.unique(test_y_actual))}\")\n",
    "\n",
    "# 4. 전체 학습 데이터로 최종 모델 학습\n",
    "print(\"\\n🔄 전체 학습 데이터로 최종 모델 학습...\")\n",
    "final_cat1_model = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 전체 학습 데이터로 모델 학습\n",
    "final_cat1_model.fit(X, y_encoded)\n",
    "print(\"✅ 최종 모델 학습 완료!\")\n",
    "\n",
    "# 5. test_data로 예측 수행\n",
    "print(\"\\n🎯 test_data 예측 수행...\")\n",
    "test_y_pred_encoded = final_cat1_model.predict(test_X)\n",
    "test_y_pred = le.inverse_transform(test_y_pred_encoded)\n",
    "\n",
    "# 6. 학습 클래스와 테스트 클래스 비교\n",
    "train_classes = set(le.classes_)\n",
    "test_actual_classes = set(test_y_actual)\n",
    "test_pred_classes = set(test_y_pred)\n",
    "\n",
    "print(f\"\\n📋 클래스 정보:\")\n",
    "print(f\"학습 클래스 수: {len(train_classes)}\")\n",
    "print(f\"학습 클래스: {sorted(train_classes)}\")\n",
    "print(f\"테스트 실제 클래스 수: {len(test_actual_classes)}\")  \n",
    "print(f\"테스트 실제 클래스: {sorted(test_actual_classes)}\")\n",
    "\n",
    "# 학습에 없는 클래스 확인\n",
    "unseen_classes = test_actual_classes - train_classes\n",
    "if unseen_classes:\n",
    "    print(f\"⚠️ 학습에 없던 클래스들: {unseen_classes}\")\n",
    "    \n",
    "common_classes = train_classes & test_actual_classes\n",
    "print(f\"공통 클래스 수: {len(common_classes)}\")\n",
    "\n",
    "# 클래스 매치 확인\n",
    "if len(train_classes) == len(test_actual_classes) == len(common_classes):\n",
    "    print(\"✅ 훈련 데이터와 테스트 데이터의 Category1 클래스가 완벽히 일치합니다!\")\n",
    "    perfect_match = True\n",
    "else:\n",
    "    print(\"❌ 클래스 불일치가 있습니다.\")\n",
    "    perfect_match = False\n",
    "\n",
    "# 7. classification_report 생성\n",
    "print(f\"\\n📊 Classification Report:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if perfect_match:\n",
    "    # 모든 클래스가 공통인 경우 - 전체 평가 가능\n",
    "    test_y_actual_encoded = le.transform(test_y_actual)\n",
    "    report = classification_report(\n",
    "        test_y_actual_encoded, \n",
    "        test_y_pred_encoded, \n",
    "        target_names=le.classes_\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    # 전체 정확도\n",
    "    accuracy = (test_y_pred == test_y_actual).mean()\n",
    "    print(f\"\\n🎯 전체 정확도: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"평가 데이터: {len(test_y_actual)}개 모두 평가\")\n",
    "    \n",
    "else:\n",
    "    # 공통 클래스만 필터링해서 평가\n",
    "    mask = np.array([actual in common_classes for actual in test_y_actual])\n",
    "    filtered_actual = test_y_actual[mask]\n",
    "    filtered_pred = test_y_pred[mask]\n",
    "    \n",
    "    print(f\"공통 클래스 평가: {len(filtered_actual)}/{len(test_y_actual)}개\")\n",
    "    \n",
    "    filtered_actual_encoded = le.transform(filtered_actual)\n",
    "    filtered_pred_encoded = le.transform(filtered_pred)\n",
    "    \n",
    "    # 공통 클래스에 대한 라벨과 인덱스 매핑\n",
    "    common_class_labels = [cls for cls in le.classes_ if cls in common_classes]\n",
    "    common_class_indices = [le.transform([cls])[0] for cls in common_class_labels]\n",
    "    \n",
    "    report = classification_report(\n",
    "        filtered_actual_encoded,\n",
    "        filtered_pred_encoded,\n",
    "        target_names=common_class_labels,\n",
    "        labels=common_class_indices\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    # 필터링된 데이터의 정확도\n",
    "    accuracy = (filtered_pred == filtered_actual).mean()\n",
    "    print(f\"\\n🎯 정확도 (공통 클래스만): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"평가 데이터: {len(filtered_actual)}/{len(test_y_actual)}개\")\n",
    "\n",
    "# 8. 예측 샘플 출력\n",
    "print(f\"\\n🔍 예측 샘플 (처음 10개):\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for i in range(min(10, len(test_texts))):\n",
    "    text = test_texts[i][:60] + \"...\" if len(test_texts[i]) > 60 else test_texts[i]\n",
    "    actual = test_y_actual[i]\n",
    "    predicted = test_y_pred[i]\n",
    "    status = \"✅\" if actual == predicted else \"❌\"\n",
    "    \n",
    "    print(f\"{i+1:2d}. {status} 실제: {actual:<12} 예측: {predicted:<12}\")\n",
    "    print(f\"    텍스트: {text}\")\n",
    "    print()\n",
    "\n",
    "# 9. 클래스별 성능 요약\n",
    "print(f\"\\n📈 클래스별 성능 요약:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "from collections import defaultdict\n",
    "class_stats = defaultdict(lambda: {'total': 0, 'correct': 0})\n",
    "\n",
    "for actual, pred in zip(test_y_actual, test_y_pred):\n",
    "    if actual in common_classes:  # 공통 클래스만 계산\n",
    "        class_stats[actual]['total'] += 1\n",
    "        if actual == pred:\n",
    "            class_stats[actual]['correct'] += 1\n",
    "\n",
    "print(f\"{'클래스':<15} {'전체':<8} {'정답':<8} {'정확도':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for class_name, stats in sorted(class_stats.items()):\n",
    "    if stats['total'] > 0:\n",
    "        class_accuracy = stats['correct'] / stats['total']\n",
    "        print(f\"{class_name:<15} {stats['total']:<8} {stats['correct']:<8} {class_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53gspj90vxl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🎯 Category2 모델의 test_data 성능 평가\n",
      "================================================================================\n",
      "Category2 학습용 변수들을 재정의합니다...\n",
      "📊 Category2 데이터 확인:\n",
      "  - 전체 Category2 데이터: 3359개\n",
      "  - 고유 Category2 클래스: 64개\n",
      "  - Category2 클래스 목록: ['갈등', '감동', '걱정', '경멸', '고마움', '고통', '공감', '공포', '궁금함', '귀중함', '그리움', '기대감', '난처함', '날카로움', '냉담', '너그러움', '놀람', '다정함', '답답함', '동정(슬픔)', '두근거림', '만족감', '매력적', '무기력', '미안함', '반가움', '반감', '발열', '부끄러움', '불만', '불신감', '불쾌', '불편함', '비위상함', '사나움', '수치심', '시기심', '신뢰감', '신명남', '실망', '싫증', '심심함', '아쉬움', '아픔', '안정감', '억울함', '외로움', '외면', '욕심', '원망', '위축감', '자랑스러움', '자신감', '절망', '죄책감', '즐거움', '초조함', '치사함', '타오름', '통쾌함', '편안함', '허망', '호감', '후회']\n",
      "✅ Category2에서 중립이 성공적으로 제거되었습니다.\n",
      "  - 인코딩된 Category2 클래스: 64개\n",
      "X shape: (3359, 1024)\n",
      "y shape: (3359,)\n",
      "y_cat1_onehot shape: (3359, 10)\n",
      "X_combined shape: (3359, 1034)\n",
      "y_cat2 shape: (3359,)\n",
      "y_cat2_encoded shape: (3359,)\n",
      "\n",
      "📝 Category2 예측을 위한 데이터 준비...\n",
      "테스트 데이터:\n",
      "- Category1 실제값: 664개\n",
      "- Category2 실제값: 664개\n",
      "- 테스트 Category2 클래스: 64개\n",
      "- 테스트 데이터 중립: Category1=5개, Category2=0개\n",
      "\n",
      "🔧 Category1 예측값으로 Category2 예측용 특성 생성...\n",
      "test_X shape: (664, 1024)\n",
      "test_cat1_onehot shape: (664, 10)\n",
      "✅ 결합된 특성: (664, 1034)\n",
      "\n",
      "🔄 전체 학습 데이터로 Category2 최종 모델 학습...\n",
      "학습 데이터 확인: X_combined (3359, 1034), y_cat2_encoded (3359,)\n",
      "✅ Category2 최종 모델 학습 완료!\n",
      "\n",
      "🎯 test_data Category2 예측 수행...\n",
      "\n",
      "📋 Category2 클래스 정보:\n",
      "학습 클래스 수: 64\n",
      "테스트 실제 클래스 수: 64\n",
      "공통 클래스 수: 64\n",
      "✅ 훈련 데이터와 테스트 데이터의 Category2 클래스가 완벽히 일치합니다!\n",
      "\n",
      "📊 Category2 Classification Report:\n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          갈등       0.00      0.00      0.00         1\n",
      "          감동       0.29      0.40      0.34        30\n",
      "          걱정       0.43      0.13      0.20        23\n",
      "          경멸       0.20      0.44      0.27        18\n",
      "         고마움       0.46      0.63      0.53        19\n",
      "          고통       0.00      0.00      0.00         9\n",
      "          공감       0.00      0.00      0.00         7\n",
      "          공포       0.00      0.00      0.00        17\n",
      "         궁금함       0.12      0.56      0.20         9\n",
      "         귀중함       0.00      0.00      0.00         5\n",
      "         그리움       0.50      0.09      0.15        11\n",
      "         기대감       0.50      0.39      0.44        18\n",
      "         난처함       0.25      0.07      0.11        14\n",
      "        날카로움       0.00      0.00      0.00         3\n",
      "          냉담       0.00      0.00      0.00         3\n",
      "        너그러움       0.00      0.00      0.00         1\n",
      "          놀람       0.33      0.19      0.24        31\n",
      "         다정함       0.00      0.00      0.00         9\n",
      "         답답함       0.22      0.11      0.15        18\n",
      "      동정(슬픔)       0.57      0.48      0.52        27\n",
      "        두근거림       0.00      0.00      0.00         2\n",
      "         만족감       0.35      0.35      0.35        49\n",
      "         매력적       1.00      0.08      0.14        13\n",
      "         무기력       0.25      0.36      0.29        14\n",
      "         미안함       1.00      0.29      0.44         7\n",
      "         반가움       0.20      0.06      0.10        16\n",
      "          반감       0.20      0.20      0.20         5\n",
      "          발열       0.00      0.00      0.00         3\n",
      "        부끄러움       0.00      0.00      0.00        16\n",
      "          불만       0.20      0.12      0.15         8\n",
      "         불신감       0.20      0.12      0.15         8\n",
      "          불쾌       0.11      0.15      0.13        20\n",
      "         불편함       0.40      0.29      0.33         7\n",
      "        비위상함       0.00      0.00      0.00         1\n",
      "         사나움       0.20      0.25      0.22         4\n",
      "         수치심       0.00      0.00      0.00         3\n",
      "         시기심       0.20      0.50      0.29         2\n",
      "         신뢰감       0.00      0.00      0.00         1\n",
      "         신명남       1.00      0.20      0.33         5\n",
      "          실망       0.11      0.31      0.16        13\n",
      "          싫증       0.00      0.00      0.00         9\n",
      "         심심함       0.00      0.00      0.00         1\n",
      "         아쉬움       0.43      0.30      0.36        33\n",
      "          아픔       0.00      0.00      0.00         3\n",
      "         안정감       0.20      0.12      0.15         8\n",
      "         억울함       0.18      0.46      0.26        13\n",
      "         외로움       0.50      0.17      0.25         6\n",
      "          외면       0.00      0.00      0.00         1\n",
      "          욕심       0.21      0.44      0.29        18\n",
      "          원망       0.00      0.00      0.00         3\n",
      "         위축감       0.00      0.00      0.00         4\n",
      "       자랑스러움       0.16      0.42      0.23        12\n",
      "         자신감       0.00      0.00      0.00         1\n",
      "          절망       0.00      0.00      0.00         7\n",
      "         죄책감       0.00      0.00      0.00         2\n",
      "         즐거움       0.40      0.44      0.42        27\n",
      "         초조함       0.00      0.00      0.00         5\n",
      "         치사함       0.00      0.00      0.00         5\n",
      "         타오름       0.00      0.00      0.00         3\n",
      "         통쾌함       0.00      0.00      0.00         1\n",
      "         편안함       0.50      0.25      0.33         4\n",
      "          허망       0.30      0.27      0.29        11\n",
      "          호감       0.33      0.10      0.15        10\n",
      "          후회       0.33      0.29      0.31         7\n",
      "\n",
      "    accuracy                           0.24       664\n",
      "   macro avg       0.20      0.16      0.15       664\n",
      "weighted avg       0.28      0.24      0.23       664\n",
      "\n",
      "\n",
      "🎯 Category2 전체 정확도: 0.2425 (24.25%)\n",
      "평가 데이터: 664개 모두 평가\n",
      "\n",
      "🔍 Category2 예측 샘플 (처음 10개):\n",
      "----------------------------------------------------------------------------------------------------\n",
      " 1. ❌ Cat1: 기쁨 → 기쁨 | Cat2: 만족감          → 즐거움         \n",
      "    텍스트: 보는동안 너무 행복했고 초콜렛이 너무 먹고싶었고 티모시가 잘생겼고 울어!!하는부분이 있어서...\n",
      "\n",
      " 2. ❌ Cat1: 기쁨 → 기쁨 | Cat2: 만족감          → 기대감         \n",
      "    텍스트: 어릴 때 가 보고 빕스는 거의 처음인데(기억에 없음) 지금 딸기축제 기간이라 만족스러운 식...\n",
      "\n",
      " 3. ✅ Cat1: 기쁨 → 기쁨 | Cat2: 만족감          → 만족감         \n",
      "    텍스트: 미리 계좌로 환전해둔 돈을 해외에서 환전수수료 없이 인출 가능한 트레블로그라는 카드인데, ...\n",
      "\n",
      " 4. ❌ Cat1: 슬픔 → 싫어함(상태) | Cat2: 무기력          → 난처함         \n",
      "    텍스트: 요즘 번아웃도 자꾸 올라오고 무기력해서 종강하고 교류하기도 버거운 상태가 와부렀으요ㅠㅠ \n",
      "\n",
      " 5. ❌ Cat1: 기쁨 → 미움(상대방) | Cat2: 즐거움          → 비위상함        \n",
      "    텍스트: 크라임씬 장똥민이 범행 도구 찾으려고 화장실 탱크 뒤지는데 거기에 진짜 똥 넣어놓은 거 진...\n",
      "\n",
      " 6. ❌ Cat1: 싫어함(상태) → 슬픔 | Cat2: 답답함          → 무기력         \n",
      "    텍스트: 가슴이 답답해짐 진짜 개답답해짐\n",
      "우리진짜투표잘하자\n",
      "\n",
      " 7. ❌ Cat1: 기쁨 → 욕망 | Cat2: 만족감          → 욕심          \n",
      "    텍스트: 지그재그랑 에이블리랑 할인 대결하나\n",
      "아 흐뭇해\n",
      "계속되길...\n",
      "영원히....\n",
      "\n",
      " 8. ❌ Cat1: 기쁨 → 욕망 | Cat2: 자랑스러움        → 욕심          \n",
      "    텍스트: 첨으로 수제 초콜릿 만듬\n",
      "초콜릿을 5시간이나 만드는 사람이 있다??? 그게 바로 나\n",
      "\n",
      " 9. ❌ Cat1: 슬픔 → 기쁨 | Cat2: 절망           → 기대감         \n",
      "    텍스트: 단톡방에 공지들 슬슬 올라오는거 보니까 곧 개강이라는게 실감나서 갑자기 재기하고싶고 인생이...\n",
      "\n",
      "10. ❌ Cat1: 기쁨 → 기쁨 | Cat2: 즐거움          → 감동          \n",
      "    텍스트: 장흥신 공손한 손가락질 개웃겨요\n",
      "애드립 미친것 같음\n",
      "\n",
      "\n",
      "📈 Category2 클래스별 성능 요약:\n",
      "------------------------------------------------------------\n",
      "클래스             전체       정답       정확도       \n",
      "--------------------------------------------------\n",
      "갈등              1        0        0.0000\n",
      "감동              30       12       0.4000\n",
      "걱정              23       3        0.1304\n",
      "경멸              18       8        0.4444\n",
      "고마움             19       12       0.6316\n",
      "고통              9        0        0.0000\n",
      "공감              7        0        0.0000\n",
      "공포              17       0        0.0000\n",
      "궁금함             9        5        0.5556\n",
      "귀중함             5        0        0.0000\n",
      "그리움             11       1        0.0909\n",
      "기대감             18       7        0.3889\n",
      "난처함             14       1        0.0714\n",
      "날카로움            3        0        0.0000\n",
      "냉담              3        0        0.0000\n",
      "너그러움            1        0        0.0000\n",
      "놀람              31       6        0.1935\n",
      "다정함             9        0        0.0000\n",
      "답답함             18       2        0.1111\n",
      "동정(슬픔)          27       13       0.4815\n",
      "두근거림            2        0        0.0000\n",
      "만족감             49       17       0.3469\n",
      "매력적             13       1        0.0769\n",
      "무기력             14       5        0.3571\n",
      "미안함             7        2        0.2857\n",
      "반가움             16       1        0.0625\n",
      "반감              5        1        0.2000\n",
      "발열              3        0        0.0000\n",
      "부끄러움            16       0        0.0000\n",
      "불만              8        1        0.1250\n",
      "불신감             8        1        0.1250\n",
      "불쾌              20       3        0.1500\n",
      "불편함             7        2        0.2857\n",
      "비위상함            1        0        0.0000\n",
      "사나움             4        1        0.2500\n",
      "수치심             3        0        0.0000\n",
      "시기심             2        1        0.5000\n",
      "신뢰감             1        0        0.0000\n",
      "신명남             5        1        0.2000\n",
      "실망              13       4        0.3077\n",
      "싫증              9        0        0.0000\n",
      "심심함             1        0        0.0000\n",
      "아쉬움             33       10       0.3030\n",
      "아픔              3        0        0.0000\n",
      "안정감             8        1        0.1250\n",
      "억울함             13       6        0.4615\n",
      "외로움             6        1        0.1667\n",
      "외면              1        0        0.0000\n",
      "욕심              18       8        0.4444\n",
      "원망              3        0        0.0000\n",
      "위축감             4        0        0.0000\n",
      "자랑스러움           12       5        0.4167\n",
      "자신감             1        0        0.0000\n",
      "절망              7        0        0.0000\n",
      "죄책감             2        0        0.0000\n",
      "즐거움             27       12       0.4444\n",
      "초조함             5        0        0.0000\n",
      "치사함             5        0        0.0000\n",
      "타오름             3        0        0.0000\n",
      "통쾌함             1        0        0.0000\n",
      "편안함             4        1        0.2500\n",
      "허망              11       3        0.2727\n",
      "호감              10       1        0.1000\n",
      "후회              7        2        0.2857\n",
      "\n",
      "📊 최종 성능 비교:\n",
      "============================================================\n",
      "Category1 정확도: 0.4880 (48.80%)\n",
      "Category2 정확도: 0.2425 (24.25%)\n",
      "✅ Category1 분류가 더 정확합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Category2 모델로 test_data 예측 및 classification_report\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎯 Category2 모델의 test_data 성능 평가\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. 필요한 변수들 정의 (필요시)\n",
    "if 'X_combined' not in locals():\n",
    "    print(\"Category2 학습용 변수들을 재정의합니다...\")\n",
    "    \n",
    "    # OneHotEncoder for Category1\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    cat1_encoder = OneHotEncoder(sparse_output=False)\n",
    "    y_cat1_onehot = cat1_encoder.fit_transform(y.reshape(-1, 1))\n",
    "    \n",
    "    # Combined features for Category2\n",
    "    X_combined = np.hstack([X, y_cat1_onehot])\n",
    "    \n",
    "    # Category2 encoder - 변경: category2 → re_category2 (중립 제거된 데이터 사용)\n",
    "    y_cat2 = data['re_category2'].values\n",
    "    print(f\"📊 Category2 데이터 확인:\")\n",
    "    print(f\"  - 전체 Category2 데이터: {len(y_cat2)}개\")\n",
    "    print(f\"  - 고유 Category2 클래스: {len(np.unique(y_cat2))}개\")\n",
    "    print(f\"  - Category2 클래스 목록: {sorted(np.unique(y_cat2))}\")\n",
    "    \n",
    "    # 중립 제거 확인\n",
    "    neutral_count = (y_cat2 == '중립').sum()\n",
    "    if neutral_count > 0:\n",
    "        print(f\"⚠️ 경고: Category2에 여전히 중립이 {neutral_count}개 있습니다!\")\n",
    "    else:\n",
    "        print(\"✅ Category2에서 중립이 성공적으로 제거되었습니다.\")\n",
    "    \n",
    "    le_cat2 = LabelEncoder()\n",
    "    y_cat2_encoded = le_cat2.fit_transform(y_cat2)\n",
    "    \n",
    "    print(f\"  - 인코딩된 Category2 클래스: {len(le_cat2.classes_)}개\")\n",
    "    \n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    print(f\"y_cat1_onehot shape: {y_cat1_onehot.shape}\")\n",
    "    print(f\"X_combined shape: {X_combined.shape}\")\n",
    "    print(f\"y_cat2 shape: {y_cat2.shape}\")\n",
    "    print(f\"y_cat2_encoded shape: {y_cat2_encoded.shape}\")\n",
    "    \n",
    "    # 크기 확인 및 수정\n",
    "    if X_combined.shape[0] != y_cat2_encoded.shape[0]:\n",
    "        print(f\"⚠️ 크기 불일치 감지: X_combined {X_combined.shape[0]} vs y_cat2_encoded {y_cat2_encoded.shape[0]}\")\n",
    "        min_size = min(X_combined.shape[0], y_cat2_encoded.shape[0])\n",
    "        X_combined = X_combined[:min_size]\n",
    "        y_cat2_encoded = y_cat2_encoded[:min_size]\n",
    "        print(f\"✅ 크기 조정 완료: {X_combined.shape[0]} rows\")\n",
    "\n",
    "# 2. Category1을 먼저 예측해야 Category2를 예측할 수 있음\n",
    "print(\"\\n📝 Category2 예측을 위한 데이터 준비...\")\n",
    "\n",
    "# test_data의 실제 category1과 category2\n",
    "test_y_actual_cat1 = test_data['category1'].values\n",
    "test_y_actual_cat2 = test_data['category2'].values\n",
    "\n",
    "print(f\"테스트 데이터:\")\n",
    "print(f\"- Category1 실제값: {len(test_y_actual_cat1)}개\")\n",
    "print(f\"- Category2 실제값: {len(test_y_actual_cat2)}개\")\n",
    "print(f\"- 테스트 Category2 클래스: {len(np.unique(test_y_actual_cat2))}개\")\n",
    "\n",
    "# 테스트 데이터에서 중립 확인 및 필터링 정보\n",
    "test_cat1_neutral_count = (test_y_actual_cat1 == '중립').sum()\n",
    "test_cat2_neutral_count = (test_y_actual_cat2 == '중립').sum()\n",
    "print(f\"- 테스트 데이터 중립: Category1={test_cat1_neutral_count}개, Category2={test_cat2_neutral_count}개\")\n",
    "\n",
    "# Category1 예측값을 사용하여 Category2 예측용 특성 생성\n",
    "print(\"\\n🔧 Category1 예측값으로 Category2 예측용 특성 생성...\")\n",
    "\n",
    "# Category1 예측값을 원핫인코딩\n",
    "test_cat1_onehot = cat1_encoder.transform(test_y_pred.reshape(-1, 1))\n",
    "test_X_combined = np.hstack([test_X, test_cat1_onehot])\n",
    "\n",
    "print(f\"test_X shape: {test_X.shape}\")\n",
    "print(f\"test_cat1_onehot shape: {test_cat1_onehot.shape}\")\n",
    "print(f\"✅ 결합된 특성: {test_X_combined.shape}\")\n",
    "\n",
    "# 3. 전체 학습 데이터로 Category2 최종 모델 학습\n",
    "print(\"\\n🔄 전체 학습 데이터로 Category2 최종 모델 학습...\")\n",
    "print(f\"학습 데이터 확인: X_combined {X_combined.shape}, y_cat2_encoded {y_cat2_encoded.shape}\")\n",
    "\n",
    "final_cat2_model = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 전체 학습 데이터로 Category2 모델 학습\n",
    "final_cat2_model.fit(X_combined, y_cat2_encoded)\n",
    "print(\"✅ Category2 최종 모델 학습 완료!\")\n",
    "\n",
    "# 4. test_data로 Category2 예측 수행\n",
    "print(\"\\n🎯 test_data Category2 예측 수행...\")\n",
    "test_y_pred_cat2_encoded = final_cat2_model.predict(test_X_combined)\n",
    "test_y_pred_cat2 = le_cat2.inverse_transform(test_y_pred_cat2_encoded)\n",
    "\n",
    "# 5. 학습 클래스와 테스트 클래스 비교 (Category2)\n",
    "train_classes_cat2 = set(le_cat2.classes_)\n",
    "test_actual_classes_cat2 = set(test_y_actual_cat2)\n",
    "\n",
    "print(f\"\\n📋 Category2 클래스 정보:\")\n",
    "print(f\"학습 클래스 수: {len(train_classes_cat2)}\")\n",
    "print(f\"테스트 실제 클래스 수: {len(test_actual_classes_cat2)}\")\n",
    "\n",
    "# 학습에 없는 클래스 확인\n",
    "unseen_classes_cat2 = test_actual_classes_cat2 - train_classes_cat2\n",
    "if unseen_classes_cat2:\n",
    "    print(f\"⚠️ 학습에 없던 Category2 클래스들: {unseen_classes_cat2}\")\n",
    "\n",
    "common_classes_cat2 = train_classes_cat2 & test_actual_classes_cat2\n",
    "print(f\"공통 클래스 수: {len(common_classes_cat2)}\")\n",
    "\n",
    "# 클래스 매치 확인\n",
    "if len(train_classes_cat2) == len(test_actual_classes_cat2) == len(common_classes_cat2):\n",
    "    print(\"✅ 훈련 데이터와 테스트 데이터의 Category2 클래스가 완벽히 일치합니다!\")\n",
    "else:\n",
    "    print(\"❌ 클래스 불일치가 있습니다.\")\n",
    "\n",
    "# 6. Category2 Classification Report 생성\n",
    "print(f\"\\n📊 Category2 Classification Report:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 모든 클래스가 일치하므로 전체 평가 가능\n",
    "test_y_actual_cat2_encoded = le_cat2.transform(test_y_actual_cat2)\n",
    "report = classification_report(\n",
    "    test_y_actual_cat2_encoded,\n",
    "    test_y_pred_cat2_encoded,\n",
    "    target_names=le_cat2.classes_\n",
    ")\n",
    "print(report)\n",
    "\n",
    "# 전체 정확도\n",
    "accuracy_cat2 = (test_y_pred_cat2 == test_y_actual_cat2).mean()\n",
    "print(f\"\\n🎯 Category2 전체 정확도: {accuracy_cat2:.4f} ({accuracy_cat2*100:.2f}%)\")\n",
    "print(f\"평가 데이터: {len(test_y_actual_cat2)}개 모두 평가\")\n",
    "\n",
    "# 7. Category2 예측 샘플 출력\n",
    "print(f\"\\n🔍 Category2 예측 샘플 (처음 10개):\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for i in range(min(10, len(test_texts))):\n",
    "    text = test_texts[i][:50] + \"...\" if len(test_texts[i]) > 50 else test_texts[i]\n",
    "    actual_cat1 = test_y_actual_cat1[i]\n",
    "    pred_cat1 = test_y_pred[i]\n",
    "    actual_cat2 = test_y_actual_cat2[i]\n",
    "    pred_cat2 = test_y_pred_cat2[i]\n",
    "    status_cat2 = \"✅\" if actual_cat2 == pred_cat2 else \"❌\"\n",
    "    \n",
    "    print(f\"{i+1:2d}. {status_cat2} Cat1: {actual_cat1} → {pred_cat1} | Cat2: {actual_cat2:<12} → {pred_cat2:<12}\")\n",
    "    print(f\"    텍스트: {text}\")\n",
    "    print()\n",
    "\n",
    "# 8. Category2 클래스별 성능 요약\n",
    "print(f\"\\n📈 Category2 클래스별 성능 요약:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "class_stats_cat2 = defaultdict(lambda: {'total': 0, 'correct': 0})\n",
    "\n",
    "for actual, pred in zip(test_y_actual_cat2, test_y_pred_cat2):\n",
    "    class_stats_cat2[actual]['total'] += 1\n",
    "    if actual == pred:\n",
    "        class_stats_cat2[actual]['correct'] += 1\n",
    "\n",
    "print(f\"{'클래스':<15} {'전체':<8} {'정답':<8} {'정확도':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for class_name, stats in sorted(class_stats_cat2.items()):\n",
    "    if stats['total'] > 0:\n",
    "        class_accuracy = stats['correct'] / stats['total']\n",
    "        print(f\"{class_name:<15} {stats['total']:<8} {stats['correct']:<8} {class_accuracy:.4f}\")\n",
    "\n",
    "# 9. Category1 vs Category2 성능 비교\n",
    "print(f\"\\n📊 최종 성능 비교:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Category1 정확도: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Category2 정확도: {accuracy_cat2:.4f} ({accuracy_cat2*100:.2f}%)\")\n",
    "\n",
    "if accuracy > accuracy_cat2:\n",
    "    print(\"✅ Category1 분류가 더 정확합니다.\")\n",
    "else:\n",
    "    print(\"✅ Category2 분류가 더 정확합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "404da083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "얘들아 딸기축제인가 딸기장례식인가는 뭐 가지마라\n",
      "어우 별로를 넘어서 아깝다 그냥\n",
      "핸드폰 바꿨는데.. 어찌나 전뇌이식이 잘되는지 이전 폰에서 듣던 음악 멈춰둔 부분까지 살려놔서 새로 산 기분이 전혀 안남..\n",
      "친구가 만들어줬어 어이없어서 받자마자 오열함\n",
      "아니 맞긴한데\n",
      "솔직히 주말 껴서 4일…연휴라기엔 너무 눈속임임…사실상 이틀 쉰 거잖아\n",
      "소인 편의점에서 매일우유 크림빵을 만원 어치 사려고 갔는데 3개를 사기에는 부족한 돈이라 슬펐소이다. 물가가 너무 비싼것 같소.\n",
      "연휴 이틀이 다 주말에 겹쳐져 있었는데 왜 대체 공휴일은 하루만 주는거야. 부족해, 주말 상관없이 설 연휴 3일 다 완벽하게 보장해 줘.\n",
      "이렇게 자극적인 드라마 아이들도 다 접할텐데 이젠 수위조절도 안하고 막찍는거같아서 좀 안타까움이 생기네요… ㅠㅠ\n",
      "이천 햅살 커피프라프치노~! 왠지 고소한 커피맛일꺼란 기대를 엄청안고 주문했는데.. 자그마치 6300원ㅜㅜ 비싼 금액인데 만족스럽진 못했다눈ㅜㅜ\n"
     ]
    }
   ],
   "source": [
    "for context in test_data[test_data['category2']=='불만']['context']:\n",
    "  print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "448dfaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 감정 분류 파이프라인 초기화...\n",
      "✅ 파이프라인 초기화 완료!\n"
     ]
    }
   ],
   "source": [
    "# 10. 통합 예측 파이프라인 구현\n",
    "\n",
    "class EmotionClassificationPipeline:\n",
    "    \"\"\"\n",
    "    텍스트 입력 → Category1 예측 → Category2 예측 → 종합 평가 파이프라인\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embeddings_model, cat1_model, cat2_model, \n",
    "                 cat1_encoder, cat2_encoder, cat1_onehot_encoder):\n",
    "        self.embeddings_model = embeddings_model\n",
    "        self.cat1_model = cat1_model\n",
    "        self.cat2_model = cat2_model\n",
    "        self.cat1_encoder = cat1_encoder\n",
    "        self.cat2_encoder = cat2_encoder\n",
    "        self.cat1_onehot_encoder = cat1_onehot_encoder\n",
    "        \n",
    "    def predict_single(self, text):\n",
    "        \"\"\"\n",
    "        단일 텍스트에 대해 카테고리1과 카테고리2를 예측\n",
    "        \n",
    "        Args:\n",
    "            text (str): 예측할 텍스트\n",
    "        \n",
    "        Returns:\n",
    "            dict: 예측 결과 딕셔너리\n",
    "        \"\"\"\n",
    "        # 1. 텍스트 임베딩\n",
    "        text_vector = self.embeddings_model.encode(text).reshape(1, -1)\n",
    "        \n",
    "        # 2. Category1 예측\n",
    "        cat1_pred_encoded = self.cat1_model.predict(text_vector)[0]\n",
    "        cat1_pred = self.cat1_encoder.inverse_transform([cat1_pred_encoded])[0]\n",
    "        cat1_prob = self.cat1_model.predict_proba(text_vector)[0].max()\n",
    "        \n",
    "        # 3. Category1 예측값을 사용하여 Category2 예측용 특성 생성\n",
    "        cat1_onehot = self.cat1_onehot_encoder.transform([[cat1_pred]])\n",
    "        combined_features = np.hstack([text_vector, cat1_onehot])\n",
    "        \n",
    "        # 4. Category2 예측\n",
    "        cat2_pred_encoded = self.cat2_model.predict(combined_features)[0]\n",
    "        cat2_pred = self.cat2_encoder.inverse_transform([cat2_pred_encoded])[0]\n",
    "        cat2_prob = self.cat2_model.predict_proba(combined_features)[0].max()\n",
    "        \n",
    "        return {\n",
    "            'text': text,\n",
    "            'category1_predicted': cat1_pred,\n",
    "            'category1_confidence': cat1_prob,\n",
    "            'category2_predicted': cat2_pred,\n",
    "            'category2_confidence': cat2_prob\n",
    "        }\n",
    "    \n",
    "    def predict_batch(self, texts):\n",
    "        \"\"\"\n",
    "        여러 텍스트에 대해 배치 예측\n",
    "        \n",
    "        Args:\n",
    "            texts (list): 예측할 텍스트 리스트\n",
    "        \n",
    "        Returns:\n",
    "            list: 예측 결과 리스트\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for text in texts:\n",
    "            result = self.predict_single(text)\n",
    "            results.append(result)\n",
    "        return results\n",
    "    \n",
    "    def evaluate_with_ground_truth(self, texts, true_cat1, true_cat2):\n",
    "        \"\"\"\n",
    "        실제 정답과 비교하여 성능 평가\n",
    "        두 카테고리가 모두 맞은 경우만 정답으로 처리\n",
    "        \n",
    "        Args:\n",
    "            texts (list): 예측할 텍스트 리스트\n",
    "            true_cat1 (list): 실제 category1 라벨\n",
    "            true_cat2 (list): 실제 category2 라벨\n",
    "        \n",
    "        Returns:\n",
    "            dict: 평가 결과\n",
    "        \"\"\"\n",
    "        predictions = self.predict_batch(texts)\n",
    "        \n",
    "        total_count = len(texts)\n",
    "        cat1_correct = 0\n",
    "        cat2_correct = 0\n",
    "        both_correct = 0\n",
    "        \n",
    "        detailed_results = []\n",
    "        \n",
    "        for i, (pred, actual_cat1, actual_cat2) in enumerate(zip(predictions, true_cat1, true_cat2)):\n",
    "            cat1_match = pred['category1_predicted'] == actual_cat1\n",
    "            cat2_match = pred['category2_predicted'] == actual_cat2\n",
    "            both_match = cat1_match and cat2_match\n",
    "            \n",
    "            if cat1_match:\n",
    "                cat1_correct += 1\n",
    "            if cat2_match:\n",
    "                cat2_correct += 1\n",
    "            if both_match:\n",
    "                both_correct += 1\n",
    "            \n",
    "            detailed_results.append({\n",
    "                'index': i,\n",
    "                'text': pred['text'],\n",
    "                'actual_cat1': actual_cat1,\n",
    "                'predicted_cat1': pred['category1_predicted'],\n",
    "                'cat1_match': cat1_match,\n",
    "                'cat1_confidence': pred['category1_confidence'],\n",
    "                'actual_cat2': actual_cat2,\n",
    "                'predicted_cat2': pred['category2_predicted'],\n",
    "                'cat2_match': cat2_match,\n",
    "                'cat2_confidence': pred['category2_confidence'],\n",
    "                'both_correct': both_match\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'total_samples': total_count,\n",
    "            'category1_accuracy': cat1_correct / total_count,\n",
    "            'category2_accuracy': cat2_correct / total_count,\n",
    "            'both_correct_accuracy': both_correct / total_count,  # 핵심 지표\n",
    "            'category1_correct_count': cat1_correct,\n",
    "            'category2_correct_count': cat2_correct,\n",
    "            'both_correct_count': both_correct,\n",
    "            'detailed_results': detailed_results\n",
    "        }\n",
    "\n",
    "# 변수 초기화 확인 및 파이프라인 객체 생성\n",
    "print(\"🚀 감정 분류 파이프라인 초기화...\")\n",
    "\n",
    "# 필요한 변수들이 정의되었는지 확인\n",
    "required_vars = ['final_cat1_model', 'final_cat2_model', 'le', 'le_cat2', 'cat1_encoder']\n",
    "missing_vars = [var for var in required_vars if var not in locals()]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"⚠️ 다음 변수들이 정의되지 않았습니다: {missing_vars}\")\n",
    "    print(\"모델을 먼저 학습시켜주세요.\")\n",
    "else:\n",
    "    pipeline = EmotionClassificationPipeline(\n",
    "        embeddings_model=embeddings_model,\n",
    "        cat1_model=final_cat1_model,\n",
    "        cat2_model=final_cat2_model,\n",
    "        cat1_encoder=le,\n",
    "        cat2_encoder=le_cat2,\n",
    "        cat1_onehot_encoder=cat1_encoder\n",
    "    )\n",
    "    print(\"✅ 파이프라인 초기화 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c20c6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 파이프라인으로 test_data 종합 평가\n",
      "================================================================================\n",
      "평가 데이터: 664개\n",
      "Category1 클래스 수: 10\n",
      "Category2 클래스 수: 64\n",
      "테스트 데이터 중립: Category1=5개, Category2=0개\n",
      "\n",
      "🔄 파이프라인 평가 실행 중...\n",
      "Category1: 중립 포함하여 평가\n",
      "Category2: 중립 없음 (테스트 데이터에도 없음)\n",
      "\n",
      "📊 파이프라인 종합 평가 결과:\n",
      "============================================================\n",
      "전체 테스트 샘플 수: 664\n",
      "\n",
      "📈 개별 정확도:\n",
      "  Category1 정확도: 0.4880 (324/664)\n",
      "  Category2 정확도: 0.2425 (161/664)\n",
      "\n",
      "🎯 핵심 지표 - 두 카테고리 모두 정답:\n",
      "  종합 정확도: 0.2244 (149/664)\n",
      "  종합 정확도: 22.44%\n",
      "\n",
      "🔍 상세 분석:\n",
      "------------------------------------------------------------\n",
      "두 카테고리 모두 정답: 149개 (22.44%)\n",
      "Category1만 정답: 175개 (26.36%)\n",
      "Category2만 정답: 12개 (1.81%)\n",
      "둘 다 틀림: 328개 (49.40%)\n",
      "\n",
      "✅ 두 카테고리 모두 정답인 샘플들 (처음 10개):\n",
      "====================================================================================================\n",
      " 1. Cat1: 기쁨 ✓ | Cat2: 만족감 ✓\n",
      "    신뢰도: Cat1=0.467, Cat2=0.208\n",
      "    텍스트: 미리 계좌로 환전해둔 돈을 해외에서 환전수수료 없이 인출 가능한 트레블로그라는 카드인데, 선택할 수 있는 디...\n",
      "\n",
      " 2. Cat1: 기쁨 ✓ | Cat2: 만족감 ✓\n",
      "    신뢰도: Cat1=0.943, Cat2=0.283\n",
      "    텍스트: 우연히 보게 된 영상인데, 노래가 너무 좋아서 플리에도 추가하고, 카카오톡 프뮤로도 해놨음. 음원도 좋긴 한...\n",
      "\n",
      " 3. Cat1: 욕망 ✓ | Cat2: 궁금함 ✓\n",
      "    신뢰도: Cat1=0.653, Cat2=0.422\n",
      "    텍스트: 일본은 근무시간에 개인메세지 안 한다고??? 신기\n",
      "애초에 개인 메세지 도구인 카카오톡으로 업무를 하는데 친구...\n",
      "\n",
      " 4. Cat1: 기쁨 ✓ | Cat2: 즐거움 ✓\n",
      "    신뢰도: Cat1=0.415, Cat2=0.367\n",
      "    텍스트: 이렇게까지 재밌을줄은 몰랐음\n",
      "헉 엠씨 없이 진행하나??\n",
      "했는데 둘의 티키타카가 미쳤음\n",
      "\n",
      " 5. Cat1: 기쁨 ✓ | Cat2: 만족감 ✓\n",
      "    신뢰도: Cat1=0.756, Cat2=0.262\n",
      "    텍스트: 초대박 귀여운 강아디도 있음 우리 자리 와서 인사도 해줌 .. 🥹\n",
      "좌석이 약간 당황스러운 것 말고 다 좋았던...\n",
      "\n",
      " 6. Cat1: 기쁨 ✓ | Cat2: 만족감 ✓\n",
      "    신뢰도: Cat1=0.641, Cat2=0.773\n",
      "    텍스트: 편의점 초콜릿 중 가장 맛있는 초콜릿이라고 생각하오. 입에 넣자마자 기분 좋아지는 맛이오. \n",
      "\n",
      " 7. Cat1: 두려움 ✓ | Cat2: 놀람 ✓\n",
      "    신뢰도: Cat1=0.304, Cat2=0.517\n",
      "    텍스트: 아니 비였는데!!! 영상8도였는데!!!! 눈으로 바뀌었다니까!!!!! 내가 과몰입을 하는게 아니라!!!! 2...\n",
      "\n",
      " 8. Cat1: 두려움 ✓ | Cat2: 걱정 ✓\n",
      "    신뢰도: Cat1=0.249, Cat2=0.648\n",
      "    텍스트: 내가 아니라 네가 다칠까봐 걱정돼\n",
      "\n",
      " 9. Cat1: 슬픔 ✓ | Cat2: 후회 ✓\n",
      "    신뢰도: Cat1=0.476, Cat2=0.167\n",
      "    텍스트: 너랑 또 그렇게 헤어지기 싫어 그때로 충분해\n",
      "\n",
      "10. Cat1: 욕망 ✓ | Cat2: 욕심 ✓\n",
      "    신뢰도: Cat1=0.706, Cat2=0.293\n",
      "    텍스트: 유주언니 환연고정 패널로 섭외해야 한다고 봄\n",
      "제발요 내가 하고 싶은 말 유주언니가 다 해주심\n",
      "\n",
      "\n",
      "❌ 두 카테고리 모두 틀린 샘플들 (처음 10개):\n",
      "====================================================================================================\n",
      " 1. Cat1: 슬픔 → 싫어함(상태) | Cat2: 무기력 → 난처함\n",
      "    신뢰도: Cat1=0.428, Cat2=0.295\n",
      "    텍스트: 요즘 번아웃도 자꾸 올라오고 무기력해서 종강하고 교류하기도 버거운 상태가 와부렀으요ㅠㅠ \n",
      "\n",
      " 2. Cat1: 기쁨 → 미움(상대방) | Cat2: 즐거움 → 비위상함\n",
      "    신뢰도: Cat1=0.515, Cat2=0.677\n",
      "    텍스트: 크라임씬 장똥민이 범행 도구 찾으려고 화장실 탱크 뒤지는데 거기에 진짜 똥 넣어놓은 거 진짜 웃겨 뒤지겠음ㅋ...\n",
      "\n",
      " 3. Cat1: 싫어함(상태) → 슬픔 | Cat2: 답답함 → 무기력\n",
      "    신뢰도: Cat1=0.476, Cat2=0.244\n",
      "    텍스트: 가슴이 답답해짐 진짜 개답답해짐\n",
      "우리진짜투표잘하자\n",
      "\n",
      " 4. Cat1: 기쁨 → 욕망 | Cat2: 만족감 → 욕심\n",
      "    신뢰도: Cat1=0.463, Cat2=0.417\n",
      "    텍스트: 지그재그랑 에이블리랑 할인 대결하나\n",
      "아 흐뭇해\n",
      "계속되길...\n",
      "영원히....\n",
      "\n",
      " 5. Cat1: 기쁨 → 욕망 | Cat2: 자랑스러움 → 욕심\n",
      "    신뢰도: Cat1=0.798, Cat2=0.434\n",
      "    텍스트: 첨으로 수제 초콜릿 만듬\n",
      "초콜릿을 5시간이나 만드는 사람이 있다??? 그게 바로 나\n",
      "\n",
      " 6. Cat1: 슬픔 → 기쁨 | Cat2: 절망 → 기대감\n",
      "    신뢰도: Cat1=0.689, Cat2=0.471\n",
      "    텍스트: 단톡방에 공지들 슬슬 올라오는거 보니까 곧 개강이라는게 실감나서 갑자기 재기하고싶고 인생이 다 끝난거처럼 암...\n",
      "\n",
      " 7. Cat1: 미움(상대방) → 분노 | Cat2: 치사함 → 원망\n",
      "    신뢰도: Cat1=0.667, Cat2=0.336\n",
      "    텍스트: 미친새끼 4강전만 안좋았던거 아니고 그전부터 안좋았던걸 사람들이 다봤는데 지 책임 없다고 쏙 빠져나가려고 지...\n",
      "\n",
      " 8. Cat1: 두려움 → 싫어함(상태) | Cat2: 걱정 → 답답함\n",
      "    신뢰도: Cat1=0.518, Cat2=0.882\n",
      "    텍스트: 나 현장에서 엄청 헤맬 거 같은데 ㅠ\n",
      "\n",
      " 9. Cat1: 수치심 → 욕망 | Cat2: 부끄러움 → 궁금함\n",
      "    신뢰도: Cat1=0.500, Cat2=0.817\n",
      "    텍스트: 보라색 교복 치니까 이런거만 뜨는데 지금 이걸 입으라는거예요?\n",
      "\n",
      "10. Cat1: 분노 → 미움(상대방) | Cat2: 불쾌 → 치사함\n",
      "    신뢰도: Cat1=0.465, Cat2=0.450\n",
      "    텍스트: 그냥 국대 제외 아무도 몰랐어야 할 사실을 알게 돼서 이 꼬락서니 난 게 짜증남\n",
      "\n",
      "\n",
      "⚖️ 중립 데이터 분석 (Category1):\n",
      "------------------------------------------------------------\n",
      "중립 데이터 총 5개 중 0개 정답 (0.0%)\n",
      "\n",
      "중립 샘플 예측 결과 (처음 5개):\n",
      "1. ❌ 예측: 욕망 (신뢰도: 0.667)\n",
      "   텍스트: 가면 쓴 사람의 의상이 일본군 제복에서 바뀌었네요 옛날처럼 일본내 성적만 올리면 그만이던 ...\n",
      "2. ❌ 예측: 기쁨 (신뢰도: 0.337)\n",
      "   텍스트: 살인자ㅇ난감 살인장면중 가장 새롭고 신선한 연출이라 감독님이 말한 팝하다는 연출 뭔지 알꺼...\n",
      "3. ❌ 예측: 기쁨 (신뢰도: 0.912)\n",
      "   텍스트: 100일도안된 아기꺼 한복이 있다는게 놀랍다\n",
      "4. ❌ 예측: 미움(상대방) (신뢰도: 0.424)\n",
      "   텍스트: 잘만 물던 쪽쪽이를 하루 아침에 거부하니 엄마는 당황스럽다\n",
      "5. ❌ 예측: 기쁨 (신뢰도: 0.771)\n",
      "   텍스트: 나만 놀라운 건가요? 몰입을 쓰신 황농문교수님께 메일보냈다는 것!?? 대단한 행동력이시네요...\n",
      "\n",
      "🔥 결론:\n",
      "이 파이프라인에서 두 카테고리가 모두 정확하게 예측된 경우는 전체의 22.44%입니다.\n",
      "※ Category1은 중립을 포함하여 평가, Category2는 중립이 없어 일치합니다.\n"
     ]
    }
   ],
   "source": [
    "# 11. 파이프라인으로 test_data 평가 (두 카테고리 모두 맞은 경우만 정답 처리)\n",
    "\n",
    "print(\"🎯 파이프라인으로 test_data 종합 평가\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# test_data 준비\n",
    "test_texts = test_data['context'].fillna('').astype(str).tolist()\n",
    "test_true_cat1 = test_data['category1'].values\n",
    "test_true_cat2 = test_data['category2'].values\n",
    "\n",
    "print(f\"평가 데이터: {len(test_texts)}개\")\n",
    "print(f\"Category1 클래스 수: {len(np.unique(test_true_cat1))}\")\n",
    "print(f\"Category2 클래스 수: {len(np.unique(test_true_cat2))}\")\n",
    "\n",
    "# 중립 데이터 확인\n",
    "neutral_cat1_count = (test_true_cat1 == '중립').sum()\n",
    "neutral_cat2_count = (test_true_cat2 == '중립').sum()\n",
    "print(f\"테스트 데이터 중립: Category1={neutral_cat1_count}개, Category2={neutral_cat2_count}개\")\n",
    "\n",
    "# 파이프라인으로 종합 평가 실행 (모든 데이터 사용 - Category1에 중립 포함)\n",
    "print(f\"\\n🔄 파이프라인 평가 실행 중...\")\n",
    "print(f\"Category1: 중립 포함하여 평가\")\n",
    "print(f\"Category2: 중립 없음 (테스트 데이터에도 없음)\")\n",
    "\n",
    "evaluation_results = pipeline.evaluate_with_ground_truth(\n",
    "    test_texts, test_true_cat1, test_true_cat2\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"\\n📊 파이프라인 종합 평가 결과:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"전체 테스트 샘플 수: {evaluation_results['total_samples']}\")\n",
    "print(f\"\")\n",
    "print(f\"📈 개별 정확도:\")\n",
    "print(f\"  Category1 정확도: {evaluation_results['category1_accuracy']:.4f} ({evaluation_results['category1_correct_count']}/{evaluation_results['total_samples']})\")\n",
    "print(f\"  Category2 정확도: {evaluation_results['category2_accuracy']:.4f} ({evaluation_results['category2_correct_count']}/{evaluation_results['total_samples']})\")\n",
    "print(f\"\")\n",
    "print(f\"🎯 핵심 지표 - 두 카테고리 모두 정답:\")\n",
    "print(f\"  종합 정확도: {evaluation_results['both_correct_accuracy']:.4f} ({evaluation_results['both_correct_count']}/{evaluation_results['total_samples']})\")\n",
    "print(f\"  종합 정확도: {evaluation_results['both_correct_accuracy']*100:.2f}%\")\n",
    "\n",
    "# 상세 분석\n",
    "print(f\"\\n🔍 상세 분석:\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# 카테고리별 매치 패턴 분석\n",
    "both_correct = sum(1 for r in evaluation_results['detailed_results'] if r['both_correct'])\n",
    "only_cat1_correct = sum(1 for r in evaluation_results['detailed_results'] if r['cat1_match'] and not r['cat2_match'])\n",
    "only_cat2_correct = sum(1 for r in evaluation_results['detailed_results'] if not r['cat1_match'] and r['cat2_match'])\n",
    "both_wrong = sum(1 for r in evaluation_results['detailed_results'] if not r['cat1_match'] and not r['cat2_match'])\n",
    "\n",
    "print(f\"두 카테고리 모두 정답: {both_correct}개 ({both_correct/evaluation_results['total_samples']*100:.2f}%)\")\n",
    "print(f\"Category1만 정답: {only_cat1_correct}개 ({only_cat1_correct/evaluation_results['total_samples']*100:.2f}%)\")\n",
    "print(f\"Category2만 정답: {only_cat2_correct}개 ({only_cat2_correct/evaluation_results['total_samples']*100:.2f}%)\")\n",
    "print(f\"둘 다 틀림: {both_wrong}개 ({both_wrong/evaluation_results['total_samples']*100:.2f}%)\")\n",
    "\n",
    "# 샘플 출력 - 두 카테고리 모두 맞은 케이스\n",
    "print(f\"\\n✅ 두 카테고리 모두 정답인 샘플들 (처음 10개):\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "correct_samples = [r for r in evaluation_results['detailed_results'] if r['both_correct']]\n",
    "for i, result in enumerate(correct_samples[:10]):\n",
    "    text = result['text'][:60] + \"...\" if len(result['text']) > 60 else result['text']\n",
    "    print(f\"{i+1:2d}. Cat1: {result['actual_cat1']} ✓ | Cat2: {result['actual_cat2']} ✓\")\n",
    "    print(f\"    신뢰도: Cat1={result['cat1_confidence']:.3f}, Cat2={result['cat2_confidence']:.3f}\")\n",
    "    print(f\"    텍스트: {text}\")\n",
    "    print()\n",
    "\n",
    "# 샘플 출력 - 둘 다 틀린 케이스  \n",
    "print(f\"\\n❌ 두 카테고리 모두 틀린 샘플들 (처음 10개):\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "wrong_samples = [r for r in evaluation_results['detailed_results'] if not r['both_correct'] and not r['cat1_match'] and not r['cat2_match']]\n",
    "for i, result in enumerate(wrong_samples[:10]):\n",
    "    text = result['text'][:60] + \"...\" if len(result['text']) > 60 else result['text']\n",
    "    print(f\"{i+1:2d}. Cat1: {result['actual_cat1']} → {result['predicted_cat1']} | Cat2: {result['actual_cat2']} → {result['predicted_cat2']}\")\n",
    "    print(f\"    신뢰도: Cat1={result['cat1_confidence']:.3f}, Cat2={result['cat2_confidence']:.3f}\")\n",
    "    print(f\"    텍스트: {text}\")\n",
    "    print()\n",
    "\n",
    "# 중립 데이터 특별 분석\n",
    "print(f\"\\n⚖️ 중립 데이터 분석 (Category1):\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "neutral_results = [r for r in evaluation_results['detailed_results'] if r['actual_cat1'] == '중립']\n",
    "if len(neutral_results) > 0:\n",
    "    neutral_correct = sum(1 for r in neutral_results if r['cat1_match'])\n",
    "    print(f\"중립 데이터 총 {len(neutral_results)}개 중 {neutral_correct}개 정답 ({neutral_correct/len(neutral_results)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n중립 샘플 예측 결과 (처음 5개):\")\n",
    "    for i, result in enumerate(neutral_results[:5]):\n",
    "        text = result['text'][:50] + \"...\" if len(result['text']) > 50 else result['text']\n",
    "        status = \"✅\" if result['cat1_match'] else \"❌\"\n",
    "        print(f\"{i+1}. {status} 예측: {result['predicted_cat1']} (신뢰도: {result['cat1_confidence']:.3f})\")\n",
    "        print(f\"   텍스트: {text}\")\n",
    "else:\n",
    "    print(\"테스트 데이터에 중립이 없습니다.\")\n",
    "\n",
    "print(f\"\\n🔥 결론:\")\n",
    "print(f\"이 파이프라인에서 두 카테고리가 모두 정확하게 예측된 경우는 전체의 {evaluation_results['both_correct_accuracy']*100:.2f}%입니다.\")\n",
    "print(f\"※ Category1은 중립을 포함하여 평가, Category2는 중립이 없어 일치합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "623b7374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 파이프라인 예측 시연\n",
      "================================================================================\n",
      "\n",
      "📝 예제 1: 친구가 생일 파티를 준비해줘서 너무 감동받았어\n",
      "------------------------------------------------------------\n",
      "🎯 예측 결과:\n",
      "  Category1: 기쁨 (신뢰도: 0.994)\n",
      "  Category2: 고마움 (신뢰도: 0.495)\n",
      "\n",
      "📝 예제 2: 시험 결과가 나쁘게 나와서 정말 실망스럽다\n",
      "------------------------------------------------------------\n",
      "🎯 예측 결과:\n",
      "  Category1: 슬픔 (신뢰도: 0.584)\n",
      "  Category2: 실망 (신뢰도: 0.804)\n",
      "\n",
      "📝 예제 3: 새로운 직장이 확정되어서 설레고 기대된다\n",
      "------------------------------------------------------------\n",
      "🎯 예측 결과:\n",
      "  Category1: 기쁨 (신뢰도: 0.983)\n",
      "  Category2: 기대감 (신뢰도: 0.978)\n",
      "\n",
      "📝 예제 4: 누군가 내 뒷담화를 하는 걸 들어서 화가 난다\n",
      "------------------------------------------------------------\n",
      "🎯 예측 결과:\n",
      "  Category1: 분노 (신뢰도: 0.578)\n",
      "  Category2: 불쾌 (신뢰도: 0.826)\n"
     ]
    }
   ],
   "source": [
    "# 12. 새로운 텍스트 예측 데모 함수\n",
    "\n",
    "def demo_pipeline_prediction():\n",
    "    \"\"\"\n",
    "    새로운 텍스트들에 대해 파이프라인 예측 시연\n",
    "    \"\"\"\n",
    "    print(\"🚀 파이프라인 예측 시연\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 예제 텍스트들\n",
    "    demo_texts = [\n",
    "        \"친구가 생일 파티를 준비해줘서 너무 감동받았어\",\n",
    "        \"시험 결과가 나쁘게 나와서 정말 실망스럽다\", \n",
    "        \"새로운 직장이 확정되어서 설레고 기대된다\",\n",
    "        \"누군가 내 뒷담화를 하는 걸 들어서 화가 난다\"\n",
    "    ]\n",
    "    \n",
    "    for i, text in enumerate(demo_texts, 1):\n",
    "        print(f\"\\n📝 예제 {i}: {text}\")\n",
    "        print(\"-\"*60)\n",
    "        \n",
    "        # 파이프라인으로 예측\n",
    "        result = pipeline.predict_single(text)\n",
    "        \n",
    "        print(f\"🎯 예측 결과:\")\n",
    "        print(f\"  Category1: {result['category1_predicted']} (신뢰도: {result['category1_confidence']:.3f})\")\n",
    "        print(f\"  Category2: {result['category2_predicted']} (신뢰도: {result['category2_confidence']:.3f})\")\n",
    "\n",
    "# 시연 실행\n",
    "demo_pipeline_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "i821u6i92xl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 PCA 차원 축소 파이프라인 평가\n",
      "================================================================================\n",
      "원본 벡터 차원: 1024\n",
      "평가할 PCA 차원: [128, 256, 512, 768]\n",
      "훈련 데이터: 3359개, 테스트 데이터: 664개\n",
      "\n",
      "\n",
      "==================== PCA 128차원 평가 ====================\n",
      "📐 PCA 128차원으로 축소 중...\n",
      "  훈련 데이터: (3359, 1024) → (3359, 128)\n",
      "  테스트 데이터: (664, 1024) → (664, 128)\n",
      "  설명 가능한 분산 비율: 0.8185 (81.85%)\n",
      "🤖 Category1 모델 훈련 중...\n",
      "  Category1 정확도: 0.5015 (50.15%)\n",
      "🤖 Category2 모델 훈련 중...\n",
      "  Category2 정확도: 0.2485 (24.85%)\n",
      "  🎯 두 카테고리 모두 정답: 152/664 (0.2289, 22.89%)\n",
      "\n",
      "==================== PCA 256차원 평가 ====================\n",
      "📐 PCA 256차원으로 축소 중...\n",
      "  훈련 데이터: (3359, 1024) → (3359, 256)\n",
      "  테스트 데이터: (664, 1024) → (664, 256)\n",
      "  설명 가능한 분산 비율: 0.9409 (94.09%)\n",
      "🤖 Category1 모델 훈련 중...\n",
      "  Category1 정확도: 0.4880 (48.80%)\n",
      "🤖 Category2 모델 훈련 중...\n",
      "  Category2 정확도: 0.2199 (21.99%)\n",
      "  🎯 두 카테고리 모두 정답: 133/664 (0.2003, 20.03%)\n",
      "\n",
      "==================== PCA 512차원 평가 ====================\n",
      "📐 PCA 512차원으로 축소 중...\n",
      "  훈련 데이터: (3359, 1024) → (3359, 512)\n",
      "  테스트 데이터: (664, 1024) → (664, 512)\n",
      "  설명 가능한 분산 비율: 0.9961 (99.61%)\n",
      "🤖 Category1 모델 훈련 중...\n",
      "  Category1 정확도: 0.4880 (48.80%)\n",
      "🤖 Category2 모델 훈련 중...\n",
      "  Category2 정확도: 0.2139 (21.39%)\n",
      "  🎯 두 카테고리 모두 정답: 130/664 (0.1958, 19.58%)\n",
      "\n",
      "==================== PCA 768차원 평가 ====================\n",
      "📐 PCA 768차원으로 축소 중...\n",
      "  훈련 데이터: (3359, 1024) → (3359, 768)\n",
      "  테스트 데이터: (664, 1024) → (664, 768)\n",
      "  설명 가능한 분산 비율: 0.9994 (99.94%)\n",
      "🤖 Category1 모델 훈련 중...\n",
      "  Category1 정확도: 0.4895 (48.95%)\n",
      "🤖 Category2 모델 훈련 중...\n",
      "  Category2 정확도: 0.2184 (21.84%)\n",
      "  🎯 두 카테고리 모두 정답: 134/664 (0.2018, 20.18%)\n",
      "\n",
      "========================= 결과 비교 분석 =========================\n",
      "PCA 차원     분산비율         Cat1 정확도     Cat2 정확도     종합 정확도      \n",
      "----------------------------------------------------------------------\n",
      "원본         100.00%      0.4880       0.2425       0.2244      \n",
      "128        81.85      % 0.5015       0.2485       0.2289      \n",
      "256        94.09      % 0.4880       0.2199       0.2003      \n",
      "512        99.61      % 0.4880       0.2139       0.1958      \n",
      "768        99.94      % 0.4895       0.2184       0.2018      \n",
      "\n",
      "🏆 성능 분석:\n",
      "  원본 (1024차원) 종합 정확도: 0.2244 (22.44%)\n",
      "  최고 PCA (128차원) 종합 정확도: 0.2289 (22.89%)\n",
      "  ✅ PCA 128차원이 원본보다 0.45%p 더 좋습니다!\n",
      "\n",
      "📊 차원별 성능 변화:\n",
      "PCA 차원  → 종합 정확도\n",
      "-------------------------\n",
      "128차원   → 0.229 |███████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░|\n",
      "256차원   → 0.200 |██████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░|\n",
      "512차원   → 0.196 |█████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░|\n",
      "768차원   → 0.202 |██████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░|\n",
      "\n",
      "🔍 최고 성능 PCA 128차원 상세 분석:\n",
      "--------------------------------------------------------------------------------\n",
      "처음 20개 샘플에서 원본과 PCA 예측 일치율: 17/20 (85.0%)\n",
      "\n",
      "원본 vs PCA 예측이 다른 샘플들 (처음 5개):\n",
      "1. 원본: ❌ | PCA: ✅\n",
      "   실제: Cat1=기쁨, Cat2=만족감\n",
      "   텍스트: 어릴 때 가 보고 빕스는 거의 처음인데(기억에 없음) 지금 딸기축제 기간이라 만족스러운 식사 하고 옴\n",
      "2. 원본: ❌ | PCA: ✅\n",
      "   실제: Cat1=싫어함(상태), Cat2=답답함\n",
      "   텍스트: 가슴이 답답해짐 진짜 개답답해짐\n",
      "우리진짜투표잘하자\n",
      "3. 원본: ✅ | PCA: ❌\n",
      "   실제: Cat1=기쁨, Cat2=만족감\n",
      "   텍스트: 우연히 보게 된 영상인데, 노래가 너무 좋아서 플리에도 추가하고, 카카오톡 프뮤로도 해놨음. 음원도 좋긴 한...\n",
      "\n",
      "💡 결론: PCA를 통한 차원 축소는 \n",
      "성능 향상에 도움이 됩니다. 계산 효율성과 성능을 모두 개선할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 13. PCA 차원 축소 파이프라인 - 두 카테고리 모두 정답 정확도 비교\n",
    "\n",
    "print(\"🔍 PCA 차원 축소 파이프라인 평가\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# PCA 차원 리스트 정의\n",
    "pca_dimensions = [128, 256, 512, 768]\n",
    "\n",
    "# 결과 저장용 딕셔너리\n",
    "pca_results = {}\n",
    "\n",
    "# 원본 벡터 크기 확인\n",
    "original_dim = X.shape[1]\n",
    "print(f\"원본 벡터 차원: {original_dim}\")\n",
    "print(f\"평가할 PCA 차원: {pca_dimensions}\")\n",
    "print(f\"훈련 데이터: {X.shape[0]}개, 테스트 데이터: {len(test_texts)}개\")\n",
    "print()\n",
    "\n",
    "# 각 PCA 차원에 대해 평가\n",
    "for n_components in pca_dimensions:\n",
    "    print(f\"\\n{'='*20} PCA {n_components}차원 평가 {'='*20}\")\n",
    "    \n",
    "    # 1. PCA 적용\n",
    "    print(f\"📐 PCA {n_components}차원으로 축소 중...\")\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    \n",
    "    # 훈련 데이터 PCA 변환\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    print(f\"  훈련 데이터: {X.shape} → {X_pca.shape}\")\n",
    "    \n",
    "    # 테스트 데이터 PCA 변환\n",
    "    test_X_pca = pca.transform(test_X)\n",
    "    print(f\"  테스트 데이터: {test_X.shape} → {test_X_pca.shape}\")\n",
    "    \n",
    "    # 설명 가능한 분산 비율\n",
    "    explained_variance = pca.explained_variance_ratio_.sum()\n",
    "    print(f\"  설명 가능한 분산 비율: {explained_variance:.4f} ({explained_variance*100:.2f}%)\")\n",
    "    \n",
    "    # 2. Category1 모델 훈련 (PCA 적용)\n",
    "    print(f\"🤖 Category1 모델 훈련 중...\")\n",
    "    cat1_model_pca = xgb.XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cat1_model_pca.fit(X_pca, y_encoded)\n",
    "    \n",
    "    # Category1 예측\n",
    "    test_y_pred_cat1_pca_encoded = cat1_model_pca.predict(test_X_pca)\n",
    "    test_y_pred_cat1_pca = le.inverse_transform(test_y_pred_cat1_pca_encoded)\n",
    "    \n",
    "    # Category1 정확도\n",
    "    cat1_accuracy_pca = (test_y_pred_cat1_pca == test_y_actual).mean()\n",
    "    print(f\"  Category1 정확도: {cat1_accuracy_pca:.4f} ({cat1_accuracy_pca*100:.2f}%)\")\n",
    "    \n",
    "    # 3. Category2 모델 훈련 (PCA 적용)\n",
    "    print(f\"🤖 Category2 모델 훈련 중...\")\n",
    "    \n",
    "    # Category1 원핫 인코딩 (PCA 적용된 예측값 사용)\n",
    "    cat1_onehot_pca = cat1_encoder.transform(test_y_pred_cat1_pca.reshape(-1, 1))\n",
    "    \n",
    "    # PCA 적용된 벡터와 Category1 원핫 결합 (훈련용)\n",
    "    y_cat1_onehot_pca = cat1_encoder.transform(y.reshape(-1, 1))\n",
    "    X_combined_pca = np.hstack([X_pca, y_cat1_onehot_pca])\n",
    "    \n",
    "    # PCA 적용된 벡터와 Category1 예측 원핫 결합 (테스트용)\n",
    "    test_X_combined_pca = np.hstack([test_X_pca, cat1_onehot_pca])\n",
    "    \n",
    "    cat2_model_pca = xgb.XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cat2_model_pca.fit(X_combined_pca, y_cat2_encoded)\n",
    "    \n",
    "    # Category2 예측\n",
    "    test_y_pred_cat2_pca_encoded = cat2_model_pca.predict(test_X_combined_pca)\n",
    "    test_y_pred_cat2_pca = le_cat2.inverse_transform(test_y_pred_cat2_pca_encoded)\n",
    "    \n",
    "    # Category2 정확도\n",
    "    cat2_accuracy_pca = (test_y_pred_cat2_pca == test_y_actual_cat2).mean()\n",
    "    print(f\"  Category2 정확도: {cat2_accuracy_pca:.4f} ({cat2_accuracy_pca*100:.2f}%)\")\n",
    "    \n",
    "    # 4. 두 카테고리 모두 정답인 경우 계산\n",
    "    both_correct_pca = (test_y_pred_cat1_pca == test_y_actual) & (test_y_pred_cat2_pca == test_y_actual_cat2)\n",
    "    both_accuracy_pca = both_correct_pca.mean()\n",
    "    both_count_pca = both_correct_pca.sum()\n",
    "    \n",
    "    print(f\"  🎯 두 카테고리 모두 정답: {both_count_pca}/{len(test_y_actual)} ({both_accuracy_pca:.4f}, {both_accuracy_pca*100:.2f}%)\")\n",
    "    \n",
    "    # 결과 저장\n",
    "    pca_results[n_components] = {\n",
    "        'explained_variance': explained_variance,\n",
    "        'cat1_accuracy': cat1_accuracy_pca,\n",
    "        'cat2_accuracy': cat2_accuracy_pca,\n",
    "        'both_accuracy': both_accuracy_pca,\n",
    "        'both_count': both_count_pca,\n",
    "        'cat1_predictions': test_y_pred_cat1_pca,\n",
    "        'cat2_predictions': test_y_pred_cat2_pca\n",
    "    }\n",
    "\n",
    "# 5. 전체 결과 비교 분석\n",
    "print(f\"\\n{'='*25} 결과 비교 분석 {'='*25}\")\n",
    "print(f\"{'PCA 차원':<10} {'분산비율':<12} {'Cat1 정확도':<12} {'Cat2 정확도':<12} {'종합 정확도':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# 원본 결과 (PCA 없음) 계산\n",
    "original_both_correct = (test_y_pred == test_y_actual) & (test_y_pred_cat2 == test_y_actual_cat2)\n",
    "original_both_accuracy = original_both_correct.mean()\n",
    "\n",
    "print(f\"{'원본':<10} {'100.00%':<12} {accuracy:<12.4f} {accuracy_cat2:<12.4f} {original_both_accuracy:<12.4f}\")\n",
    "\n",
    "# PCA 결과들\n",
    "for dim in pca_dimensions:\n",
    "    result = pca_results[dim]\n",
    "    print(f\"{dim:<10} {result['explained_variance']*100:<11.2f}% {result['cat1_accuracy']:<12.4f} {result['cat2_accuracy']:<12.4f} {result['both_accuracy']:<12.4f}\")\n",
    "\n",
    "# 6. 최고 성능 차원 찾기\n",
    "print(f\"\\n🏆 성능 분석:\")\n",
    "best_both_accuracy = max(result['both_accuracy'] for result in pca_results.values())\n",
    "best_pca_dim = max(pca_results.keys(), key=lambda k: pca_results[k]['both_accuracy'])\n",
    "\n",
    "print(f\"  원본 (1024차원) 종합 정확도: {original_both_accuracy:.4f} ({original_both_accuracy*100:.2f}%)\")\n",
    "print(f\"  최고 PCA ({best_pca_dim}차원) 종합 정확도: {best_both_accuracy:.4f} ({best_both_accuracy*100:.2f}%)\")\n",
    "\n",
    "if best_both_accuracy > original_both_accuracy:\n",
    "    improvement = (best_both_accuracy - original_both_accuracy) * 100\n",
    "    print(f\"  ✅ PCA {best_pca_dim}차원이 원본보다 {improvement:.2f}%p 더 좋습니다!\")\n",
    "else:\n",
    "    decline = (original_both_accuracy - best_both_accuracy) * 100\n",
    "    print(f\"  ⚠️ 원본이 최고 PCA보다 {decline:.2f}%p 더 좋습니다.\")\n",
    "\n",
    "# 7. 차원별 성능 변화 시각화 (텍스트)\n",
    "print(f\"\\n📊 차원별 성능 변화:\")\n",
    "print(f\"PCA 차원  → 종합 정확도\")\n",
    "print(\"-\" * 25)\n",
    "for dim in sorted(pca_dimensions):\n",
    "    result = pca_results[dim]\n",
    "    bar_length = int(result['both_accuracy'] * 50)  # 50칸 기준\n",
    "    bar = \"█\" * bar_length + \"░\" * (50 - bar_length)\n",
    "    print(f\"{dim:>3}차원   → {result['both_accuracy']:.3f} |{bar}|\")\n",
    "\n",
    "# 8. 상세 샘플 분석 (최고 성능 PCA 차원)\n",
    "print(f\"\\n🔍 최고 성능 PCA {best_pca_dim}차원 상세 분석:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "best_cat1_preds = pca_results[best_pca_dim]['cat1_predictions']\n",
    "best_cat2_preds = pca_results[best_pca_dim]['cat2_predictions']\n",
    "\n",
    "# 원본 vs PCA 예측 비교\n",
    "agreement_count = 0\n",
    "disagreement_examples = []\n",
    "\n",
    "for i in range(min(len(test_y_actual), 20)):  # 처음 20개 샘플만\n",
    "    original_both = (test_y_pred[i] == test_y_actual[i]) and (test_y_pred_cat2[i] == test_y_actual_cat2[i])\n",
    "    pca_both = (best_cat1_preds[i] == test_y_actual[i]) and (best_cat2_preds[i] == test_y_actual_cat2[i])\n",
    "    \n",
    "    if original_both == pca_both:\n",
    "        agreement_count += 1\n",
    "    else:\n",
    "        disagreement_examples.append({\n",
    "            'index': i,\n",
    "            'text': test_texts[i][:60] + \"...\" if len(test_texts[i]) > 60 else test_texts[i],\n",
    "            'actual_cat1': test_y_actual[i],\n",
    "            'actual_cat2': test_y_actual_cat2[i],\n",
    "            'original_both': original_both,\n",
    "            'pca_both': pca_both\n",
    "        })\n",
    "\n",
    "print(f\"처음 20개 샘플에서 원본과 PCA 예측 일치율: {agreement_count}/20 ({agreement_count/20*100:.1f}%)\")\n",
    "\n",
    "if disagreement_examples:\n",
    "    print(f\"\\n원본 vs PCA 예측이 다른 샘플들 (처음 5개):\")\n",
    "    for i, example in enumerate(disagreement_examples[:5]):\n",
    "        status_original = \"✅\" if example['original_both'] else \"❌\"\n",
    "        status_pca = \"✅\" if example['pca_both'] else \"❌\"\n",
    "        print(f\"{i+1}. 원본: {status_original} | PCA: {status_pca}\")\n",
    "        print(f\"   실제: Cat1={example['actual_cat1']}, Cat2={example['actual_cat2']}\")\n",
    "        print(f\"   텍스트: {example['text']}\")\n",
    "\n",
    "print(f\"\\n💡 결론: PCA를 통한 차원 축소는 \")\n",
    "if best_both_accuracy > original_both_accuracy:\n",
    "    print(\"성능 향상에 도움이 됩니다. 계산 효율성과 성능을 모두 개선할 수 있습니다.\")\n",
    "else:\n",
    "    print(\"성능을 약간 저하시키지만, 계산 효율성은 크게 개선됩니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "vb9xxoiufnl",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          16\n",
      "Memory Avail:       15.70 GB / 31.91 GB (49.2%)\n",
      "Disk Space Avail:   89.07 GB / 465.12 GB (19.1%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 AutoGluon으로 Category1 & Category2 개별 최적 모델 탐색\n",
      "================================================================================\n",
      "✅ AutoGluon 라이브러리 로드 성공\n",
      "\n",
      "📊 AutoGluon용 데이터 준비...\n",
      "훈련 데이터 크기: (3359, 1026)\n",
      "테스트 데이터 크기: (664, 1024)\n",
      "Category1 클래스 수: 10\n",
      "Category2 클래스 수: 64\n",
      "\n",
      "🤖 Category1 AutoGluon 모델 훈련 시작...\n",
      "============================================================\n",
      "Category1 모델들 훈련 중... (예상 소요시간: 3-5분)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"c:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\autogluon_category1_model\"\n",
      "Train Data Rows:    3359\n",
      "Train Data Columns: 1024\n",
      "Label Column:       category1\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 9 out of 10 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9994045846978268\n",
      "Train Data Class Count: 9\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    16070.75 MB\n",
      "\tTrain Data (Original)  Memory Usage: 26.23 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1024 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1024 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\t5.4s = Fit runtime\n",
      "\t1024 features in original data used to generate 1024 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 26.23 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.5s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 116.30s of the 174.50s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=1.80%)\n",
      "\t0.825\t = Validation score   (f1_macro)\n",
      "\t11.75s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 101.64s of the 159.83s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=2.80%)\n",
      "\t0.8157\t = Validation score   (f1_macro)\n",
      "\t75.29s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 23.27s of the 81.46s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=2.72%)\n",
      "\t0.7104\t = Validation score   (f1_macro)\n",
      "\t19.85s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 0.52s of the 58.71s of remaining time.\n",
      "\tWarning: Model is expected to require 10.7s to train, which exceeds the maximum time limit of 0.1s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 174.50s of the 57.65s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.467, 'LightGBM_BAG_L1': 0.333, 'LightGBMXT_BAG_L1': 0.2}\n",
      "\t0.8348\t = Validation score   (f1_macro)\n",
      "\t0.16s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 11 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 57.47s of the 57.46s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=1.87%)\n",
      "\t0.8343\t = Validation score   (f1_macro)\n",
      "\t14.53s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 38.90s of the 38.89s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=3.06%)\n",
      "\t0.8353\t = Validation score   (f1_macro)\n",
      "\t31.34s\t = Training   runtime\n",
      "\t0.09s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 3.02s of the 3.01s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=2.95%)\n",
      "\t0.7595\t = Validation score   (f1_macro)\n",
      "\t3.36s\t = Training   runtime\n",
      "\t0.04s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 174.50s of the -3.19s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.333, 'NeuralNetFastAI_BAG_L2': 0.333, 'LightGBMXT_BAG_L2': 0.333}\n",
      "\t0.8454\t = Validation score   (f1_macro)\n",
      "\t0.21s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 183.45s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1737.6 rows/s (1119 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\autogluon_category1_model\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Category1 AutoGluon 모델 훈련 완료!\n",
      "\n",
      "📋 Category1 모델 리더보드:\n",
      "                    model  score_val eval_metric  pred_time_val    fit_time  \\\n",
      "0     WeightedEnsemble_L3   0.845421    f1_macro       0.645323  152.975757   \n",
      "1       LightGBMXT_BAG_L2   0.835284    f1_macro       0.449279  138.235540   \n",
      "2     WeightedEnsemble_L2   0.834770    f1_macro       0.367259  107.058965   \n",
      "3  NeuralNetFastAI_BAG_L2   0.834273    f1_macro       0.558301  121.429098   \n",
      "4  NeuralNetFastAI_BAG_L1   0.824998    f1_macro       0.156036   11.753919   \n",
      "\n",
      "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                0.002001           0.207047            3       True   \n",
      "1                0.085021          31.339612            2       True   \n",
      "2                0.003001           0.163037            2       True   \n",
      "3                0.194043          14.533170            2       True   \n",
      "4                0.156036          11.753919            1       True   \n",
      "\n",
      "   fit_order  \n",
      "0          8  \n",
      "1          6  \n",
      "2          4  \n",
      "3          5  \n",
      "4          1  \n",
      "🏆 Category1 최고 모델: WeightedEnsemble_L3 (F1: 0.8454)\n",
      "\n",
      "🤖 Category2 AutoGluon 모델 훈련 시작...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          16\n",
      "Memory Avail:       14.82 GB / 31.91 GB (46.4%)\n",
      "Disk Space Avail:   88.98 GB / 465.12 GB (19.1%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category2 모델들 훈련 중... (예상 소요시간: 3-5분)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 180s\n",
      "AutoGluon will save models to \"c:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\autogluon_category2_model\"\n",
      "Train Data Rows:    3359\n",
      "Train Data Columns: 1025\n",
      "Label Column:       category2\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Train Data Class Count: 64\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15207.55 MB\n",
      "\tTrain Data (Original)  Memory Usage: 26.49 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', [])  : 1024 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\t\t('object', []) :    1 | ['predicted_category1']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', []) :    1 | ['predicted_category1']\n",
      "\t\t('float', [])    : 1024 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\t5.6s = Fit runtime\n",
      "\t1025 features in original data used to generate 1025 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 26.25 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.72s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 116.16s of the 174.28s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=1.90%)\n",
      "\t0.6369\t = Validation score   (f1_macro)\n",
      "\t12.76s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 100.64s of the 158.76s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=6.59%)\n",
      "\t0.5429\t = Validation score   (f1_macro)\n",
      "\t82.51s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 15.11s of the 73.23s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=6.50%)\n",
      "\t0.3556\t = Validation score   (f1_macro)\n",
      "\t14.4s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 174.28s of the 55.98s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.429, 'NeuralNetFastAI_BAG_L1': 0.286, 'LightGBM_BAG_L1': 0.286}\n",
      "\t0.6532\t = Validation score   (f1_macro)\n",
      "\t0.26s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 11 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 55.69s of the 55.67s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=2.09%)\n",
      "\t0.6455\t = Validation score   (f1_macro)\n",
      "\t13.58s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 39.11s of the 39.09s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=7.23%)\n",
      "\t0.5409\t = Validation score   (f1_macro)\n",
      "\t33.34s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 2.78s of the 2.77s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=7.15%)\n",
      "\t0.594\t = Validation score   (f1_macro)\n",
      "\t6.6s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 174.28s of the -6.70s of remaining time.\n",
      "\tEnsemble Weights: {'LightGBMXT_BAG_L1': 0.333, 'NeuralNetFastAI_BAG_L2': 0.25, 'LightGBM_BAG_L2': 0.25, 'NeuralNetFastAI_BAG_L1': 0.167}\n",
      "\t0.667\t = Validation score   (f1_macro)\n",
      "\t0.34s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 187.11s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1613.9 rows/s (1120 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\autogluon_category2_model\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Category2 AutoGluon 모델 훈련 완료!\n",
      "\n",
      "📋 Category2 모델 리더보드:\n",
      "                    model  score_val eval_metric  pred_time_val    fit_time  \\\n",
      "0     WeightedEnsemble_L3   0.667043    f1_macro       0.696630  130.190227   \n",
      "1     WeightedEnsemble_L2   0.653207    f1_macro       0.448575  109.940131   \n",
      "2  NeuralNetFastAI_BAG_L2   0.645488    f1_macro       0.639618  123.253865   \n",
      "3  NeuralNetFastAI_BAG_L1   0.636916    f1_macro       0.168512   12.763404   \n",
      "4         LightGBM_BAG_L2   0.593968    f1_macro       0.498585  116.274353   \n",
      "\n",
      "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                0.004001           0.339079            3       True   \n",
      "1                0.003000           0.263061            2       True   \n",
      "2                0.194044          13.576795            2       True   \n",
      "3                0.168512          12.763404            1       True   \n",
      "4                0.053010           6.597283            2       True   \n",
      "\n",
      "   fit_order  \n",
      "0          8  \n",
      "1          4  \n",
      "2          5  \n",
      "3          1  \n",
      "4          7  \n",
      "🏆 Category2 최고 모델: WeightedEnsemble_L3 (F1: 0.6670)\n",
      "\n",
      "🔄 저장된 모델 로드 및 테스트 예측\n",
      "============================================================\n",
      "AutoGluon 모델로 예측 수행...\n",
      "📈 Category1 예측 중...\n",
      "📈 Category2 예측 중...\n",
      "✅ AutoGluon 모델 예측 완료!\n",
      "\n",
      "📊 AutoGluon 모델 성능 평가\n",
      "============================================================\n",
      "Category1 정확도: 0.5226 (52.26%)\n",
      "Category2 정확도: 0.3283 (32.83%)\n",
      "\n",
      "🎯 핵심 지표 - 두 카테고리 모두 정답:\n",
      "정확도: 0.2500 (25.00%)\n",
      "정답 개수: 166/664\n",
      "\n",
      "📈 모델 성능 비교:\n",
      "------------------------------------------------------------\n",
      "모델                   Cat1 정확도     Cat2 정확도     종합 정확도       개선        \n",
      "------------------------------------------------------------\n",
      "기존 XGBoost           0.4880       0.2425       0.2244       기준        \n",
      "AutoGluon            0.5226       0.3283       0.2500       +0.0256   \n",
      "\n",
      "📋 상세 분류 성능 (Classification Report)\n",
      "================================================================================\n",
      "🔹 Category1 분류 성능:\n",
      "F1-Score (macro): 0.3853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          기쁨       0.75      0.71      0.73       188\n",
      "         두려움       0.90      0.26      0.41        72\n",
      "     미움(상대방)       0.35      0.63      0.45        43\n",
      "          분노       0.27      0.67      0.38        36\n",
      "          사랑       0.72      0.28      0.40        47\n",
      "         수치심       0.50      0.16      0.24        25\n",
      "          슬픔       0.64      0.65      0.65       117\n",
      "     싫어함(상태)       0.46      0.12      0.19        49\n",
      "          욕망       0.32      0.55      0.40        82\n",
      "          중립       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.52       664\n",
      "   macro avg       0.49      0.40      0.39       664\n",
      "weighted avg       0.60      0.52      0.52       664\n",
      "\n",
      "\n",
      "🔹 Category2 분류 성능:\n",
      "F1-Score (macro): 0.2147\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          갈등       0.00      0.00      0.00         1\n",
      "          감동       0.48      0.33      0.39        30\n",
      "          걱정       0.36      0.22      0.27        23\n",
      "          경멸       0.38      0.44      0.41        18\n",
      "         고마움       0.58      0.79      0.67        19\n",
      "          고통       0.00      0.00      0.00         9\n",
      "          공감       0.33      0.14      0.20         7\n",
      "          공포       1.00      0.06      0.11        17\n",
      "         궁금함       0.21      0.67      0.32         9\n",
      "         귀중함       0.33      0.20      0.25         5\n",
      "         그리움       0.43      0.27      0.33        11\n",
      "         기대감       0.29      0.39      0.33        18\n",
      "         난처함       0.33      0.07      0.12        14\n",
      "        날카로움       0.25      0.33      0.29         3\n",
      "          냉담       0.00      0.00      0.00         3\n",
      "        너그러움       0.00      0.00      0.00         1\n",
      "          놀람       0.54      0.42      0.47        31\n",
      "         다정함       0.40      0.22      0.29         9\n",
      "         답답함       0.62      0.28      0.38        18\n",
      "      동정(슬픔)       0.55      0.59      0.57        27\n",
      "        두근거림       0.00      0.00      0.00         2\n",
      "         만족감       0.55      0.43      0.48        49\n",
      "         매력적       0.50      0.08      0.13        13\n",
      "         무기력       0.42      0.36      0.38        14\n",
      "         미안함       0.50      0.43      0.46         7\n",
      "         반가움       0.43      0.19      0.26        16\n",
      "          반감       0.00      0.00      0.00         5\n",
      "          발열       0.00      0.00      0.00         3\n",
      "        부끄러움       0.40      0.12      0.19        16\n",
      "          불만       0.00      0.00      0.00         8\n",
      "         불신감       0.83      0.62      0.71         8\n",
      "          불쾌       0.17      0.55      0.27        20\n",
      "         불편함       0.67      0.29      0.40         7\n",
      "        비위상함       0.00      0.00      0.00         1\n",
      "         사나움       0.09      0.25      0.13         4\n",
      "         수치심       0.00      0.00      0.00         3\n",
      "         시기심       0.09      0.50      0.15         2\n",
      "         신뢰감       0.00      0.00      0.00         1\n",
      "         신명남       0.00      0.00      0.00         5\n",
      "          실망       0.25      0.31      0.28        13\n",
      "          싫증       0.00      0.00      0.00         9\n",
      "         심심함       0.00      0.00      0.00         1\n",
      "         아쉬움       0.33      0.48      0.40        33\n",
      "          아픔       0.00      0.00      0.00         3\n",
      "         안정감       0.18      0.25      0.21         8\n",
      "         억울함       0.23      0.38      0.29        13\n",
      "         외로움       0.33      0.17      0.22         6\n",
      "          외면       0.00      0.00      0.00         1\n",
      "          욕심       0.24      0.33      0.28        18\n",
      "          원망       0.00      0.00      0.00         3\n",
      "         위축감       0.00      0.00      0.00         4\n",
      "       자랑스러움       0.31      0.42      0.36        12\n",
      "         자신감       0.00      0.00      0.00         1\n",
      "          절망       0.40      0.29      0.33         7\n",
      "         죄책감       0.00      0.00      0.00         2\n",
      "         즐거움       0.41      0.48      0.44        27\n",
      "         초조함       1.00      0.40      0.57         5\n",
      "         치사함       0.04      0.20      0.07         5\n",
      "         타오름       0.00      0.00      0.00         3\n",
      "         통쾌함       0.00      0.00      0.00         1\n",
      "         편안함       0.00      0.00      0.00         4\n",
      "          허망       0.50      0.18      0.27        11\n",
      "          호감       0.45      0.50      0.48        10\n",
      "          후회       0.57      0.57      0.57         7\n",
      "\n",
      "    accuracy                           0.33       664\n",
      "   macro avg       0.27      0.22      0.21       664\n",
      "weighted avg       0.39      0.33      0.32       664\n",
      "\n",
      "\n",
      "🔍 예측 샘플 분석 (처음 15개):\n",
      "====================================================================================================\n",
      " 1. ❌ Cat1: 기쁨 → 기쁨 ✓ | Cat2: 만족감 → 즐거움 ✗\n",
      "      텍스트: 보는동안 너무 행복했고 초콜렛이 너무 먹고싶었고 티모시가 잘생겼고 울어!!하는부분이 있어서...\n",
      "\n",
      " 2. ✅ Cat1: 기쁨 → 기쁨 ✓ | Cat2: 만족감 → 만족감 ✓\n",
      "      텍스트: 어릴 때 가 보고 빕스는 거의 처음인데(기억에 없음) 지금 딸기축제 기간이라 만족스러운 식...\n",
      "\n",
      " 3. ✅ Cat1: 기쁨 → 기쁨 ✓ | Cat2: 만족감 → 만족감 ✓\n",
      "      텍스트: 미리 계좌로 환전해둔 돈을 해외에서 환전수수료 없이 인출 가능한 트레블로그라는 카드인데, ...\n",
      "\n",
      " 4. ❌ Cat1: 슬픔 → 싫어함(상태) ✗ | Cat2: 무기력 → 난처함 ✗\n",
      "      텍스트: 요즘 번아웃도 자꾸 올라오고 무기력해서 종강하고 교류하기도 버거운 상태가 와부렀으요ㅠㅠ \n",
      "\n",
      " 5. ❌ Cat1: 기쁨 → 미움(상대방) ✗ | Cat2: 즐거움 → 치사함 ✗\n",
      "      텍스트: 크라임씬 장똥민이 범행 도구 찾으려고 화장실 탱크 뒤지는데 거기에 진짜 똥 넣어놓은 거 진...\n",
      "\n",
      " 6. ❌ Cat1: 싫어함(상태) → 분노 ✗ | Cat2: 답답함 → 답답함 ✓\n",
      "      텍스트: 가슴이 답답해짐 진짜 개답답해짐\n",
      "우리진짜투표잘하자\n",
      "\n",
      " 7. ❌ Cat1: 기쁨 → 욕망 ✗ | Cat2: 만족감 → 아쉬움 ✗\n",
      "      텍스트: 지그재그랑 에이블리랑 할인 대결하나\n",
      "아 흐뭇해\n",
      "계속되길...\n",
      "영원히....\n",
      "\n",
      " 8. ❌ Cat1: 기쁨 → 욕망 ✗ | Cat2: 자랑스러움 → 욕심 ✗\n",
      "      텍스트: 첨으로 수제 초콜릿 만듬\n",
      "초콜릿을 5시간이나 만드는 사람이 있다??? 그게 바로 나\n",
      "\n",
      " 9. ❌ Cat1: 슬픔 → 슬픔 ✓ | Cat2: 절망 → 무기력 ✗\n",
      "      텍스트: 단톡방에 공지들 슬슬 올라오는거 보니까 곧 개강이라는게 실감나서 갑자기 재기하고싶고 인생이...\n",
      "\n",
      "10. ❌ Cat1: 기쁨 → 미움(상대방) ✗ | Cat2: 즐거움 → 치사함 ✗\n",
      "      텍스트: 장흥신 공손한 손가락질 개웃겨요\n",
      "애드립 미친것 같음\n",
      "\n",
      "11. ❌ Cat1: 기쁨 → 미움(상대방) ✗ | Cat2: 만족감 → 놀람 ✗\n",
      "      텍스트: 회사사람이 이 명함케이스 주면서 포장 뜯어보면 넘 구려서 깜짝 놀랄 거라고 했는데 나......\n",
      "\n",
      "12. ❌ Cat1: 미움(상대방) → 분노 ✗ | Cat2: 치사함 → 원망 ✗\n",
      "      텍스트: 미친새끼 4강전만 안좋았던거 아니고 그전부터 안좋았던걸 사람들이 다봤는데 지 책임 없다고 ...\n",
      "\n",
      "13. ❌ Cat1: 두려움 → 분노 ✗ | Cat2: 걱정 → 불쾌 ✗\n",
      "      텍스트: 나 현장에서 엄청 헤맬 거 같은데 ㅠ\n",
      "\n",
      "14. ❌ Cat1: 수치심 → 욕망 ✗ | Cat2: 부끄러움 → 궁금함 ✗\n",
      "      텍스트: 보라색 교복 치니까 이런거만 뜨는데 지금 이걸 입으라는거예요?\n",
      "\n",
      "15. ❌ Cat1: 기쁨 → 기쁨 ✓ | Cat2: 만족감 → 즐거움 ✗\n",
      "      텍스트: 우연히 보게 된 영상인데, 노래가 너무 좋아서 플리에도 추가하고, 카카오톡 프뮤로도 해놨음...\n",
      "\n",
      "\n",
      "💡 결론 및 권장사항:\n",
      "============================================================\n",
      "✅ AutoGluon 모델이 기존보다 2.56%p 향상되었습니다!\n",
      "권장사항: 새로운 모델을 사용하세요.\n",
      "\n",
      "💾 AutoGluon 모델 저장 위치:\n",
      "- Category1: autogluon_category1_model\n",
      "- Category2: autogluon_category2_model\n",
      "\n",
      "📥 모델 로드 방법:\n",
      "from autogluon.tabular import TabularPredictor\n",
      "cat1_predictor = TabularPredictor.load('autogluon_category1_model')\n",
      "cat2_predictor = TabularPredictor.load('autogluon_category2_model')\n",
      "\n",
      "🔮 새로운 데이터 예측:\n",
      "cat1_pred = cat1_predictor.predict(new_data)\n",
      "new_data_with_cat1 = new_data.copy()\n",
      "new_data_with_cat1['predicted_category1'] = cat1_pred\n",
      "cat2_pred = cat2_predictor.predict(new_data_with_cat1)\n",
      "\n",
      "🎯 최종 성과:\n",
      "두 카테고리 동시 정답률: 25.00% (166/664개)\n"
     ]
    }
   ],
   "source": [
    "# 14. AutoGluon 개별 모델 - Category1 & Category2 각각 최적 모델 훈련 및 평가\n",
    "\n",
    "print(\"🚀 AutoGluon으로 Category1 & Category2 개별 최적 모델 탐색\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    from autogluon.tabular import TabularPredictor\n",
    "    print(\"✅ AutoGluon 라이브러리 로드 성공\")\n",
    "    autogluon_available = True\n",
    "except ImportError:\n",
    "    print(\"❌ AutoGluon이 설치되지 않았습니다. 다음 명령으로 설치하세요:\")\n",
    "    print(\"pip install autogluon\")\n",
    "    autogluon_available = False\n",
    "    \n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. AutoGluon용 데이터 준비\n",
    "print(\"\\n📊 AutoGluon용 데이터 준비...\")\n",
    "\n",
    "# 훈련 데이터: 벡터만 사용 (라벨 제외)\n",
    "train_features_df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "train_features_df['category1'] = y  # re_category1 사용\n",
    "train_features_df['category2'] = data['re_category2'].values\n",
    "\n",
    "# 테스트 데이터: 벡터만\n",
    "test_features_df = pd.DataFrame(test_X, columns=[f'feature_{i}' for i in range(test_X.shape[1])])\n",
    "\n",
    "print(f\"훈련 데이터 크기: {train_features_df.shape}\")\n",
    "print(f\"테스트 데이터 크기: {test_features_df.shape}\")\n",
    "print(f\"Category1 클래스 수: {len(train_features_df['category1'].unique())}\")\n",
    "print(f\"Category2 클래스 수: {len(train_features_df['category2'].unique())}\")\n",
    "\n",
    "# 모델 저장 경로\n",
    "cat1_save_path = \"autogluon_category1_model\"\n",
    "cat2_save_path = \"autogluon_category2_model\"\n",
    "\n",
    "# 기존 모델 폴더 삭제\n",
    "for path in [cat1_save_path, cat2_save_path]:\n",
    "    if os.path.exists(path):\n",
    "        import shutil\n",
    "        shutil.rmtree(path)\n",
    "        print(f\"기존 모델 폴더 {path} 삭제됨\")\n",
    "\n",
    "# 2. Category1 모델 훈련\n",
    "print(f\"\\n🤖 Category1 AutoGluon 모델 훈련 시작...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cat1_predictor = None\n",
    "if autogluon_available:\n",
    "    try:\n",
    "        # Category1 예측기 생성\n",
    "        cat1_predictor = TabularPredictor(\n",
    "            label='category1',\n",
    "            path=cat1_save_path,\n",
    "            eval_metric='f1_macro',\n",
    "            problem_type='multiclass'\n",
    "        )\n",
    "        \n",
    "        # 모델 훈련\n",
    "        print(\"Category1 모델들 훈련 중... (예상 소요시간: 3-5분)\")\n",
    "        cat1_predictor = cat1_predictor.fit(\n",
    "            train_data=train_features_df.drop(['category2'], axis=1),\n",
    "            time_limit=180,  # 3분\n",
    "            presets='medium_quality_faster_train',\n",
    "            num_bag_folds=3,\n",
    "            num_bag_sets=1,\n",
    "            num_stack_levels=1\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Category1 AutoGluon 모델 훈련 완료!\")\n",
    "        \n",
    "        # Category1 리더보드\n",
    "        print(f\"\\n📋 Category1 모델 리더보드:\")\n",
    "        cat1_leaderboard = cat1_predictor.leaderboard()\n",
    "        print(cat1_leaderboard.head())\n",
    "        \n",
    "        cat1_best_model = cat1_leaderboard.iloc[0]['model']\n",
    "        cat1_best_score = cat1_leaderboard.iloc[0]['score_val']\n",
    "        print(f\"🏆 Category1 최고 모델: {cat1_best_model} (F1: {cat1_best_score:.4f})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Category1 AutoGluon 훈련 실패: {str(e)}\")\n",
    "        cat1_predictor = None\n",
    "\n",
    "# 3. Category2 모델 훈련\n",
    "print(f\"\\n🤖 Category2 AutoGluon 모델 훈련 시작...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cat2_predictor = None\n",
    "if autogluon_available:\n",
    "    try:\n",
    "        # Category2 예측기 생성\n",
    "        cat2_predictor = TabularPredictor(\n",
    "            label='category2',\n",
    "            path=cat2_save_path,\n",
    "            eval_metric='f1_macro',\n",
    "            problem_type='multiclass'\n",
    "        )\n",
    "        \n",
    "        # Category1 예측값을 특성으로 추가 (기존 파이프라인과 동일한 방식)\n",
    "        if cat1_predictor is not None:\n",
    "            # 훈련 데이터에 Category1 예측값 추가\n",
    "            train_cat1_pred = cat1_predictor.predict(train_features_df.drop(['category1', 'category2'], axis=1))\n",
    "            train_enhanced_df = train_features_df.drop(['category1'], axis=1).copy()\n",
    "            train_enhanced_df['predicted_category1'] = train_cat1_pred\n",
    "        else:\n",
    "            # Category1 예측기가 없으면 실제 Category1 값 사용\n",
    "            train_enhanced_df = train_features_df.drop(['category1'], axis=1).copy()\n",
    "            train_enhanced_df['predicted_category1'] = train_features_df['category1']\n",
    "        \n",
    "        # 모델 훈련\n",
    "        print(\"Category2 모델들 훈련 중... (예상 소요시간: 3-5분)\")\n",
    "        cat2_predictor = cat2_predictor.fit(\n",
    "            train_data=train_enhanced_df,\n",
    "            time_limit=180,  # 3분\n",
    "            presets='medium_quality_faster_train',\n",
    "            num_bag_folds=3,\n",
    "            num_bag_sets=1,\n",
    "            num_stack_levels=1\n",
    "        )\n",
    "        \n",
    "        print(\"✅ Category2 AutoGluon 모델 훈련 완료!\")\n",
    "        \n",
    "        # Category2 리더보드\n",
    "        print(f\"\\n📋 Category2 모델 리더보드:\")\n",
    "        cat2_leaderboard = cat2_predictor.leaderboard()\n",
    "        print(cat2_leaderboard.head())\n",
    "        \n",
    "        cat2_best_model = cat2_leaderboard.iloc[0]['model']\n",
    "        cat2_best_score = cat2_leaderboard.iloc[0]['score_val']\n",
    "        print(f\"🏆 Category2 최고 모델: {cat2_best_model} (F1: {cat2_best_score:.4f})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Category2 AutoGluon 훈련 실패: {str(e)}\")\n",
    "        cat2_predictor = None\n",
    "\n",
    "# 4. XGBoost 대안 모델 (AutoGluon 실패시)\n",
    "if not autogluon_available or cat1_predictor is None or cat2_predictor is None:\n",
    "    print(f\"\\n🔄 XGBoost 대안 모델로 진행...\")\n",
    "    \n",
    "    # Category1 XGBoost 모델\n",
    "    print(\"Category1 XGBoost 모델 훈련...\")\n",
    "    cat1_xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=10,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    cat1_xgb_model.fit(X, y_encoded)\n",
    "    \n",
    "    # Category2 XGBoost 모델 (Category1 포함)\n",
    "    print(\"Category2 XGBoost 모델 훈련...\")\n",
    "    y_cat1_onehot_xgb = cat1_encoder.transform(y.reshape(-1, 1))\n",
    "    X_combined_xgb = np.hstack([X, y_cat1_onehot_xgb])\n",
    "    \n",
    "    cat2_xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=10,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    cat2_xgb_model.fit(X_combined_xgb, y_cat2_encoded)\n",
    "    \n",
    "    print(\"✅ XGBoost 대안 모델 훈련 완료!\")\n",
    "\n",
    "# 5. 모델 로드 및 테스트 예측 시뮬레이션\n",
    "print(f\"\\n🔄 저장된 모델 로드 및 테스트 예측\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 실제로는 다음과 같이 로드할 수 있습니다:\n",
    "# cat1_loaded_predictor = TabularPredictor.load(cat1_save_path)\n",
    "# cat2_loaded_predictor = TabularPredictor.load(cat2_save_path)\n",
    "\n",
    "if autogluon_available and cat1_predictor is not None and cat2_predictor is not None:\n",
    "    print(\"AutoGluon 모델로 예측 수행...\")\n",
    "    \n",
    "    # Category1 예측\n",
    "    print(\"📈 Category1 예측 중...\")\n",
    "    test_pred_cat1_ag = cat1_predictor.predict(test_features_df)\n",
    "    test_pred_cat1_proba = cat1_predictor.predict_proba(test_features_df)\n",
    "    \n",
    "    # Category2 예측 (Category1 예측값 포함)\n",
    "    print(\"📈 Category2 예측 중...\")\n",
    "    test_enhanced_df = test_features_df.copy()\n",
    "    test_enhanced_df['predicted_category1'] = test_pred_cat1_ag\n",
    "    test_pred_cat2_ag = cat2_predictor.predict(test_enhanced_df)\n",
    "    test_pred_cat2_proba = cat2_predictor.predict_proba(test_enhanced_df)\n",
    "    \n",
    "    model_type = \"AutoGluon\"\n",
    "    \n",
    "else:\n",
    "    print(\"XGBoost 모델로 예측 수행...\")\n",
    "    \n",
    "    # Category1 예측 (XGBoost)\n",
    "    test_pred_cat1_encoded_ag = cat1_xgb_model.predict(test_X)\n",
    "    test_pred_cat1_ag = le.inverse_transform(test_pred_cat1_encoded_ag)\n",
    "    \n",
    "    # Category2 예측 (XGBoost)\n",
    "    test_cat1_onehot_ag = cat1_encoder.transform(test_pred_cat1_ag.reshape(-1, 1))\n",
    "    test_X_combined_ag = np.hstack([test_X, test_cat1_onehot_ag])\n",
    "    test_pred_cat2_encoded_ag = cat2_xgb_model.predict(test_X_combined_ag)\n",
    "    test_pred_cat2_ag = le_cat2.inverse_transform(test_pred_cat2_encoded_ag)\n",
    "    \n",
    "    model_type = \"XGBoost 고성능\"\n",
    "\n",
    "print(f\"✅ {model_type} 모델 예측 완료!\")\n",
    "\n",
    "# 6. 성능 평가 - 기존 파이프라인과 동일한 방식\n",
    "print(f\"\\n📊 {model_type} 모델 성능 평가\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 개별 카테고리 정확도\n",
    "cat1_accuracy_ag = (test_pred_cat1_ag == test_y_actual).mean()\n",
    "cat2_accuracy_ag = (test_pred_cat2_ag == test_y_actual_cat2).mean()\n",
    "\n",
    "print(f\"Category1 정확도: {cat1_accuracy_ag:.4f} ({cat1_accuracy_ag*100:.2f}%)\")\n",
    "print(f\"Category2 정확도: {cat2_accuracy_ag:.4f} ({cat2_accuracy_ag*100:.2f}%)\")\n",
    "\n",
    "# 🎯 핵심 지표: 두 카테고리 모두 정답\n",
    "both_correct_ag = (test_pred_cat1_ag == test_y_actual) & (test_pred_cat2_ag == test_y_actual_cat2)\n",
    "both_accuracy_ag = both_correct_ag.mean()\n",
    "both_count_ag = both_correct_ag.sum()\n",
    "\n",
    "print(f\"\\n🎯 핵심 지표 - 두 카테고리 모두 정답:\")\n",
    "print(f\"정확도: {both_accuracy_ag:.4f} ({both_accuracy_ag*100:.2f}%)\")\n",
    "print(f\"정답 개수: {both_count_ag}/{len(test_y_actual)}\")\n",
    "\n",
    "# 7. 기존 파이프라인과 성능 비교\n",
    "print(f\"\\n📈 모델 성능 비교:\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'모델':<20} {'Cat1 정확도':<12} {'Cat2 정확도':<12} {'종합 정확도':<12} {'개선':<10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# 기존 결과 계산\n",
    "original_both_correct = (test_y_pred == test_y_actual) & (test_y_pred_cat2 == test_y_actual_cat2)\n",
    "original_both_accuracy = original_both_correct.mean()\n",
    "\n",
    "print(f\"{'기존 XGBoost':<20} {accuracy:<12.4f} {accuracy_cat2:<12.4f} {original_both_accuracy:<12.4f} {'기준':<10}\")\n",
    "\n",
    "# AutoGluon/XGBoost 고성능 결과\n",
    "improvement = both_accuracy_ag - original_both_accuracy\n",
    "improvement_text = f\"+{improvement:.4f}\" if improvement > 0 else f\"{improvement:.4f}\"\n",
    "\n",
    "print(f\"{model_type:<20} {cat1_accuracy_ag:<12.4f} {cat2_accuracy_ag:<12.4f} {both_accuracy_ag:<12.4f} {improvement_text:<10}\")\n",
    "\n",
    "# 8. 상세 분류 성능 분석\n",
    "print(f\"\\n📋 상세 분류 성능 (Classification Report)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Category1 분류 리포트\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "print(\"🔹 Category1 분류 성능:\")\n",
    "cat1_f1 = f1_score(test_y_actual, test_pred_cat1_ag, average='macro')\n",
    "print(f\"F1-Score (macro): {cat1_f1:.4f}\")\n",
    "cat1_report = classification_report(test_y_actual, test_pred_cat1_ag)\n",
    "print(cat1_report)\n",
    "\n",
    "print(\"\\n🔹 Category2 분류 성능:\")\n",
    "cat2_f1 = f1_score(test_y_actual_cat2, test_pred_cat2_ag, average='macro')\n",
    "print(f\"F1-Score (macro): {cat2_f1:.4f}\")\n",
    "cat2_report = classification_report(test_y_actual_cat2, test_pred_cat2_ag)\n",
    "print(cat2_report)\n",
    "\n",
    "# 9. 예측 샘플 분석\n",
    "print(f\"\\n🔍 예측 샘플 분석 (처음 15개):\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for i in range(min(15, len(test_y_actual))):\n",
    "    text = test_texts[i][:50] + \"...\" if len(test_texts[i]) > 50 else test_texts[i]\n",
    "    \n",
    "    actual_cat1 = test_y_actual[i]\n",
    "    actual_cat2 = test_y_actual_cat2[i]\n",
    "    pred_cat1 = test_pred_cat1_ag[i]\n",
    "    pred_cat2 = test_pred_cat2_ag[i]\n",
    "    \n",
    "    cat1_match = actual_cat1 == pred_cat1\n",
    "    cat2_match = actual_cat2 == pred_cat2\n",
    "    both_match = cat1_match and cat2_match\n",
    "    \n",
    "    status = \"✅\" if both_match else \"❌\"\n",
    "    cat1_status = \"✓\" if cat1_match else \"✗\"\n",
    "    cat2_status = \"✓\" if cat2_match else \"✗\"\n",
    "    \n",
    "    print(f\"{i+1:2d}. {status} Cat1: {actual_cat1} → {pred_cat1} {cat1_status} | Cat2: {actual_cat2} → {pred_cat2} {cat2_status}\")\n",
    "    print(f\"      텍스트: {text}\")\n",
    "    print()\n",
    "\n",
    "# 10. 결론 및 모델 저장 정보\n",
    "print(f\"\\n💡 결론 및 권장사항:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if improvement > 0.01:\n",
    "    print(f\"✅ {model_type} 모델이 기존보다 {improvement*100:.2f}%p 향상되었습니다!\")\n",
    "    print(\"권장사항: 새로운 모델을 사용하세요.\")\n",
    "elif improvement > -0.01:\n",
    "    print(f\"📊 {model_type} 모델과 기존 모델이 유사합니다 (차이: {abs(improvement)*100:.2f}%p).\")\n",
    "    print(\"권장사항: 계산 효율성을 고려하여 선택하세요.\")\n",
    "else:\n",
    "    print(f\"⚠️ 기존 모델이 {abs(improvement)*100:.2f}%p 더 좋습니다.\")\n",
    "    print(\"권장사항: 기존 모델을 유지하거나 하이퍼파라미터를 조정하세요.\")\n",
    "\n",
    "if autogluon_available and cat1_predictor is not None and cat2_predictor is not None:\n",
    "    print(f\"\\n💾 AutoGluon 모델 저장 위치:\")\n",
    "    print(f\"- Category1: {cat1_save_path}\")\n",
    "    print(f\"- Category2: {cat2_save_path}\")\n",
    "    print(f\"\\n📥 모델 로드 방법:\")\n",
    "    print(f\"from autogluon.tabular import TabularPredictor\")\n",
    "    print(f\"cat1_predictor = TabularPredictor.load('{cat1_save_path}')\")\n",
    "    print(f\"cat2_predictor = TabularPredictor.load('{cat2_save_path}')\")\n",
    "    print(f\"\\n🔮 새로운 데이터 예측:\")\n",
    "    print(f\"cat1_pred = cat1_predictor.predict(new_data)\")\n",
    "    print(f\"new_data_with_cat1 = new_data.copy()\")\n",
    "    print(f\"new_data_with_cat1['predicted_category1'] = cat1_pred\")\n",
    "    print(f\"cat2_pred = cat2_predictor.predict(new_data_with_cat1)\")\n",
    "else:\n",
    "    print(f\"\\n⚙️ XGBoost 모델이 메모리에 저장되어 있습니다.\")\n",
    "    print(f\"필요시 pickle을 사용하여 저장할 수 있습니다.\")\n",
    "\n",
    "print(f\"\\n🎯 최종 성과:\")\n",
    "print(f\"두 카테고리 동시 정답률: {both_accuracy_ag*100:.2f}% ({both_count_ag}/{len(test_y_actual)}개)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ave9ukmaybv",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preset alias specified: 'medium_quality_faster_train' maps to 'medium_quality'.\n",
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          16\n",
      "Memory Avail:       14.01 GB / 31.91 GB (43.9%)\n",
      "Disk Space Avail:   87.85 GB / 465.12 GB (18.9%)\n",
      "===================================================\n",
      "Presets specified: ['medium_quality_faster_train']\n",
      "Using hyperparameters preset: hyperparameters='default'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔗 AutoGluon 복합 라벨 방식 - 카테고리 조합 예측\n",
      "================================================================================\n",
      "✅ AutoGluon 라이브러리 로드 성공\n",
      "\n",
      "📊 복합 라벨 데이터 준비...\n",
      "훈련 데이터 크기: (3359, 1027)\n",
      "테스트 데이터 크기: (664, 1027)\n",
      "복합 라벨 종류: 77개\n",
      "\n",
      "📈 복합 라벨 상위 15개 분포:\n",
      "combined_label\n",
      "슬픔_무기력      98\n",
      "수치심_부끄러움    96\n",
      "기쁨_편안함      92\n",
      "슬픔_외로움      90\n",
      "두려움_놀람      84\n",
      "슬픔_허망       78\n",
      "기쁨_안정감      78\n",
      "기쁨_공감       77\n",
      "기쁨_기대감      77\n",
      "분노_불쾌       72\n",
      "사랑_두근거림     71\n",
      "슬픔_그리움      67\n",
      "기쁨_감동       67\n",
      "사랑_다정함      65\n",
      "기쁨_고마움      64\n",
      "Name: count, dtype: int64\n",
      "\n",
      "⚠️ 희소한 라벨 (8개): ['중립_공감', '수치심_수치심', '기쁨_귀중함', '미움(상대방)_불쾌', '슬픔_죄책감', '슬픔_답답함', '사랑_공감', '슬픔_공감']\n",
      "이러한 라벨들은 훈련이 어려울 수 있습니다.\n",
      "\n",
      "🤖 복합 라벨 AutoGluon 모델 훈련 시작...\n",
      "============================================================\n",
      "복합 라벨 모델들 훈련 중... (예상 소요 시간: 5-10분)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Beginning AutoGluon training ... Time limit = 300s\n",
      "AutoGluon will save models to \"c:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\autogluon_combined_label_model\"\n",
      "Train Data Rows:    3359\n",
      "Train Data Columns: 1024\n",
      "Label Column:       combined_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 67 out of 77 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.993450431676094\n",
      "Train Data Class Count: 67\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    14305.22 MB\n",
      "\tTrain Data (Original)  Memory Usage: 26.07 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1024 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1024 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\t5.2s = Fit runtime\n",
      "\t1024 features in original data used to generate 1024 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 26.07 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.37s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "AutoGluon will fit 2 stack levels (L1 to L2) ...\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 196.37s of the 294.62s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=2.07%)\n",
      "\t0.5921\t = Validation score   (f1_macro)\n",
      "\t14.01s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 178.39s of the 276.64s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=7.34%)\n",
      "\t0.4963\t = Validation score   (f1_macro)\n",
      "\t144.92s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 30.09s of the 128.34s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=6.78%)\n",
      "\t0.3124\t = Validation score   (f1_macro)\n",
      "\t26.62s\t = Training   runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 0.47s of the 98.72s of remaining time.\n",
      "\tWarning: Model is expected to require 26.4s to train, which exceeds the maximum time limit of 0.0s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestGini_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 294.63s of the 97.45s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.75, 'LightGBM_BAG_L1': 0.188, 'LightGBMXT_BAG_L1': 0.062}\n",
      "\t0.5928\t = Validation score   (f1_macro)\n",
      "\t0.28s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Fitting 11 L2 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ... Training model for up to 97.13s of the 97.12s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=2.19%)\n",
      "\t0.6119\t = Validation score   (f1_macro)\n",
      "\t13.61s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L2 ... Training model for up to 80.30s of the 80.29s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=7.68%)\n",
      "\t0.5149\t = Validation score   (f1_macro)\n",
      "\t66.94s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L2 ... Training model for up to 10.10s of the 10.08s of remaining time.\n",
      "\tFitting 3 child models (S1F1 - S1F3) | Fitting with ParallelLocalFoldFittingStrategy (3 workers, per: cpus=5, gpus=0, memory=7.40%)\n",
      "\t0.5391\t = Validation score   (f1_macro)\n",
      "\t10.97s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L3 ... Training model for up to 294.63s of the -4.02s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L2': 0.458, 'LightGBMXT_BAG_L2': 0.333, 'NeuralNetFastAI_BAG_L1': 0.125, 'LightGBM_BAG_L2': 0.083}\n",
      "\t0.6228\t = Validation score   (f1_macro)\n",
      "\t0.37s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 304.47s ... Best model: WeightedEnsemble_L3 | Estimated inference throughput: 1147.3 rows/s (1113 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\autogluon_combined_label_model\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AutoGluon 복합 라벨 모델 훈련 완료!\n",
      "\n",
      "📋 복합 라벨 AutoGluon 모델 리더보드:\n",
      "                    model  score_val eval_metric  pred_time_val    fit_time  \\\n",
      "0     WeightedEnsemble_L3   0.622779    f1_macro       0.972064  277.438740   \n",
      "1  NeuralNetFastAI_BAG_L2   0.611854    f1_macro       0.776809  199.168023   \n",
      "2     WeightedEnsemble_L2   0.592764    f1_macro       0.559211  185.839937   \n",
      "3  NeuralNetFastAI_BAG_L1   0.592117    f1_macro       0.197045   14.014211   \n",
      "4         LightGBM_BAG_L2   0.539056    f1_macro       0.606224  196.524052   \n",
      "\n",
      "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                0.003000           0.368226            3       True   \n",
      "1                0.220598          13.610406            2       True   \n",
      "2                0.003000           0.282319            2       True   \n",
      "3                0.197045          14.014211            1       True   \n",
      "4                0.050013          10.966435            2       True   \n",
      "\n",
      "   fit_order  \n",
      "0          8  \n",
      "1          5  \n",
      "2          4  \n",
      "3          1  \n",
      "4          7  \n",
      "\n",
      "🏆 최고 성능 복합 모델: WeightedEnsemble_L3\n",
      "검증 F1-Score: 0.6228\n",
      "\n",
      "🎯 복합 라벨 모델 예측 수행...\n",
      "============================================================\n",
      "AutoGluon 복합 라벨 모델로 예측...\n",
      "복합 라벨을 개별 카테고리로 분리...\n",
      "✅ AutoGluon 복합 복합 라벨 예측 완료!\n",
      "\n",
      "📊 AutoGluon 복합 모델 성능 평가\n",
      "============================================================\n",
      "Category1 정확도: 0.5572 (55.72%)\n",
      "Category2 정확도: 0.3630 (36.30%)\n",
      "\n",
      "🎯 핵심 지표 - 두 카테고리 모두 정답:\n",
      "정확도: 0.3404 (34.04%)\n",
      "정답 개수: 226/664\n",
      "복합 라벨 직접 정확도: 0.3404 (34.04%)\n",
      "복합 라벨 F1-Score (macro): 0.2190\n",
      "\n",
      "📈 모델 방식 종합 비교:\n",
      "--------------------------------------------------------------------------------\n",
      "방식                   Cat1 정확도     Cat2 정확도     종합 정확도       개선        \n",
      "--------------------------------------------------------------------------------\n",
      "기존 개별 모델             0.4880       0.2425       0.2244       기준        \n",
      "AutoGluon 복합         0.5572       0.3630       0.3404       +0.1160   \n",
      "\n",
      "📋 복합 라벨 Classification Report (상위 20개 클래스):\n",
      "--------------------------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      기쁨_만족감       0.64      0.48      0.55        48\n",
      "      욕망_아쉬움       0.64      0.42      0.51        33\n",
      "       기쁨_감동       0.63      0.40      0.49        30\n",
      "      기쁨_즐거움       0.52      0.59      0.55        27\n",
      "      두려움_걱정       0.60      0.26      0.36        23\n",
      "      두려움_놀람       0.67      0.17      0.28        23\n",
      "       분노_불쾌       0.29      0.50      0.36        20\n",
      "   슬픔_동정(슬픔)       0.67      0.60      0.63        20\n",
      "      기쁨_고마움       0.62      0.84      0.71        19\n",
      " 싫어함(상태)_답답함       0.67      0.44      0.53        18\n",
      "       욕망_욕심       0.50      0.44      0.47        18\n",
      "  미움(상대방)_경멸       0.52      0.61      0.56        18\n",
      "      두려움_공포       1.00      0.29      0.45        17\n",
      "      기쁨_반가움       0.67      0.12      0.21        16\n",
      "    수치심_부끄러움       0.50      0.06      0.11        16\n",
      " 싫어함(상태)_난처함       0.20      0.07      0.11        14\n",
      "      슬픔_무기력       0.89      0.57      0.70        14\n",
      "       슬픔_실망       0.38      0.23      0.29        13\n",
      "      욕망_기대감       0.00      0.00      0.00        13\n",
      "      슬픔_억울함       0.46      0.46      0.46        13\n",
      "\n",
      "   micro avg       0.56      0.40      0.47       413\n",
      "   macro avg       0.55      0.38      0.42       413\n",
      "weighted avg       0.57      0.40      0.44       413\n",
      "\n",
      "\n",
      "🔍 복합 라벨 예측 샘플 분석 (처음 15개):\n",
      "====================================================================================================\n",
      " 1. ❌ 복합: 기쁨_만족감 → 기쁨_즐거움\n",
      "      개별: 기쁨|만족감 → 기쁨|즐거움\n",
      "      텍스트: 보는동안 너무 행복했고 초콜렛이 너무 먹고싶었고 티모시가 잘생겼고 울어!!하는부분이 있어서...\n",
      "\n",
      " 2. ✅ 복합: 기쁨_만족감 → 기쁨_만족감\n",
      "      개별: 기쁨|만족감 → 기쁨|만족감\n",
      "      텍스트: 어릴 때 가 보고 빕스는 거의 처음인데(기억에 없음) 지금 딸기축제 기간이라 만족스러운 식...\n",
      "\n",
      " 3. ✅ 복합: 기쁨_만족감 → 기쁨_만족감\n",
      "      개별: 기쁨|만족감 → 기쁨|만족감\n",
      "      텍스트: 미리 계좌로 환전해둔 돈을 해외에서 환전수수료 없이 인출 가능한 트레블로그라는 카드인데, ...\n",
      "\n",
      " 4. ✅ 복합: 슬픔_무기력 → 슬픔_무기력\n",
      "      개별: 슬픔|무기력 → 슬픔|무기력\n",
      "      텍스트: 요즘 번아웃도 자꾸 올라오고 무기력해서 종강하고 교류하기도 버거운 상태가 와부렀으요ㅠㅠ \n",
      "\n",
      " 5. ❌ 복합: 기쁨_즐거움 → 분노_불쾌\n",
      "      개별: 기쁨|즐거움 → 분노|불쾌\n",
      "      텍스트: 크라임씬 장똥민이 범행 도구 찾으려고 화장실 탱크 뒤지는데 거기에 진짜 똥 넣어놓은 거 진...\n",
      "\n",
      " 6. ✅ 복합: 싫어함(상태)_답답함 → 싫어함(상태)_답답함\n",
      "      개별: 싫어함(상태)|답답함 → 싫어함(상태)|답답함\n",
      "      텍스트: 가슴이 답답해짐 진짜 개답답해짐\n",
      "우리진짜투표잘하자\n",
      "\n",
      " 7. ❌ 복합: 기쁨_만족감 → 기쁨_즐거움\n",
      "      개별: 기쁨|만족감 → 기쁨|즐거움\n",
      "      텍스트: 지그재그랑 에이블리랑 할인 대결하나\n",
      "아 흐뭇해\n",
      "계속되길...\n",
      "영원히....\n",
      "\n",
      " 8. ❌ 복합: 기쁨_자랑스러움 → 욕망_욕심\n",
      "      개별: 기쁨|자랑스러움 → 욕망|욕심\n",
      "      텍스트: 첨으로 수제 초콜릿 만듬\n",
      "초콜릿을 5시간이나 만드는 사람이 있다??? 그게 바로 나\n",
      "\n",
      " 9. ❌ 복합: 슬픔_절망 → 슬픔_무기력\n",
      "      개별: 슬픔|절망 → 슬픔|무기력\n",
      "      텍스트: 단톡방에 공지들 슬슬 올라오는거 보니까 곧 개강이라는게 실감나서 갑자기 재기하고싶고 인생이...\n",
      "\n",
      "10. ❌ 복합: 기쁨_즐거움 → 미움(상대방)_경멸\n",
      "      개별: 기쁨|즐거움 → 미움(상대방)|경멸\n",
      "      텍스트: 장흥신 공손한 손가락질 개웃겨요\n",
      "애드립 미친것 같음\n",
      "\n",
      "11. ❌ 복합: 기쁨_만족감 → 미움(상대방)_치사함\n",
      "      개별: 기쁨|만족감 → 미움(상대방)|치사함\n",
      "      텍스트: 회사사람이 이 명함케이스 주면서 포장 뜯어보면 넘 구려서 깜짝 놀랄 거라고 했는데 나......\n",
      "\n",
      "12. ❌ 복합: 미움(상대방)_치사함 → 분노_원망\n",
      "      개별: 미움(상대방)|치사함 → 분노|원망\n",
      "      텍스트: 미친새끼 4강전만 안좋았던거 아니고 그전부터 안좋았던걸 사람들이 다봤는데 지 책임 없다고 ...\n",
      "\n",
      "13. ❌ 복합: 두려움_걱정 → 싫어함(상태)_답답함\n",
      "      개별: 두려움|걱정 → 싫어함(상태)|답답함\n",
      "      텍스트: 나 현장에서 엄청 헤맬 거 같은데 ㅠ\n",
      "\n",
      "14. ❌ 복합: 수치심_부끄러움 → 욕망_갈등\n",
      "      개별: 수치심|부끄러움 → 욕망|갈등\n",
      "      텍스트: 보라색 교복 치니까 이런거만 뜨는데 지금 이걸 입으라는거예요?\n",
      "\n",
      "15. ❌ 복합: 기쁨_만족감 → 기쁨_즐거움\n",
      "      개별: 기쁨|만족감 → 기쁨|즐거움\n",
      "      텍스트: 우연히 보게 된 영상인데, 노래가 너무 좋아서 플리에도 추가하고, 카카오톡 프뮤로도 해놨음...\n",
      "\n",
      "\n",
      "🔬 복합 라벨 방식 분석:\n",
      "============================================================\n",
      "📈 장점:\n",
      "1. 카테고리 간 의존성을 직접적으로 학습\n",
      "2. 한 번의 예측으로 두 카테고리 동시 결정\n",
      "3. 카테고리 조합의 빈도를 고려한 학습\n",
      "\n",
      "📉 단점:\n",
      "1. 희소한 조합에 대한 학습 어려움\n",
      "2. 새로운 조합 출현 시 대응 곤란\n",
      "3. 클래스 수 증가로 인한 복잡도 상승\n",
      "\n",
      "💡 복합 라벨 방식 결론:\n",
      "✅ 복합 라벨 방식이 11.60%p 향상! 카테고리 의존성이 강한 경우 효과적\n",
      "\n",
      "💾 복합 라벨 모델 저장 위치: autogluon_combined_label_model\n",
      "📥 모델 로드 방법:\n",
      "combined_predictor = TabularPredictor.load('autogluon_combined_label_model')\n",
      "combined_pred = combined_predictor.predict(new_data)\n",
      "# 복합 라벨을 개별 카테고리로 분리\n",
      "cat1_pred, cat2_pred = combined_pred.str.split('_', expand=True)[0], combined_pred.str.split('_', expand=True)[1]\n",
      "\n",
      "🎯 복합 라벨 최종 성과:\n",
      "두 카테고리 동시 정답률: 34.04% (226/664개)\n",
      "복합 라벨 직접 정확도: 34.04%\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. \n",
      "\u001b[1;31m셀의 코드를 검토하여 가능한 오류 원인을 식별하세요. \n",
      "\u001b[1;31m자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'>여기</a>를 클릭하세요. \n",
      "\u001b[1;31m자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# 15. AutoGluon 복합 라벨 방식 - 두 카테고리 조합을 하나의 라벨로 예측\n",
    "\n",
    "print(\"🔗 AutoGluon 복합 라벨 방식 - 카테고리 조합 예측\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    from autogluon.tabular import TabularPredictor\n",
    "    print(\"✅ AutoGluon 라이브러리 로드 성공\")\n",
    "    autogluon_available = True\n",
    "except ImportError:\n",
    "    print(\"❌ AutoGluon이 설치되지 않았습니다. 다음 명령으로 설치하세요:\")\n",
    "    print(\"pip install autogluon\")\n",
    "    autogluon_available = False\n",
    "    \n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. 복합 라벨 데이터 준비\n",
    "print(\"\\n📊 복합 라벨 데이터 준비...\")\n",
    "\n",
    "# 훈련 데이터: 벡터 + 복합 라벨\n",
    "train_combined_df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "train_combined_df['category1'] = y\n",
    "train_combined_df['category2'] = data['re_category2'].values\n",
    "\n",
    "# 두 카테고리를 결합한 복합 라벨 생성 (예: \"기쁨_감동\", \"슬픔_절망\")\n",
    "train_combined_df['combined_label'] = train_combined_df['category1'] + \"_\" + train_combined_df['category2']\n",
    "\n",
    "# 테스트 데이터: 벡터 + 실제 라벨  \n",
    "test_combined_df = pd.DataFrame(test_X, columns=[f'feature_{i}' for i in range(test_X.shape[1])])\n",
    "test_combined_df['category1'] = test_y_actual\n",
    "test_combined_df['category2'] = test_y_actual_cat2\n",
    "test_combined_df['combined_label'] = test_combined_df['category1'] + \"_\" + test_combined_df['category2']\n",
    "\n",
    "print(f\"훈련 데이터 크기: {train_combined_df.shape}\")\n",
    "print(f\"테스트 데이터 크기: {test_combined_df.shape}\")\n",
    "print(f\"복합 라벨 종류: {len(train_combined_df['combined_label'].unique())}개\")\n",
    "\n",
    "# 복합 라벨 분포 확인\n",
    "print(f\"\\n📈 복합 라벨 상위 15개 분포:\")\n",
    "label_counts = train_combined_df['combined_label'].value_counts()\n",
    "print(label_counts.head(15))\n",
    "\n",
    "# 희소한 라벨 확인\n",
    "rare_labels = label_counts[label_counts < 3]  # 3개 미만인 라벨\n",
    "if len(rare_labels) > 0:\n",
    "    print(f\"\\n⚠️ 희소한 라벨 ({len(rare_labels)}개): {rare_labels.index.tolist()}\")\n",
    "    print(\"이러한 라벨들은 훈련이 어려울 수 있습니다.\")\n",
    "\n",
    "# 2. 복합 라벨 AutoGluon 모델 훈련\n",
    "combined_save_path = \"autogluon_combined_label_model\"\n",
    "if os.path.exists(combined_save_path):\n",
    "    import shutil\n",
    "    shutil.rmtree(combined_save_path)\n",
    "    print(f\"기존 복합 라벨 모델 폴더 {combined_save_path} 삭제됨\")\n",
    "\n",
    "print(f\"\\n🤖 복합 라벨 AutoGluon 모델 훈련 시작...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "combined_predictor = None\n",
    "if autogluon_available:\n",
    "    try:\n",
    "        # 복합 라벨 예측기 생성\n",
    "        combined_predictor = TabularPredictor(\n",
    "            label='combined_label', \n",
    "            path=combined_save_path,\n",
    "            eval_metric='f1_macro',  # F1 점수 최적화\n",
    "            problem_type='multiclass'\n",
    "        )\n",
    "        \n",
    "        # 모델 훈련 (여러 알고리즘 자동 시도)\n",
    "        print(\"복합 라벨 모델들 훈련 중... (예상 소요 시간: 5-10분)\")\n",
    "        combined_predictor = combined_predictor.fit(\n",
    "            train_data=train_combined_df.drop(['category1', 'category2'], axis=1),\n",
    "            time_limit=300,  # 5분 제한\n",
    "            presets='medium_quality_faster_train',\n",
    "            num_bag_folds=3,  # 앙상블을 위한 폴드 수\n",
    "            num_bag_sets=1,\n",
    "            num_stack_levels=1\n",
    "        )\n",
    "        \n",
    "        print(\"✅ AutoGluon 복합 라벨 모델 훈련 완료!\")\n",
    "        \n",
    "        # 리더보드 출력\n",
    "        print(f\"\\n📋 복합 라벨 AutoGluon 모델 리더보드:\")\n",
    "        combined_leaderboard = combined_predictor.leaderboard()\n",
    "        print(combined_leaderboard.head())\n",
    "        \n",
    "        # 최고 성능 모델 정보\n",
    "        best_combined_model = combined_leaderboard.iloc[0]['model']\n",
    "        best_combined_score = combined_leaderboard.iloc[0]['score_val']\n",
    "        print(f\"\\n🏆 최고 성능 복합 모델: {best_combined_model}\")\n",
    "        print(f\"검증 F1-Score: {best_combined_score:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ AutoGluon 복합 라벨 훈련 실패: {str(e)}\")\n",
    "        combined_predictor = None\n",
    "\n",
    "# 3. XGBoost 대안 모델 (AutoGluon 실패시)\n",
    "if not autogluon_available or combined_predictor is None:\n",
    "    print(f\"\\n🔄 XGBoost 복합 라벨 모델로 진행...\")\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    # 복합 라벨 인코딩\n",
    "    combined_le = LabelEncoder()\n",
    "    y_combined_encoded = combined_le.fit_transform(train_combined_df['combined_label'])\n",
    "    \n",
    "    print(f\"복합 라벨 인코딩: {len(combined_le.classes_)}개 클래스\")\n",
    "    \n",
    "    # XGBoost 모델 훈련 (복합 라벨용 고성능 설정)\n",
    "    combined_xgb_model = xgb.XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        learning_rate=0.03,\n",
    "        max_depth=10,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(\"XGBoost 복합 라벨 모델 훈련 중...\")\n",
    "    combined_xgb_model.fit(X, y_combined_encoded)\n",
    "    \n",
    "    print(\"✅ XGBoost 복합 라벨 모델 훈련 완료!\")\n",
    "\n",
    "# 4. 복합 라벨 모델로 예측 수행\n",
    "print(f\"\\n🎯 복합 라벨 모델 예측 수행...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if autogluon_available and combined_predictor is not None:\n",
    "    print(\"AutoGluon 복합 라벨 모델로 예측...\")\n",
    "    \n",
    "    # 테스트 데이터 예측\n",
    "    test_pred_combined_labels = combined_predictor.predict(test_combined_df.drop(['category1', 'category2', 'combined_label'], axis=1))\n",
    "    test_pred_combined_proba = combined_predictor.predict_proba(test_combined_df.drop(['category1', 'category2', 'combined_label'], axis=1))\n",
    "    \n",
    "    model_type = \"AutoGluon 복합\"\n",
    "    \n",
    "else:\n",
    "    print(\"XGBoost 복합 라벨 모델로 예측...\")\n",
    "    \n",
    "    # 예측\n",
    "    test_pred_combined_encoded = combined_xgb_model.predict(test_X)\n",
    "    test_pred_combined_labels = combined_le.inverse_transform(test_pred_combined_encoded)\n",
    "    \n",
    "    model_type = \"XGBoost 복합\"\n",
    "\n",
    "# 5. 복합 라벨을 개별 카테고리로 분리\n",
    "print(f\"복합 라벨을 개별 카테고리로 분리...\")\n",
    "\n",
    "# 예측된 복합 라벨을 개별 카테고리로 분리\n",
    "if isinstance(test_pred_combined_labels, pd.Series):\n",
    "    test_pred_split = test_pred_combined_labels.str.split('_', expand=True)\n",
    "elif isinstance(test_pred_combined_labels, np.ndarray):\n",
    "    test_pred_split = pd.Series(test_pred_combined_labels).str.split('_', expand=True)\n",
    "\n",
    "test_pred_cat1_combined = test_pred_split[0].values\n",
    "test_pred_cat2_combined = test_pred_split[1].values\n",
    "\n",
    "print(f\"✅ {model_type} 복합 라벨 예측 완료!\")\n",
    "\n",
    "# 6. 성능 평가\n",
    "print(f\"\\n📊 {model_type} 모델 성능 평가\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 개별 카테고리 정확도\n",
    "cat1_accuracy_combined = (test_pred_cat1_combined == test_y_actual).mean()\n",
    "cat2_accuracy_combined = (test_pred_cat2_combined == test_y_actual_cat2).mean()\n",
    "\n",
    "print(f\"Category1 정확도: {cat1_accuracy_combined:.4f} ({cat1_accuracy_combined*100:.2f}%)\")\n",
    "print(f\"Category2 정확도: {cat2_accuracy_combined:.4f} ({cat2_accuracy_combined*100:.2f}%)\")\n",
    "\n",
    "# 🎯 핵심 지표: 두 카테고리 모두 정답 (복합 라벨의 핵심 장점)\n",
    "both_correct_combined = (test_pred_cat1_combined == test_y_actual) & (test_pred_cat2_combined == test_y_actual_cat2)\n",
    "both_accuracy_combined = both_correct_combined.mean()\n",
    "both_count_combined = both_correct_combined.sum()\n",
    "\n",
    "print(f\"\\n🎯 핵심 지표 - 두 카테고리 모두 정답:\")\n",
    "print(f\"정확도: {both_accuracy_combined:.4f} ({both_accuracy_combined*100:.2f}%)\")\n",
    "print(f\"정답 개수: {both_count_combined}/{len(test_y_actual)}\")\n",
    "\n",
    "# 복합 라벨 직접 비교 (가장 정확한 지표)\n",
    "test_actual_combined_labels = test_combined_df['combined_label'].values\n",
    "combined_direct_accuracy = (test_pred_combined_labels == test_actual_combined_labels).mean()\n",
    "print(f\"복합 라벨 직접 정확도: {combined_direct_accuracy:.4f} ({combined_direct_accuracy*100:.2f}%)\")\n",
    "\n",
    "# F1-Score 계산 (복합 라벨 기준)\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "f1_combined_direct = f1_score(test_actual_combined_labels, test_pred_combined_labels, average='macro')\n",
    "print(f\"복합 라벨 F1-Score (macro): {f1_combined_direct:.4f}\")\n",
    "\n",
    "# 7. 모든 방식 성능 비교\n",
    "print(f\"\\n📈 모델 방식 종합 비교:\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'방식':<20} {'Cat1 정확도':<12} {'Cat2 정확도':<12} {'종합 정확도':<12} {'개선':<10}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# 기존 개별 모델 방식\n",
    "original_both_accuracy = (test_y_pred == test_y_actual) & (test_y_pred_cat2 == test_y_actual_cat2)\n",
    "original_both_accuracy = original_both_accuracy.mean()\n",
    "print(f\"{'기존 개별 모델':<20} {accuracy:<12.4f} {accuracy_cat2:<12.4f} {original_both_accuracy:<12.4f} {'기준':<10}\")\n",
    "\n",
    "# 복합 라벨 방식\n",
    "improvement_combined = both_accuracy_combined - original_both_accuracy\n",
    "improvement_text_combined = f\"+{improvement_combined:.4f}\" if improvement_combined > 0 else f\"{improvement_combined:.4f}\"\n",
    "print(f\"{model_type:<20} {cat1_accuracy_combined:<12.4f} {cat2_accuracy_combined:<12.4f} {both_accuracy_combined:<12.4f} {improvement_text_combined:<10}\")\n",
    "\n",
    "# 8. 복합 라벨 상세 분류 리포트 (상위 클래스)\n",
    "print(f\"\\n📋 복합 라벨 Classification Report (상위 20개 클래스):\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# 가장 빈번한 복합 라벨들만 보고서 생성\n",
    "top_combined_labels = pd.Series(test_actual_combined_labels).value_counts().head(20).index.tolist()\n",
    "mask_combined = pd.Series(test_actual_combined_labels).isin(top_combined_labels)\n",
    "\n",
    "if mask_combined.sum() > 0:\n",
    "    filtered_actual_combined = pd.Series(test_actual_combined_labels)[mask_combined]\n",
    "    filtered_pred_combined = pd.Series(test_pred_combined_labels)[mask_combined]\n",
    "    \n",
    "    combined_report = classification_report(\n",
    "        filtered_actual_combined, \n",
    "        filtered_pred_combined, \n",
    "        target_names=top_combined_labels, \n",
    "        labels=top_combined_labels,\n",
    "        zero_division=0\n",
    "    )\n",
    "    print(combined_report)\n",
    "\n",
    "# 9. 복합 라벨 예측 샘플 분석\n",
    "print(f\"\\n🔍 복합 라벨 예측 샘플 분석 (처음 15개):\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "for i in range(min(15, len(test_y_actual))):\n",
    "    text = test_texts[i][:50] + \"...\" if len(test_texts[i]) > 50 else test_texts[i]\n",
    "    \n",
    "    actual_combined = test_actual_combined_labels[i]\n",
    "    pred_combined = test_pred_combined_labels[i]\n",
    "    \n",
    "    # 개별 카테고리 분리\n",
    "    actual_cat1 = test_y_actual[i]\n",
    "    actual_cat2 = test_y_actual_cat2[i]\n",
    "    pred_cat1 = test_pred_cat1_combined[i]\n",
    "    pred_cat2 = test_pred_cat2_combined[i]\n",
    "    \n",
    "    # 매칭 상태\n",
    "    combined_match = actual_combined == pred_combined\n",
    "    both_match = (actual_cat1 == pred_cat1) and (actual_cat2 == pred_cat2)\n",
    "    \n",
    "    status = \"✅\" if combined_match else \"❌\"\n",
    "    \n",
    "    print(f\"{i+1:2d}. {status} 복합: {actual_combined} → {pred_combined}\")\n",
    "    print(f\"      개별: {actual_cat1}|{actual_cat2} → {pred_cat1}|{pred_cat2}\")\n",
    "    print(f\"      텍스트: {text}\")\n",
    "    print()\n",
    "\n",
    "# 10. 복합 라벨 방식의 장단점 분석\n",
    "print(f\"\\n🔬 복합 라벨 방식 분석:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"📈 장점:\")\n",
    "print(f\"1. 카테고리 간 의존성을 직접적으로 학습\")\n",
    "print(f\"2. 한 번의 예측으로 두 카테고리 동시 결정\")\n",
    "print(f\"3. 카테고리 조합의 빈도를 고려한 학습\")\n",
    "\n",
    "print(f\"\\n📉 단점:\")\n",
    "print(f\"1. 희소한 조합에 대한 학습 어려움\")\n",
    "print(f\"2. 새로운 조합 출현 시 대응 곤란\")\n",
    "print(f\"3. 클래스 수 증가로 인한 복잡도 상승\")\n",
    "\n",
    "print(f\"\\n💡 복합 라벨 방식 결론:\")\n",
    "if improvement_combined > 0.01:\n",
    "    print(f\"✅ 복합 라벨 방식이 {improvement_combined*100:.2f}%p 향상! 카테고리 의존성이 강한 경우 효과적\")\n",
    "elif improvement_combined > -0.01:\n",
    "    print(f\"📊 개별 모델과 유사한 성능. 데이터 특성에 따라 선택\")\n",
    "else:\n",
    "    print(f\"⚠️ 개별 모델이 {abs(improvement_combined)*100:.2f}%p 더 좋음. 희소한 조합 때문일 가능성\")\n",
    "\n",
    "if autogluon_available and combined_predictor is not None:\n",
    "    print(f\"\\n💾 복합 라벨 모델 저장 위치: {combined_save_path}\")\n",
    "    print(f\"📥 모델 로드 방법:\")\n",
    "    print(f\"combined_predictor = TabularPredictor.load('{combined_save_path}')\")\n",
    "    print(f\"combined_pred = combined_predictor.predict(new_data)\")\n",
    "    print(f\"# 복합 라벨을 개별 카테고리로 분리\")\n",
    "    print(f\"cat1_pred, cat2_pred = combined_pred.str.split('_', expand=True)[0], combined_pred.str.split('_', expand=True)[1]\")\n",
    "\n",
    "print(f\"\\n🎯 복합 라벨 최종 성과:\")\n",
    "print(f\"두 카테고리 동시 정답률: {both_accuracy_combined*100:.2f}% ({both_count_combined}/{len(test_y_actual)}개)\")\n",
    "print(f\"복합 라벨 직접 정확도: {combined_direct_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb77oepa1tu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "🔬 복합 라벨 방식: 로지스틱 회귀 vs SVM Linear 비교\n",
      "================================================================================\n",
      "📊 데이터 준비 중...\n",
      "📝 테스트 데이터 벡터 생성 중...\n",
      "훈련 데이터: 3359개\n",
      "테스트 데이터: 664개\n",
      "벡터 차원: 1024차원\n",
      "복합 라벨 종류: 77개\n",
      "훈련 데이터 고유 라벨: 77개\n",
      "테스트 데이터 고유 라벨: 70개\n",
      "공통 라벨: 68개\n",
      "테스트에만 있는 라벨: 2개\n",
      "처리할 수 없는 라벨들: ['중립_놀람', '중립_만족감']...\n",
      "필터링 후 훈련 데이터: 3335개\n",
      "필터링 후 테스트 데이터: 660개\n",
      "인코딩된 라벨 종류: 68\n",
      "\n",
      "🤖 로지스틱 회귀 모델 훈련 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1281: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 SVM Linear 모델 훈련 중...\n",
      "\n",
      "================================================================================\n",
      "📊 모델 성능 비교 결과\n",
      "================================================================================\n",
      "\n",
      "🔸 로지스틱 회귀 결과:\n",
      "  - 복합 라벨 정확도: 0.2939 (29.39%)\n",
      "  - Category1 정확도: 0.5030 (50.30%)\n",
      "  - Category2 정확도: 0.3106 (31.06%)\n",
      "  - 두 카테고리 모두 정답: 194/660 (29.39%)\n",
      "  - F1-Score (Macro): 0.1735\n",
      "  - F1-Score (Weighted): 0.2628\n",
      "\n",
      "🔸 SVM Linear 결과:\n",
      "  - 복합 라벨 정확도: 0.3197 (31.97%)\n",
      "  - Category1 정확도: 0.5303 (53.03%)\n",
      "  - Category2 정확도: 0.3394 (33.94%)\n",
      "  - 두 카테고리 모두 정답: 211/660 (31.97%)\n",
      "  - F1-Score (Macro): 0.1995\n",
      "  - F1-Score (Weighted): 0.2982\n",
      "\n",
      "🏆 성능 비교:\n",
      "  - 복합 라벨 정확도가 더 높은 모델: SVM Linear\n",
      "  - 두 카테고리 동시 정답률이 더 높은 모델: SVM Linear\n",
      "  - F1-Score (Macro)가 더 높은 모델: SVM Linear\n",
      "\n",
      "📈 성능 차이:\n",
      "  - 복합 라벨 정확도 차이: 0.0258 (2.58%p)\n",
      "  - 두 카테고리 동시 정답률 차이: 0.0258 (2.58%p)\n",
      "  - F1-Score 차이: 0.0259\n",
      "\n",
      "📝 샘플 예측 결과 비교 (처음 10개):\n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "No. 실제 Cat1      실제 Cat2      LR Cat1      LR Cat2      SVM Cat1     SVM Cat2     LR 정답    SVM 정답  \n",
      "------------------------------------------------------------------------------------------------------------------------\n",
      "1   기쁨           만족감          기쁨           즐거움          기쁨           만족감          ✗        ✓       \n",
      "2   기쁨           만족감          기쁨           만족감          기쁨           만족감          ✓        ✓       \n",
      "3   기쁨           만족감          기쁨           만족감          기쁨           만족감          ✓        ✓       \n",
      "4   슬픔           무기력          싫어함(상태)      답답함          싫어함(상태)      난처함          ✗        ✗       \n",
      "5   기쁨           즐거움          미움(상대방)      비위상함         미움(상대방)      비위상함         ✗        ✗       \n",
      "6   싫어함(상태)      답답함          싫어함(상태)      답답함          싫어함(상태)      답답함          ✓        ✓       \n",
      "7   기쁨           만족감          기쁨           즐거움          욕망           아쉬움          ✗        ✗       \n",
      "8   기쁨           자랑스러움        욕망           궁금함          욕망           욕심           ✗        ✗       \n",
      "9   슬픔           절망           기쁨           기대감          슬픔           무기력          ✗        ✗       \n",
      "10  기쁨           즐거움          미움(상대방)      경멸           미움(상대방)      경멸           ✗        ✗       \n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 복합 라벨 방식으로 로지스틱 회귀와 SVM Linear 모델 비교\n",
    "print(\"=\" * 80)\n",
    "print(\"🔬 복합 라벨 방식: 로지스틱 회귀 vs SVM Linear 비교\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 1. 데이터 준비 (기존 임베딩 벡터 사용)\n",
    "print(\"📊 데이터 준비 중...\")\n",
    "\n",
    "# 훈련 데이터 준비 (data 변수의 임베딩 벡터 사용)\n",
    "X_train = np.vstack(data['vector'].values)  # 1024차원 임베딩 벡터\n",
    "train_cat1 = data['re_category1'].values\n",
    "train_cat2 = data['re_category2'].values\n",
    "\n",
    "# 테스트 데이터 준비 (test_data의 임베딩 벡터 생성)\n",
    "print(\"📝 테스트 데이터 벡터 생성 중...\")\n",
    "test_texts = test_data['context'].fillna('').astype(str).tolist()\n",
    "test_vectors = [embeddings_model.encode(text).tolist() for text in test_texts]\n",
    "X_test = np.vstack(test_vectors)  # 1024차원 임베딩 벡터\n",
    "\n",
    "test_cat1_actual = test_data['category1'].values\n",
    "test_cat2_actual = test_data['category2'].values\n",
    "\n",
    "# 복합 라벨 생성 (category1_category2 형태)\n",
    "train_combined_labels = [f\"{cat1}_{cat2}\" for cat1, cat2 in zip(train_cat1, train_cat2)]\n",
    "test_combined_labels = [f\"{cat1}_{cat2}\" for cat1, cat2 in zip(test_cat1_actual, test_cat2_actual)]\n",
    "\n",
    "print(f\"훈련 데이터: {len(X_train)}개\")\n",
    "print(f\"테스트 데이터: {len(X_test)}개\")\n",
    "print(f\"벡터 차원: {X_train.shape[1]}차원\")\n",
    "print(f\"복합 라벨 종류: {len(set(train_combined_labels))}개\")\n",
    "\n",
    "# 훈련/테스트 라벨 분석\n",
    "train_label_set = set(train_combined_labels)\n",
    "test_label_set = set(test_combined_labels)\n",
    "unseen_labels = test_label_set - train_label_set\n",
    "common_labels = train_label_set & test_label_set\n",
    "\n",
    "print(f\"훈련 데이터 고유 라벨: {len(train_label_set)}개\")\n",
    "print(f\"테스트 데이터 고유 라벨: {len(test_label_set)}개\")\n",
    "print(f\"공통 라벨: {len(common_labels)}개\")\n",
    "print(f\"테스트에만 있는 라벨: {len(unseen_labels)}개\")\n",
    "\n",
    "if unseen_labels:\n",
    "    print(f\"처리할 수 없는 라벨들: {sorted(list(unseen_labels))[:5]}...\")\n",
    "    \n",
    "    # 공통 라벨만 사용하여 필터링\n",
    "    train_mask = np.array([label in common_labels for label in train_combined_labels])\n",
    "    test_mask = np.array([label in common_labels for label in test_combined_labels])\n",
    "    \n",
    "    X_train_filtered = X_train[train_mask]\n",
    "    train_combined_filtered = [label for i, label in enumerate(train_combined_labels) if train_mask[i]]\n",
    "    \n",
    "    X_test_filtered = X_test[test_mask]\n",
    "    test_combined_filtered = [label for i, label in enumerate(test_combined_labels) if test_mask[i]]\n",
    "    test_cat1_filtered = test_cat1_actual[test_mask]\n",
    "    test_cat2_filtered = test_cat2_actual[test_mask]\n",
    "    \n",
    "    print(f\"필터링 후 훈련 데이터: {len(X_train_filtered)}개\")\n",
    "    print(f\"필터링 후 테스트 데이터: {len(X_test_filtered)}개\")\n",
    "else:\n",
    "    X_train_filtered = X_train\n",
    "    train_combined_filtered = train_combined_labels\n",
    "    X_test_filtered = X_test\n",
    "    test_combined_filtered = test_combined_labels\n",
    "    test_cat1_filtered = test_cat1_actual\n",
    "    test_cat2_filtered = test_cat2_actual\n",
    "\n",
    "# 2. 라벨 인코딩\n",
    "le_combined = LabelEncoder()\n",
    "y_train_encoded = le_combined.fit_transform(train_combined_filtered)\n",
    "y_test_encoded = le_combined.transform(test_combined_filtered)\n",
    "\n",
    "print(f\"인코딩된 라벨 종류: {len(le_combined.classes_)}\")\n",
    "\n",
    "# 3. 로지스틱 회귀 모델 훈련\n",
    "print(\"\\n🤖 로지스틱 회귀 모델 훈련 중...\")\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42, multi_class='ovr')\n",
    "lr_model.fit(X_train_filtered, y_train_encoded)\n",
    "\n",
    "# 로지스틱 회귀 예측\n",
    "lr_pred_encoded = lr_model.predict(X_test_filtered)\n",
    "lr_pred_labels = le_combined.inverse_transform(lr_pred_encoded)\n",
    "\n",
    "# 로지스틱 회귀 결과 분석\n",
    "lr_accuracy = accuracy_score(test_combined_filtered, lr_pred_labels)\n",
    "lr_f1_macro = f1_score(y_test_encoded, lr_pred_encoded, average='macro')\n",
    "lr_f1_weighted = f1_score(y_test_encoded, lr_pred_encoded, average='weighted')\n",
    "\n",
    "# 개별 카테고리 정확도 계산 (로지스틱 회귀)\n",
    "lr_cat1_pred = [label.split('_')[0] for label in lr_pred_labels]\n",
    "lr_cat2_pred = [label.split('_')[1] for label in lr_pred_labels]\n",
    "lr_cat1_accuracy = accuracy_score(test_cat1_filtered, lr_cat1_pred)\n",
    "lr_cat2_accuracy = accuracy_score(test_cat2_filtered, lr_cat2_pred)\n",
    "lr_both_correct = sum(1 for i in range(len(test_cat1_filtered)) \n",
    "                     if lr_cat1_pred[i] == test_cat1_filtered[i] and lr_cat2_pred[i] == test_cat2_filtered[i])\n",
    "lr_both_accuracy = lr_both_correct / len(test_cat1_filtered)\n",
    "\n",
    "# 4. SVM Linear 모델 훈련\n",
    "print(\"🤖 SVM Linear 모델 훈련 중...\")\n",
    "svm_model = SVC(kernel='linear', random_state=42, probability=True)\n",
    "svm_model.fit(X_train_filtered, y_train_encoded)\n",
    "\n",
    "# SVM 예측\n",
    "svm_pred_encoded = svm_model.predict(X_test_filtered)\n",
    "svm_pred_labels = le_combined.inverse_transform(svm_pred_encoded)\n",
    "\n",
    "# SVM 결과 분석\n",
    "svm_accuracy = accuracy_score(test_combined_filtered, svm_pred_labels)\n",
    "svm_f1_macro = f1_score(y_test_encoded, svm_pred_encoded, average='macro')\n",
    "svm_f1_weighted = f1_score(y_test_encoded, svm_pred_encoded, average='weighted')\n",
    "\n",
    "# 개별 카테고리 정확도 계산 (SVM)\n",
    "svm_cat1_pred = [label.split('_')[0] for label in svm_pred_labels]\n",
    "svm_cat2_pred = [label.split('_')[1] for label in svm_pred_labels]\n",
    "svm_cat1_accuracy = accuracy_score(test_cat1_filtered, svm_cat1_pred)\n",
    "svm_cat2_accuracy = accuracy_score(test_cat2_filtered, svm_cat2_pred)\n",
    "svm_both_correct = sum(1 for i in range(len(test_cat1_filtered)) \n",
    "                      if svm_cat1_pred[i] == test_cat1_filtered[i] and svm_cat2_pred[i] == test_cat2_filtered[i])\n",
    "svm_both_accuracy = svm_both_correct / len(test_cat1_filtered)\n",
    "\n",
    "# 5. 결과 출력\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"📊 모델 성능 비교 결과\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n🔸 로지스틱 회귀 결과:\")\n",
    "print(f\"  - 복합 라벨 정확도: {lr_accuracy:.4f} ({lr_accuracy*100:.2f}%)\")\n",
    "print(f\"  - Category1 정확도: {lr_cat1_accuracy:.4f} ({lr_cat1_accuracy*100:.2f}%)\")\n",
    "print(f\"  - Category2 정확도: {lr_cat2_accuracy:.4f} ({lr_cat2_accuracy*100:.2f}%)\")\n",
    "print(f\"  - 두 카테고리 모두 정답: {lr_both_correct}/{len(test_cat1_filtered)} ({lr_both_accuracy*100:.2f}%)\")\n",
    "print(f\"  - F1-Score (Macro): {lr_f1_macro:.4f}\")\n",
    "print(f\"  - F1-Score (Weighted): {lr_f1_weighted:.4f}\")\n",
    "\n",
    "print(f\"\\n🔸 SVM Linear 결과:\")\n",
    "print(f\"  - 복합 라벨 정확도: {svm_accuracy:.4f} ({svm_accuracy*100:.2f}%)\")\n",
    "print(f\"  - Category1 정확도: {svm_cat1_accuracy:.4f} ({svm_cat1_accuracy*100:.2f}%)\")\n",
    "print(f\"  - Category2 정확도: {svm_cat2_accuracy:.4f} ({svm_cat2_accuracy*100:.2f}%)\")\n",
    "print(f\"  - 두 카테고리 모두 정답: {svm_both_correct}/{len(test_cat1_filtered)} ({svm_both_accuracy*100:.2f}%)\")\n",
    "print(f\"  - F1-Score (Macro): {svm_f1_macro:.4f}\")\n",
    "print(f\"  - F1-Score (Weighted): {svm_f1_weighted:.4f}\")\n",
    "\n",
    "# 성능 비교\n",
    "print(f\"\\n🏆 성능 비교:\")\n",
    "better_complex = \"로지스틱 회귀\" if lr_accuracy > svm_accuracy else \"SVM Linear\"\n",
    "better_both = \"로지스틱 회귀\" if lr_both_accuracy > svm_both_accuracy else \"SVM Linear\"\n",
    "better_f1 = \"로지스틱 회귀\" if lr_f1_macro > svm_f1_macro else \"SVM Linear\"\n",
    "\n",
    "print(f\"  - 복합 라벨 정확도가 더 높은 모델: {better_complex}\")\n",
    "print(f\"  - 두 카테고리 동시 정답률이 더 높은 모델: {better_both}\")\n",
    "print(f\"  - F1-Score (Macro)가 더 높은 모델: {better_f1}\")\n",
    "\n",
    "# 차이 분석\n",
    "acc_diff = abs(lr_accuracy - svm_accuracy)\n",
    "both_diff = abs(lr_both_accuracy - svm_both_accuracy)\n",
    "f1_diff = abs(lr_f1_macro - svm_f1_macro)\n",
    "\n",
    "print(f\"\\n📈 성능 차이:\")\n",
    "print(f\"  - 복합 라벨 정확도 차이: {acc_diff:.4f} ({acc_diff*100:.2f}%p)\")\n",
    "print(f\"  - 두 카테고리 동시 정답률 차이: {both_diff:.4f} ({both_diff*100:.2f}%p)\")\n",
    "print(f\"  - F1-Score 차이: {f1_diff:.4f}\")\n",
    "\n",
    "# 샘플 예측 결과 비교\n",
    "print(f\"\\n📝 샘플 예측 결과 비교 (처음 10개):\")\n",
    "print(\"-\" * 120)\n",
    "print(f\"{'No.':<3} {'실제 Cat1':<12} {'실제 Cat2':<12} {'LR Cat1':<12} {'LR Cat2':<12} {'SVM Cat1':<12} {'SVM Cat2':<12} {'LR 정답':<8} {'SVM 정답':<8}\")\n",
    "print(\"-\" * 120)\n",
    "\n",
    "for i in range(min(10, len(test_cat1_filtered))):\n",
    "    lr_correct = \"✓\" if lr_cat1_pred[i] == test_cat1_filtered[i] and lr_cat2_pred[i] == test_cat2_filtered[i] else \"✗\"\n",
    "    svm_correct = \"✓\" if svm_cat1_pred[i] == test_cat1_filtered[i] and svm_cat2_pred[i] == test_cat2_filtered[i] else \"✗\"\n",
    "    \n",
    "    print(f\"{i+1:<3} {test_cat1_filtered[i]:<12} {test_cat2_filtered[i]:<12} \"\n",
    "          f\"{lr_cat1_pred[i]:<12} {lr_cat2_pred[i]:<12} {svm_cat1_pred[i]:<12} {svm_cat2_pred[i]:<12} \"\n",
    "          f\"{lr_correct:<8} {svm_correct:<8}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e6c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skn_after_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
