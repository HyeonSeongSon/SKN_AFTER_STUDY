{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13495b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\skn\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f72f27ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 필터링 전: 3360개\n",
      "re_category1에서 중립: 3개\n",
      "re_category2에서 중립: 1개\n",
      "데이터 필터링 후: 3359개\n",
      "제거된 데이터: 1개\n",
      "남은 re_category1 클래스 (10개): ['기쁨', '두려움', '미움(상대방)', '분노', '사랑', '수치심', '슬픔', '싫어함(상태)', '욕망', '중립']\n",
      "남은 re_category2 클래스 (64개): ['갈등', '감동', '걱정', '경멸', '고마움', '고통', '공감', '공포', '궁금함', '귀중함', '그리움', '기대감', '난처함', '날카로움', '냉담', '너그러움', '놀람', '다정함', '답답함', '동정(슬픔)', '두근거림', '만족감', '매력적', '무기력', '미안함', '반가움', '반감', '발열', '부끄러움', '불만', '불신감', '불쾌', '불편함', '비위상함', '사나움', '수치심', '시기심', '신뢰감', '신명남', '실망', '싫증', '심심함', '아쉬움', '아픔', '안정감', '억울함', '외로움', '외면', '욕심', '원망', '위축감', '자랑스러움', '자신감', '절망', '죄책감', '즐거움', '초조함', '치사함', '타오름', '통쾌함', '편안함', '허망', '호감', '후회']\n",
      "필터링 후 re_category1 중립: 2개\n",
      "필터링 후 re_category2 중립: 0개\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>generator_context</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>input_context</th>\n",
       "      <th>original_index</th>\n",
       "      <th>augmentation_index</th>\n",
       "      <th>re_category1</th>\n",
       "      <th>re_category2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>갑자기 내 책상 위에 놓인 따뜻한 손편지에 마음이 뭉클해졌다.</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "      <td>설탕 스틱 껴준거 센스 백점 만점에 천점</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>비가 오는데도 친구가 내 좋아하는 카페까지 우산 들고 따라와줘서 마음이 따뜻해졌어.</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "      <td>아쓰 산차이 기분 안 좋은 거 알아채고 산차이가 가고 싶다던 토끼집 데려온 거 감동</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>햇살 아래 반짝이는 아이의 눈동자가 마치 작은 보석처럼 빛났다. 그 순간, 세상 모...</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "      <td>신데렐라 드레스는 다시 봐도 너무 아름다워. 사람에게 꿈의 물결을 입히다니요.</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>이번 전시회 준비하면서 철저하게 세부까지 챙겨준 덕분에 모든 게 완벽하게 마무리돼서...</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "      <td>와 민희진 씨 애들 숙소 스타일링까지 맡기면서 신경써 준 거 진짜 좀 대단하네</td>\n",
       "      <td>107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>비 오는 날 낯선 사람이 내게 담요를 건네며 추위 걱정해 줬다. 마음이 따뜻해져서 ...</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "      <td>개감동인 거 자기가 쓰고 있던 우산 나 주고\\n자기가 비 맞아가면서 뒤집어준 거야\\...</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  generator_context category1  \\\n",
       "0           0                 갑자기 내 책상 위에 놓인 따뜻한 손편지에 마음이 뭉클해졌다.        기쁨   \n",
       "1           1     비가 오는데도 친구가 내 좋아하는 카페까지 우산 들고 따라와줘서 마음이 따뜻해졌어.        기쁨   \n",
       "2           2  햇살 아래 반짝이는 아이의 눈동자가 마치 작은 보석처럼 빛났다. 그 순간, 세상 모...        기쁨   \n",
       "3           3  이번 전시회 준비하면서 철저하게 세부까지 챙겨준 덕분에 모든 게 완벽하게 마무리돼서...        기쁨   \n",
       "4           4  비 오는 날 낯선 사람이 내게 담요를 건네며 추위 걱정해 줬다. 마음이 따뜻해져서 ...        기쁨   \n",
       "\n",
       "  category2                                      input_context  \\\n",
       "0        감동                             설탕 스틱 껴준거 센스 백점 만점에 천점   \n",
       "1        감동     아쓰 산차이 기분 안 좋은 거 알아채고 산차이가 가고 싶다던 토끼집 데려온 거 감동   \n",
       "2        감동        신데렐라 드레스는 다시 봐도 너무 아름다워. 사람에게 꿈의 물결을 입히다니요.   \n",
       "3        감동        와 민희진 씨 애들 숙소 스타일링까지 맡기면서 신경써 준 거 진짜 좀 대단하네   \n",
       "4        감동  개감동인 거 자기가 쓰고 있던 우산 나 주고\\n자기가 비 맞아가면서 뒤집어준 거야\\...   \n",
       "\n",
       "   original_index  augmentation_index re_category1 re_category2  \n",
       "0            20.0                 NaN           기쁨           감동  \n",
       "1            79.0                 NaN           기쁨           감동  \n",
       "2           104.0                 NaN           기쁨           감동  \n",
       "3           107.0                 NaN           기쁨           감동  \n",
       "4           137.0                 NaN           기쁨           감동  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(r'C:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\data\\retest_augmentation.xlsx')\n",
    "\n",
    "# re_category2에서만 중립 데이터 제거 (re_category1은 중립 유지)\n",
    "print(f\"데이터 필터링 전: {len(data)}개\")\n",
    "print(f\"re_category1에서 중립: {(data['re_category1'] == '중립').sum()}개\")\n",
    "print(f\"re_category2에서 중립: {(data['re_category2'] == '중립').sum()}개\")\n",
    "\n",
    "# re_category2에서만 중립 데이터 제거 (Category2에 중립이 없으므로 라벨 불일치 방지)\n",
    "original_count = len(data)\n",
    "data = data[data['re_category2'] != '중립'].copy()\n",
    "\n",
    "# 인덱스 재설정\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "print(f\"데이터 필터링 후: {len(data)}개\")\n",
    "print(f\"제거된 데이터: {original_count - len(data)}개\")\n",
    "\n",
    "# 필터링된 데이터 확인\n",
    "print(f\"남은 re_category1 클래스 ({len(data['re_category1'].unique())}개): {sorted(data['re_category1'].unique())}\")\n",
    "print(f\"남은 re_category2 클래스 ({len(data['re_category2'].unique())}개): {sorted(data['re_category2'].unique())}\")\n",
    "\n",
    "# 중립 확인\n",
    "print(f\"필터링 후 re_category1 중립: {(data['re_category1'] == '중립').sum()}개\")\n",
    "print(f\"필터링 후 re_category2 중립: {(data['re_category2'] == '중립').sum()}개\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2dbf27be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_model():\n",
    "  \"\"\"\n",
    "  임베딩 모델 초기화\n",
    "  \"\"\"\n",
    "  model = SentenceTransformer(\"dragonkue/snowflake-arctic-embed-l-v2.0-ko\") \n",
    "  vec_dim = len(model.encode(\"dummy_text\"))\n",
    "  print(f\"모델 차원: {vec_dim}\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c873e343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 차원: 1024\n"
     ]
    }
   ],
   "source": [
    "embeddings_model = embeddings_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4926f06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "변수 X 초기화됨\n",
      "변수 y 초기화됨\n",
      "✅ 기존 변수들이 초기화되었습니다.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3359 entries, 0 to 3358\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Unnamed: 0          3359 non-null   int64  \n",
      " 1   generator_context   3359 non-null   object \n",
      " 2   category1           3359 non-null   object \n",
      " 3   category2           3359 non-null   object \n",
      " 4   input_context       3359 non-null   object \n",
      " 5   original_index      664 non-null    float64\n",
      " 6   augmentation_index  2695 non-null   float64\n",
      " 7   re_category1        3359 non-null   object \n",
      " 8   re_category2        3359 non-null   object \n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 236.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# 기존 변수 초기화 (중립 데이터 제거로 인한 크기 불일치 방지)\n",
    "vars_to_reset = ['X', 'y', 'y_encoded', 'X_combined', 'y_cat2', 'y_cat2_encoded', 'le', 'le_cat2', 'cat1_encoder']\n",
    "for var_name in vars_to_reset:\n",
    "    if var_name in locals():\n",
    "        del locals()[var_name]\n",
    "        print(f\"변수 {var_name} 초기화됨\")\n",
    "\n",
    "print(\"✅ 기존 변수들이 초기화되었습니다.\")\n",
    "\n",
    "# 데이터 정보 확인\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd04d86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 필터링된 데이터로 벡터 생성...\n",
      "✅ 벡터 생성 완료: 3359개\n"
     ]
    }
   ],
   "source": [
    "# 중립 데이터 제거 후 벡터 생성\n",
    "print(\"📝 필터링된 데이터로 벡터 생성...\")\n",
    "data['vector'] = data['generator_context'].apply(lambda x: embeddings_model.encode(x).tolist())\n",
    "print(f\"✅ 벡터 생성 완료: {len(data)}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0axv5b84ef7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 코사인 유사도를 사용한 Top3 유사한 샘플 찾기\n",
      "============================================================\n",
      "📊 벡터 데이터 준비 중...\n",
      "벡터 행렬 크기: (3359, 1024)\n",
      "🧮 코사인 유사도 계산 중... (총 3359개 샘플을 배치 단위로 처리)\n",
      "처리 중: 1-100 / 3359\n",
      "처리 중: 101-200 / 3359\n",
      "처리 중: 201-300 / 3359\n",
      "처리 중: 301-400 / 3359\n",
      "처리 중: 401-500 / 3359\n",
      "처리 중: 501-600 / 3359\n",
      "처리 중: 601-700 / 3359\n",
      "처리 중: 701-800 / 3359\n",
      "처리 중: 801-900 / 3359\n",
      "처리 중: 901-1000 / 3359\n",
      "처리 중: 1001-1100 / 3359\n",
      "처리 중: 1101-1200 / 3359\n",
      "처리 중: 1201-1300 / 3359\n",
      "처리 중: 1301-1400 / 3359\n",
      "처리 중: 1401-1500 / 3359\n",
      "처리 중: 1501-1600 / 3359\n",
      "처리 중: 1601-1700 / 3359\n",
      "처리 중: 1701-1800 / 3359\n",
      "처리 중: 1801-1900 / 3359\n",
      "처리 중: 1901-2000 / 3359\n",
      "처리 중: 2001-2100 / 3359\n",
      "처리 중: 2101-2200 / 3359\n",
      "처리 중: 2201-2300 / 3359\n",
      "처리 중: 2301-2400 / 3359\n",
      "처리 중: 2401-2500 / 3359\n",
      "처리 중: 2501-2600 / 3359\n",
      "처리 중: 2601-2700 / 3359\n",
      "처리 중: 2701-2800 / 3359\n",
      "처리 중: 2801-2900 / 3359\n",
      "처리 중: 2901-3000 / 3359\n",
      "처리 중: 3001-3100 / 3359\n",
      "처리 중: 3101-3200 / 3359\n",
      "처리 중: 3201-3300 / 3359\n",
      "처리 중: 3301-3359 / 3359\n",
      "✅ Top3 유사한 샘플 찾기 완료\n",
      "📝 새로운 컬럼들을 데이터프레임에 추가 중...\n",
      "✅ 새로운 컬럼 추가 완료\n",
      "\n",
      "📋 업데이트된 데이터프레임 정보:\n",
      "데이터 크기: (3359, 16)\n",
      "새로 추가된 컬럼: top1_context, top1_category, top2_context, top2_category, top3_context, top3_category\n",
      "\n",
      "🔍 Top3 유사도 결과 샘플 (첫 3개):\n",
      "====================================================================================================\n",
      "[샘플 1]\n",
      "원본 텍스트: 갑자기 내 책상 위에 놓인 따뜻한 손편지에 마음이 뭉클해졌다....\n",
      "원본 카테고리: 기쁨_감동\n",
      "\n",
      "  Top1 유사 텍스트: 친구가 오랜만에 보내온 편지에 마음이 따뜻해져서 저도 모르게 눈가가 촉촉해졌어요....\n",
      "  Top1 카테고리&유사도: 기쁨_감동_0.7459\n",
      "\n",
      "  Top2 유사 텍스트: 따뜻한 햇살 아래서 친구의 진심 어린 편지를 읽는데, 가슴이 벅차올라 한참을 멍하니 그 자리에 서 있었어....\n",
      "  Top2 카테고리&유사도: 기쁨_감동_0.7265\n",
      "\n",
      "  Top3 유사 텍스트: 오랜만에 만난 친구가 진심 어린 편지를 건네주자 마음이 따뜻해져서 눈물이 났다....\n",
      "  Top3 카테고리&유사도: 기쁨_감동_0.7153\n",
      "====================================================================================================\n",
      "[샘플 2]\n",
      "원본 텍스트: 비가 오는데도 친구가 내 좋아하는 카페까지 우산 들고 따라와줘서 마음이 따뜻해졌어....\n",
      "원본 카테고리: 기쁨_감동\n",
      "\n",
      "  Top1 유사 텍스트: 오후에 갑자기 비가 쏟아졌는데, 동료가 우산을 같이 써주며 \"걱정 마, 내가 있어\"라고 말해줘서 마음이 따뜻해졌어....\n",
      "  Top1 카테고리&유사도: 기쁨_고마움_0.7774\n",
      "\n",
      "  Top2 유사 텍스트: 비 오는 날, 친구가 우산을 나눠줘서 쓸쓸함이 사라지고 마음속에 포근함이 가득 차올랐다....\n",
      "  Top2 카테고리&유사도: 기쁨_고마움_0.7719\n",
      "\n",
      "  Top3 유사 텍스트: 창밖 비 내리는 카페에서 친구가 내 고민에 귀 기울이며 따뜻한 눈빛으로 맞장구칠 때, 마음이 든든해졌다....\n",
      "  Top3 카테고리&유사도: 기쁨_신뢰감_0.7643\n",
      "====================================================================================================\n",
      "[샘플 3]\n",
      "원본 텍스트: 햇살 아래 반짝이는 아이의 눈동자가 마치 작은 보석처럼 빛났다. 그 순간, 세상 모든 희망이 그녀에게 쏟아지는 듯했다....\n",
      "원본 카테고리: 기쁨_감동\n",
      "\n",
      "  Top1 유사 텍스트: 햇살이 그녀의 눈동자에 반짝이며, 무심한 듯 다가오는 그 모습에 나는 가슴이 뛰었다....\n",
      "  Top1 카테고리&유사도: 사랑_두근거림_0.7278\n",
      "\n",
      "  Top2 유사 텍스트: 햇살 아래 그녀의 미소가 반짝였다. 눈을 뗄 수 없는 그 모습에 마음이 저절로 끌렸다....\n",
      "  Top2 카테고리&유사도: 사랑_매력적_0.6993\n",
      "\n",
      "  Top3 유사 텍스트: 햇살 아래 반짝이는 눈동자처럼, 연인의 작은 손길이 내 하루를 특별하게 물들였다....\n",
      "  Top3 카테고리&유사도: 사랑_귀중함_0.6877\n",
      "====================================================================================================\n",
      "\n",
      "📈 유사도 분포 통계:\n",
      "평균 유사도: 0.7333\n",
      "최대 유사도: 0.9572\n",
      "최소 유사도: 0.3699\n",
      "표준편차: 0.0780\n",
      "\n",
      "📊 Top3 유사 샘플들과 원본의 카테고리 일치 분석:\n",
      "Top1 - Category1 일치: 2570/3359 (76.5%)\n",
      "Top1 - Category2 일치: 1595/3359 (47.5%)\n",
      "Top1 - 둘 다 일치: 1564/3359 (46.6%)\n",
      "\n",
      "Top2 - Category1 일치: 2501/3359 (74.5%)\n",
      "Top2 - Category2 일치: 1479/3359 (44.0%)\n",
      "Top2 - 둘 다 일치: 1447/3359 (43.1%)\n",
      "\n",
      "Top3 - Category1 일치: 2448/3359 (72.9%)\n",
      "Top3 - Category2 일치: 1398/3359 (41.6%)\n",
      "Top3 - 둘 다 일치: 1373/3359 (40.9%)\n",
      "\n",
      "🎉 코사인 유사도 기반 Top3 유사한 샘플 추가 완료!\n",
      "총 3359개 샘플에 대해 각각 Top3 유사한 샘플 정보가 추가되었습니다.\n",
      "\n",
      "📋 최종 데이터프레임 컬럼 목록:\n",
      "  - Unnamed: 0\n",
      "  - generator_context\n",
      "  - category1\n",
      "  - category2\n",
      "  - input_context\n",
      "  - original_index\n",
      "  - augmentation_index\n",
      "  - re_category1\n",
      "  - re_category2\n",
      "  - vector\n",
      "  - top1_context\n",
      "  - top1_category\n",
      "  - top2_context\n",
      "  - top2_category\n",
      "  - top3_context\n",
      "  - top3_category\n",
      "\n",
      "데이터 저장 권장사항:\n",
      "data.to_excel('enhanced_data_with_similarity.xlsx', index=False)\n",
      "# 또는\n",
      "data.to_csv('enhanced_data_with_similarity.csv', index=False)\n"
     ]
    }
   ],
   "source": [
    "# 코사인 유사도를 사용한 Top3 유사한 샘플 찾기\n",
    "print(\"🔍 코사인 유사도를 사용한 Top3 유사한 샘플 찾기\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "# 벡터 데이터를 numpy 배열로 변환\n",
    "print(\"📊 벡터 데이터 준비 중...\")\n",
    "vectors = np.vstack(data['vector'].values)\n",
    "print(f\"벡터 행렬 크기: {vectors.shape}\")\n",
    "\n",
    "# 메모리 효율성을 위해 배치로 처리\n",
    "batch_size = 100\n",
    "n_samples = len(data)\n",
    "\n",
    "print(f\"🧮 코사인 유사도 계산 중... (총 {n_samples}개 샘플을 배치 단위로 처리)\")\n",
    "\n",
    "# 새로운 컬럼들을 위한 리스트 초기화\n",
    "top1_context = []\n",
    "top1_category = []\n",
    "top2_context = []\n",
    "top2_category = []\n",
    "top3_context = []\n",
    "top3_category = []\n",
    "\n",
    "# 배치별로 처리\n",
    "for batch_start in range(0, n_samples, batch_size):\n",
    "    batch_end = min(batch_start + batch_size, n_samples)\n",
    "    print(f\"처리 중: {batch_start+1}-{batch_end} / {n_samples}\")\n",
    "    \n",
    "    # 현재 배치에 대한 유사도 계산\n",
    "    batch_vectors = vectors[batch_start:batch_end]\n",
    "    similarities = cosine_similarity(batch_vectors, vectors)\n",
    "    \n",
    "    # 각 샘플에 대해 Top3 유사한 샘플 찾기\n",
    "    for i in range(batch_end - batch_start):\n",
    "        current_idx = batch_start + i\n",
    "        sim_row = similarities[i]\n",
    "        \n",
    "        # 자기 자신과의 유사도를 -1로 설정 (제외)\n",
    "        sim_row[current_idx] = -1\n",
    "        \n",
    "        # 유사도가 높은 순서로 정렬 (인덱스 반환)\n",
    "        top_indices = np.argsort(sim_row)[::-1][:3]  # 상위 3개\n",
    "        top_similarities = sim_row[top_indices]\n",
    "        \n",
    "        # Top 1\n",
    "        idx1 = top_indices[0]\n",
    "        sim1 = top_similarities[0]\n",
    "        top1_context.append(data.iloc[idx1]['generator_context'])\n",
    "        top1_category.append(f\"{data.iloc[idx1]['re_category1']}_{data.iloc[idx1]['re_category2']}_{sim1:.4f}\")\n",
    "        \n",
    "        # Top 2\n",
    "        idx2 = top_indices[1]\n",
    "        sim2 = top_similarities[1]\n",
    "        top2_context.append(data.iloc[idx2]['generator_context'])\n",
    "        top2_category.append(f\"{data.iloc[idx2]['re_category1']}_{data.iloc[idx2]['re_category2']}_{sim2:.4f}\")\n",
    "        \n",
    "        # Top 3\n",
    "        idx3 = top_indices[2]\n",
    "        sim3 = top_similarities[2]\n",
    "        top3_context.append(data.iloc[idx3]['generator_context'])\n",
    "        top3_category.append(f\"{data.iloc[idx3]['re_category1']}_{data.iloc[idx3]['re_category2']}_{sim3:.4f}\")\n",
    "\n",
    "print(\"✅ Top3 유사한 샘플 찾기 완료\")\n",
    "\n",
    "# 새로운 컬럼들을 데이터프레임에 추가\n",
    "print(\"📝 새로운 컬럼들을 데이터프레임에 추가 중...\")\n",
    "data['top1_context'] = top1_context\n",
    "data['top1_category'] = top1_category\n",
    "data['top2_context'] = top2_context\n",
    "data['top2_category'] = top2_category\n",
    "data['top3_context'] = top3_context\n",
    "data['top3_category'] = top3_category\n",
    "\n",
    "print(\"✅ 새로운 컬럼 추가 완료\")\n",
    "\n",
    "# 결과 확인\n",
    "print(f\"\\n📋 업데이트된 데이터프레임 정보:\")\n",
    "print(f\"데이터 크기: {data.shape}\")\n",
    "print(f\"새로 추가된 컬럼: top1_context, top1_category, top2_context, top2_category, top3_context, top3_category\")\n",
    "\n",
    "# 샘플 확인\n",
    "print(f\"\\n🔍 Top3 유사도 결과 샘플 (첫 3개):\")\n",
    "print(\"=\"*100)\n",
    "for i in range(3):\n",
    "    print(f\"[샘플 {i+1}]\")\n",
    "    print(f\"원본 텍스트: {data.iloc[i]['generator_context'][:80]}...\")\n",
    "    print(f\"원본 카테고리: {data.iloc[i]['re_category1']}_{data.iloc[i]['re_category2']}\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"  Top1 유사 텍스트: {data.iloc[i]['top1_context'][:80]}...\")\n",
    "    print(f\"  Top1 카테고리&유사도: {data.iloc[i]['top1_category']}\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"  Top2 유사 텍스트: {data.iloc[i]['top2_context'][:80]}...\")\n",
    "    print(f\"  Top2 카테고리&유사도: {data.iloc[i]['top2_category']}\")\n",
    "    print()\n",
    "    \n",
    "    print(f\"  Top3 유사 텍스트: {data.iloc[i]['top3_context'][:80]}...\")\n",
    "    print(f\"  Top3 카테고리&유사도: {data.iloc[i]['top3_category']}\")\n",
    "    print(\"=\"*100)\n",
    "\n",
    "# 유사도 분포 통계\n",
    "print(f\"\\n📈 유사도 분포 통계:\")\n",
    "all_similarities = []\n",
    "for i in range(len(data)):\n",
    "    for j in [1, 2, 3]:\n",
    "        category_col = f'top{j}_category'\n",
    "        similarity_str = data.iloc[i][category_col].split('_')[-1]\n",
    "        all_similarities.append(float(similarity_str))\n",
    "\n",
    "similarities_array = np.array(all_similarities)\n",
    "print(f\"평균 유사도: {similarities_array.mean():.4f}\")\n",
    "print(f\"최대 유사도: {similarities_array.max():.4f}\")\n",
    "print(f\"최소 유사도: {similarities_array.min():.4f}\")\n",
    "print(f\"표준편차: {similarities_array.std():.4f}\")\n",
    "\n",
    "# 카테고리 일치 분석\n",
    "print(f\"\\n📊 Top3 유사 샘플들과 원본의 카테고리 일치 분석:\")\n",
    "category1_matches = [0, 0, 0]  # top1, top2, top3\n",
    "category2_matches = [0, 0, 0]\n",
    "both_matches = [0, 0, 0]\n",
    "\n",
    "for i in range(len(data)):\n",
    "    orig_cat1 = data.iloc[i]['re_category1']\n",
    "    orig_cat2 = data.iloc[i]['re_category2']\n",
    "    \n",
    "    for j in range(3):\n",
    "        top_category = data.iloc[i][f'top{j+1}_category']\n",
    "        top_cat1, top_cat2, _ = top_category.split('_')\n",
    "        \n",
    "        if orig_cat1 == top_cat1:\n",
    "            category1_matches[j] += 1\n",
    "        if orig_cat2 == top_cat2:\n",
    "            category2_matches[j] += 1\n",
    "        if orig_cat1 == top_cat1 and orig_cat2 == top_cat2:\n",
    "            both_matches[j] += 1\n",
    "\n",
    "for j in range(3):\n",
    "    print(f\"Top{j+1} - Category1 일치: {category1_matches[j]}/{len(data)} ({category1_matches[j]/len(data)*100:.1f}%)\")\n",
    "    print(f\"Top{j+1} - Category2 일치: {category2_matches[j]}/{len(data)} ({category2_matches[j]/len(data)*100:.1f}%)\")\n",
    "    print(f\"Top{j+1} - 둘 다 일치: {both_matches[j]}/{len(data)} ({both_matches[j]/len(data)*100:.1f}%)\")\n",
    "    print()\n",
    "\n",
    "print(f\"🎉 코사인 유사도 기반 Top3 유사한 샘플 추가 완료!\")\n",
    "print(f\"총 {len(data)}개 샘플에 대해 각각 Top3 유사한 샘플 정보가 추가되었습니다.\")\n",
    "\n",
    "# 컬럼 정보 최종 확인\n",
    "print(f\"\\n📋 최종 데이터프레임 컬럼 목록:\")\n",
    "for col in data.columns:\n",
    "    print(f\"  - {col}\")\n",
    "    \n",
    "print(f\"\\n데이터 저장 권장사항:\")\n",
    "print(f\"data.to_excel('enhanced_data_with_similarity.xlsx', index=False)\")\n",
    "print(f\"# 또는\")\n",
    "print(f\"data.to_csv('enhanced_data_with_similarity.csv', index=False)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9e9ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_excel('enhanced_data_with_similarity.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e02917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(r'C:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\data\\enhanced_data_with_similarity.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5b5067f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[(data['re_category1']!=data['category1'])|(data['re_category2']!=data['category2'])].to_excel('dif.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "890f8182",
   "metadata": {},
   "outputs": [],
   "source": [
    "good_data = data[(data['re_category1']==data['category1'])&(data['re_category2']==data['category2'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fad90c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "re_label = pd.read_excel(r'C:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\data\\dif.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cc20f973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3359 entries, 0 to 3358\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Unnamed: 0          3359 non-null   int64  \n",
      " 1   generator_context   3359 non-null   object \n",
      " 2   category1           3359 non-null   object \n",
      " 3   category2           3359 non-null   object \n",
      " 4   input_context       3359 non-null   object \n",
      " 5   original_index      664 non-null    float64\n",
      " 6   augmentation_index  2695 non-null   float64\n",
      " 7   re_category1        3359 non-null   object \n",
      " 8   re_category2        3359 non-null   object \n",
      " 9   vector              3359 non-null   object \n",
      " 10  top1_context        3359 non-null   object \n",
      " 11  top1_category       3359 non-null   object \n",
      " 12  top2_context        3359 non-null   object \n",
      " 13  top2_category       3359 non-null   object \n",
      " 14  top3_context        3359 non-null   object \n",
      " 15  top3_category       3359 non-null   object \n",
      "dtypes: float64(2), int64(1), object(13)\n",
      "memory usage: 420.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([good_data, re_label], axis=0, ignore_index=True)\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5d1688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.iloc[:, :9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3b7dde",
   "metadata": {},
   "source": [
    "### category1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c27bb42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 상태 확인:\n",
      "필터링된 데이터 개수: 3359\n",
      "벡터 타입: <class 'list'>\n",
      "벡터 길이: 1024\n",
      "벡터가 리스트 형태입니다. 직접 변환합니다...\n",
      "X shape: (3359, 1024)\n",
      "y shape: (3359,)\n",
      "✅ X와 y의 크기가 일치합니다!\n",
      "✅ 성공적으로 변환되었습니다!\n"
     ]
    }
   ],
   "source": [
    "# 필터링된 데이터로 벡터와 라벨 생성\n",
    "print(\"데이터 상태 확인:\")\n",
    "print(f\"필터링된 데이터 개수: {len(data)}\")\n",
    "print(f\"벡터 타입: {type(data['vector'].iloc[0])}\")\n",
    "print(f\"벡터 길이: {len(data['vector'].iloc[0])}\")\n",
    "\n",
    "# 벡터가 이미 리스트 형태라면 직접 numpy array로 변환\n",
    "if isinstance(data['vector'].iloc[0], list):\n",
    "    print(\"벡터가 리스트 형태입니다. 직접 변환합니다...\")\n",
    "    X = np.vstack(data['vector'].values)\n",
    "    y = data['re_category1'].values  # 변경: category1 → re_category1\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    \n",
    "    # 크기 일치 확인\n",
    "    if X.shape[0] == y.shape[0]:\n",
    "        print(\"✅ X와 y의 크기가 일치합니다!\")\n",
    "    else:\n",
    "        print(f\"❌ 크기 불일치: X {X.shape[0]} vs y {y.shape[0]}\")\n",
    "    \n",
    "    print(\"✅ 성공적으로 변환되었습니다!\")\n",
    "else:\n",
    "    print(\"벡터 형태에 문제가 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "wqea3alqoni",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 실제 test_data 로드 및 평가\n",
      "\n",
      "테스트 데이터 기본 정보:\n",
      "데이터 크기: (664, 5)\n",
      "컬럼들: ['index', 'context', 'annotations_split', 'category1', 'category2']\n",
      "\n",
      "데이터 샘플:\n",
      "   index  \\\n",
      "0      0   \n",
      "1      1   \n",
      "2      2   \n",
      "3      3   \n",
      "4      4   \n",
      "\n",
      "                                                                                              context  \\\n",
      "0                                            보는동안 너무 행복했고 초콜렛이 너무 먹고싶었고 티모시가 잘생겼고 울어!!하는부분이 있어서 울었다네요   \n",
      "1                                            어릴 때 가 보고 빕스는 거의 처음인데(기억에 없음) 지금 딸기축제 기간이라 만족스러운 식사 하고 옴   \n",
      "2  미리 계좌로 환전해둔 돈을 해외에서 환전수수료 없이 인출 가능한 트레블로그라는 카드인데, 선택할 수 있는 디자인 중에 이 여권 스타일이 너무 센스 있고 유니크해서 마음에 든다.   \n",
      "3                                                   요즘 번아웃도 자꾸 올라오고 무기력해서 종강하고 교류하기도 버거운 상태가 와부렀으요ㅠㅠ    \n",
      "4                                    크라임씬 장똥민이 범행 도구 찾으려고 화장실 탱크 뒤지는데 거기에 진짜 똥 넣어놓은 거 진짜 웃겨 뒤지겠음ㅋㅋㅋㅋㅋ   \n",
      "\n",
      "                                                                  annotations_split  \\\n",
      "0         [['기쁨', '만족감'], ['기쁨', '만족감'], ['기쁨', '감동'], ['기쁨', '감동'], ['기쁨', '만족감']]   \n",
      "1       [['기쁨', '만족감'], ['기쁨', '만족감'], ['기쁨', '만족감'], ['기쁨', '만족감'], ['기쁨', '만족감']]   \n",
      "2       [['기쁨', '만족감'], ['기쁨', '만족감'], ['기쁨', '만족감'], ['기쁨', '만족감'], ['기쁨', '만족감']]   \n",
      "3  [['슬픔', '무기력'], ['싫어함(상태)', '무기력'], ['슬픔', '무기력'], ['슬픔', '무기력'], ['슬픔', '무기력']]   \n",
      "4       [['기쁨', '즐거움'], ['기쁨', '통쾌함'], ['기쁨', '통쾌함'], ['기쁨', '즐거움'], ['기쁨', '즐거움']]   \n",
      "\n",
      "  category1 category2  \n",
      "0        기쁨       만족감  \n",
      "1        기쁨       만족감  \n",
      "2        기쁨       만족감  \n",
      "3        슬픔       무기력  \n",
      "4        기쁨       즐거움  \n",
      "\n",
      "test_data 컬럼 확인:\n",
      "- index: int64\n",
      "- context: object\n",
      "- annotations_split: object\n",
      "- category1: object\n",
      "- category2: object\n",
      "\n",
      "식별된 컬럼:\n",
      "텍스트 컬럼: context\n",
      "Category1 컬럼: category1\n",
      "\n",
      "✅ 필요한 컬럼들을 찾았습니다!\n",
      "테스트 데이터 개수: 664\n",
      "Category1 클래스들: ['기쁨' '슬픔' '싫어함(상태)' '미움(상대방)' '두려움' '수치심' '욕망' '분노' '사랑' '중립']\n"
     ]
    }
   ],
   "source": [
    "# 9. 실제 test_data로 모델 성능 평가\n",
    "\n",
    "print(\"📁 실제 test_data 로드 및 평가\\n\")\n",
    "\n",
    "# test_data 로드\n",
    "test_data = pd.read_excel(r'C:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\data\\증강할데이터33.xlsx')\n",
    "print(\"테스트 데이터 기본 정보:\")\n",
    "print(f\"데이터 크기: {test_data.shape}\")\n",
    "print(f\"컬럼들: {list(test_data.columns)}\")\n",
    "print(\"\\n데이터 샘플:\")\n",
    "print(test_data.head())\n",
    "\n",
    "# test_data에서 텍스트와 category1 컬럼 확인\n",
    "print(f\"\\ntest_data 컬럼 확인:\")\n",
    "for col in test_data.columns:\n",
    "    print(f\"- {col}: {test_data[col].dtype}\")\n",
    "\n",
    "# 텍스트 컬럼과 category1 컬럼 식별 (컬럼명에 따라 조정 필요)\n",
    "text_column = None\n",
    "category1_column = None\n",
    "\n",
    "# 가능한 텍스트 컬럼명들\n",
    "possible_text_columns = ['context', 'text', 'content', 'sentence', '내용', '문장']\n",
    "for col in test_data.columns:\n",
    "    if any(keyword in col.lower() for keyword in possible_text_columns):\n",
    "        text_column = col\n",
    "        break\n",
    "\n",
    "# 가능한 category1 컬럼명들\n",
    "possible_cat1_columns = ['category1', 'cat1', 'label', '감정', '카테고리1']\n",
    "for col in test_data.columns:\n",
    "    if any(keyword in col.lower() for keyword in possible_cat1_columns):\n",
    "        category1_column = col\n",
    "        break\n",
    "\n",
    "print(f\"\\n식별된 컬럼:\")\n",
    "print(f\"텍스트 컬럼: {text_column}\")\n",
    "print(f\"Category1 컬럼: {category1_column}\")\n",
    "\n",
    "if text_column and category1_column:\n",
    "    print(f\"\\n✅ 필요한 컬럼들을 찾았습니다!\")\n",
    "    print(f\"테스트 데이터 개수: {len(test_data)}\")\n",
    "    print(f\"Category1 클래스들: {test_data[category1_column].unique()}\")\n",
    "else:\n",
    "    print(f\"\\n❌ 필요한 컬럼을 찾을 수 없습니다. 수동으로 지정해주세요.\")\n",
    "    print(\"사용 가능한 컬럼들:\")\n",
    "    for i, col in enumerate(test_data.columns):\n",
    "        print(f\"{i}: {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "mqo1whwl3l",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 테스트 데이터 벡터 생성 및 라벨 준비...\n",
      "테스트 텍스트 샘플:\n",
      "1. 보는동안 너무 행복했고 초콜렛이 너무 먹고싶었고 티모시가 잘생겼고 울어!!하는부분이 있어서 울었다네요...\n",
      "2. 어릴 때 가 보고 빕스는 거의 처음인데(기억에 없음) 지금 딸기축제 기간이라 만족스러운 식사 하고 옴...\n",
      "3. 미리 계좌로 환전해둔 돈을 해외에서 환전수수료 없이 인출 가능한 트레블로그라는 카드인데, 선택할 수 있는 디자인 중에 이 여권 스타일이 너무 센스 있고 유니크해서 마음에 든다....\n",
      "\n",
      "📊 테스트 데이터 벡터화 중...\n",
      "✅ 테스트 데이터 준비 완료:\n",
      "test_X shape: (664, 1024)\n",
      "test_y_actual shape: (664,)\n",
      "test_y_actual_cat2 shape: (664,)\n",
      "테스트 데이터 category1 클래스: 10개\n",
      "테스트 데이터 category2 클래스: 64개\n"
     ]
    }
   ],
   "source": [
    "# 테스트 데이터를 위한 벡터 생성 및 라벨 준비\n",
    "print(f\"\\n🔧 테스트 데이터 벡터 생성 및 라벨 준비...\")\n",
    "\n",
    "# 테스트 데이터에서 벡터 생성\n",
    "test_texts = test_data['context'].values\n",
    "print(f\"테스트 텍스트 샘플:\")\n",
    "for i in range(3):\n",
    "    print(f\"{i+1}. {test_texts[i][:100]}...\")\n",
    "\n",
    "print(f\"\\n📊 테스트 데이터 벡터화 중...\")\n",
    "test_vectors = [embeddings_model.encode(text).tolist() for text in test_texts]\n",
    "test_X = np.array(test_vectors)\n",
    "\n",
    "# 테스트 라벨 준비\n",
    "test_y_actual = test_data['category1'].values\n",
    "test_y_actual_cat2 = test_data['category2'].values\n",
    "\n",
    "print(f\"✅ 테스트 데이터 준비 완료:\")\n",
    "print(f\"test_X shape: {test_X.shape}\")\n",
    "print(f\"test_y_actual shape: {test_y_actual.shape}\")\n",
    "print(f\"test_y_actual_cat2 shape: {test_y_actual_cat2.shape}\")\n",
    "print(f\"테스트 데이터 category1 클래스: {len(np.unique(test_y_actual))}개\")\n",
    "print(f\"테스트 데이터 category2 클래스: {len(np.unique(test_y_actual_cat2))}개\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "89mic30g7jg",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🤖 복합 라벨 방식 AutoGluon 모델 훈련 시작...\n",
      "✅ AutoGluon 라이브러리 로드 성공\n",
      "복합 라벨 예시: ['기쁨_감동' '기쁨_감동' '기쁨_감동' '기쁨_감동' '기쁨_감동']\n",
      "총 복합 라벨 종류: 76개\n",
      "\n",
      "📈 복합 라벨 상위 10개 분포:\n",
      "슬픔_무기력      98\n",
      "수치심_부끄러움    96\n",
      "슬픔_외로움      90\n",
      "기쁨_기대감      84\n",
      "두려움_놀람      83\n",
      "기쁨_공감       83\n",
      "기쁨_편안함      80\n",
      "슬픔_허망       78\n",
      "기쁨_안정감      73\n",
      "분노_불쾌       72\n",
      "Name: count, dtype: int64\n",
      "\n",
      "⚠️ 희소한 라벨 (7개): ['중립_공감', '수치심_수치심', '미움(상대방)_불쾌', '슬픔_답답함', '슬픔_죄책감', '사랑_공감', '슬픔_공감']\n",
      "이러한 라벨들은 훈련이 어려울 수 있습니다.\n",
      "\n",
      "📊 AutoGluon 훈련 데이터 준비...\n",
      "훈련 데이터 크기: (3359, 1025)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Verbosity: 2 (Standard Logging)\n",
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.4.0\n",
      "Python Version:     3.12.11\n",
      "Operating System:   Windows\n",
      "Platform Machine:   AMD64\n",
      "Platform Version:   10.0.19045\n",
      "CPU Count:          16\n",
      "Memory Avail:       14.78 GB / 31.91 GB (46.3%)\n",
      "Disk Space Avail:   73.07 GB / 465.12 GB (15.7%)\n",
      "===================================================\n",
      "Presets specified: ['best_quality']\n",
      "Using hyperparameters preset: hyperparameters='default'\n",
      "Setting dynamic_stacking from 'auto' to True. Reason: Enable dynamic_stacking when use_bag_holdout is disabled. (use_bag_holdout=False)\n",
      "Stack configuration (auto_stack=True): num_stack_levels=2, num_bag_folds=5, num_bag_sets=1\n",
      "DyStack is enabled (dynamic_stacking=True). AutoGluon will try to determine whether the input data is affected by stacked overfitting and enable or disable stacking as a consequence.\n",
      "\tThis is used to identify the optimal `num_stack_levels` value. Copies of AutoGluon will be fit on subsets of the data. Then holdout validation data is used to detect stacked overfitting.\n",
      "\tRunning DyStack for up to 150s of the 600s of remaining time (25%).\n",
      "\t\tContext path: \"c:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\autogluon_combined_f1_model\\ds_sub_fit\\sub_fit_ho\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기존 모델 폴더 autogluon_combined_f1_model 삭제됨\n",
      "\n",
      "🚀 AutoGluon F1-Score 최적화 모델 훈련 시작...\n",
      "============================================================\n",
      "복합 라벨 모델들 훈련 중... (예상 소요 시간: 5-10분)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Leaderboard on holdout data (DyStack):\n",
      "                    model  score_holdout  score_val eval_metric  pred_time_test  pred_time_val    fit_time  pred_time_test_marginal  pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  fit_order\n",
      "0     WeightedEnsemble_L2       0.611152   0.626684    f1_macro        1.280977       0.348022   54.318815                 0.004001                0.003001           0.272061            2       True          4\n",
      "1  NeuralNetFastAI_BAG_L1       0.608330   0.622798    f1_macro        1.072931       0.185041   14.538218                 1.072931                0.185041          14.538218            1       True          1\n",
      "2     WeightedEnsemble_L4       0.605447   0.637328    f1_macro        1.531044       0.692788   95.697352                 0.007002                0.004000           0.352452            4       True         10\n",
      "3  NeuralNetFastAI_BAG_L3       0.587420   0.610210    f1_macro        1.692081       0.909314  109.469433                 0.168039                0.220526          14.124533            3       True          8\n",
      "4  NeuralNetFastAI_BAG_L2       0.581237   0.619527    f1_macro        1.430011       0.582268   68.185716                 0.153035                0.237247          14.138962            2       True          5\n",
      "5     WeightedEnsemble_L3       0.580401   0.620483    f1_macro        1.527043       0.692788   95.549434                 0.003001                0.004000           0.204534            3       True          7\n",
      "6       LightGBMXT_BAG_L2       0.496096   0.430220    f1_macro        1.371008       0.451540   81.205938                 0.094031                0.106520          27.159184            2       True          6\n",
      "7       LightGBMXT_BAG_L3       0.458464   0.358741    f1_macro        1.594057       0.763795  103.127346                 0.070014                0.075007           7.782446            3       True          9\n",
      "8       LightGBMXT_BAG_L1       0.446330   0.374656    f1_macro        0.162036       0.109023   35.847080                 0.162036                0.109023          35.847080            1       True          2\n",
      "9         LightGBM_BAG_L1       0.209314   0.197870    f1_macro        0.042010       0.050956    3.661456                 0.042010                0.050956           3.661456            1       True          3\n",
      "\t0\t = Optimal   num_stack_levels (Stacked Overfitting Occurred: True)\n",
      "\t163s\t = DyStack   runtime |\t437s\t = Remaining runtime\n",
      "Starting main fit with num_stack_levels=0.\n",
      "\tFor future fit calls on this dataset, you can skip DyStack to save time: `predictor.fit(..., dynamic_stacking=False, num_stack_levels=0)`\n",
      "Beginning AutoGluon training ... Time limit = 437s\n",
      "AutoGluon will save models to \"c:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\autogluon_combined_f1_model\"\n",
      "Train Data Rows:    3359\n",
      "Train Data Columns: 1024\n",
      "Label Column:       combined_label\n",
      "Problem Type:       multiclass\n",
      "Preprocessing data ...\n",
      "Warning: Some classes in the training set have fewer than 10 examples. AutoGluon will only keep 67 out of 76 classes for training and will not try to predict the rare classes. To keep more classes, increase the number of datapoints from these rare classes in the training data or reduce label_count_threshold.\n",
      "Fraction of data from classes with at least 10 examples that will be kept for training models: 0.9937481393271808\n",
      "Train Data Class Count: 67\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    15057.08 MB\n",
      "\tTrain Data (Original)  Memory Usage: 26.08 MB (0.2% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tStage 5 Generators:\n",
      "\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1024 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 1024 | ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4', ...]\n",
      "\t5.0s = Fit runtime\n",
      "\t1024 features in original data used to generate 1024 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 26.08 MB (0.2% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 5.11s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1_macro'\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "User-specified model hyperparameters to be fit:\n",
      "{\n",
      "\t'NN_TORCH': [{}],\n",
      "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
      "\t'CAT': [{}],\n",
      "\t'XGB': [{}],\n",
      "\t'FASTAI': [{}],\n",
      "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
      "}\n",
      "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ... Training model for up to 432.16s of the 432.15s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=1.87%)\n",
      "\t0.6115\t = Validation score   (f1_macro)\n",
      "\t14.38s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBMXT_BAG_L1 ... Training model for up to 414.04s of the 414.04s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=7.02%)\n",
      "\t0.5382\t = Validation score   (f1_macro)\n",
      "\t334.31s\t = Training   runtime\n",
      "\t0.74s\t = Validation runtime\n",
      "Fitting model: LightGBM_BAG_L1 ... Training model for up to 76.16s of the 76.16s of remaining time.\n",
      "\tFitting 5 child models (S1F1 - S1F5) | Fitting with ParallelLocalFoldFittingStrategy (5 workers, per: cpus=3, gpus=0, memory=6.47%)\n",
      "\t0.3453\t = Validation score   (f1_macro)\n",
      "\t63.54s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Fitting model: RandomForestGini_BAG_L1 ... Training model for up to 9.53s of the 9.52s of remaining time.\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 106 due to low time. Expected time usage reduced from 24.9s -> 9.1s...\n",
      "\t0.3719\t = Validation score   (f1_macro)\n",
      "\t3.57s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr_BAG_L1 ... Training model for up to 5.26s of the 5.25s of remaining time.\n",
      "\tWarning: Model is expected to require 56.2s to train, which exceeds the maximum time limit of 4.9s, skipping model...\n",
      "\tTime limit exceeded... Skipping RandomForestEntr_BAG_L1.\n",
      "Fitting model: WeightedEnsemble_L2 ... Training model for up to 360.00s of the 3.35s of remaining time.\n",
      "\tEnsemble Weights: {'NeuralNetFastAI_BAG_L1': 0.455, 'RandomForestGini_BAG_L1': 0.364, 'LightGBMXT_BAG_L1': 0.182}\n",
      "\t0.6213\t = Validation score   (f1_macro)\n",
      "\t0.36s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 434.34s ... Best model: WeightedEnsemble_L2 | Estimated inference throughput: 672.9 rows/s (668 batch size)\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"c:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\autogluon_combined_f1_model\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ AutoGluon 복합 라벨 모델 훈련 완료!\n",
      "\n",
      "📋 AutoGluon 모델 리더보드 (F1-macro 기준):\n",
      "                     model  score_val eval_metric  pred_time_val    fit_time  \\\n",
      "0      WeightedEnsemble_L2   0.621278    f1_macro       1.250298  352.629694   \n",
      "1   NeuralNetFastAI_BAG_L1   0.611499    f1_macro       0.189046   14.384632   \n",
      "2        LightGBMXT_BAG_L1   0.538246    f1_macro       0.739181  334.311806   \n",
      "3  RandomForestGini_BAG_L1   0.371932    f1_macro       0.319072    3.574869   \n",
      "4          LightGBM_BAG_L1   0.345299    f1_macro       0.142033   63.536590   \n",
      "\n",
      "   pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
      "0                0.003000           0.358388            2       True   \n",
      "1                0.189046          14.384632            1       True   \n",
      "2                0.739181         334.311806            1       True   \n",
      "3                0.319072           3.574869            1       True   \n",
      "4                0.142033          63.536590            1       True   \n",
      "\n",
      "   fit_order  \n",
      "0          5  \n",
      "1          1  \n",
      "2          2  \n",
      "3          4  \n",
      "4          3  \n",
      "\n",
      "🏆 최고 성능 모델: WeightedEnsemble_L2\n",
      "검증 F1-macro Score: 0.6213\n",
      "\n",
      "🎯 AutoGluon 모델로 테스트 데이터 예측...\n",
      "✅ AutoGluon 모델 예측 완료!\n",
      "\n",
      "📊 AutoGluon 복합 라벨 모델 성능:\n",
      "==================================================\n",
      "정확도:\n",
      "  Category1: 0.5331 (53.31%)\n",
      "  Category2: 0.3434 (34.34%)\n",
      "  복합 라벨: 0.3208 (32.08%)\n",
      "\n",
      "F1-Score (macro):\n",
      "  Category1: 0.3936\n",
      "  Category2: 0.2410\n",
      "  복합 라벨: 0.2134\n",
      "\n",
      "🎯 두 카테고리 모두 정답: 0.3208 (32.08%)\n",
      "정답 개수: 213/664\n",
      "\n",
      "✅ AutoGluon F1-최적화 모델 성능 평가 완료!\n",
      "\n",
      "💾 모델 저장 위치: autogluon_combined_f1_model\n",
      "📥 모델 재로드 방법:\n",
      "combined_predictor = TabularPredictor.load('autogluon_combined_f1_model')\n",
      "\n",
      "🎉 최종 성과 요약:\n",
      "🏆 최고 성능 모델: WeightedEnsemble_L2\n",
      "📈 검증 F1-macro: 0.6213\n",
      "📊 테스트 F1-macro: 0.2134\n",
      "🎯 두 카테고리 동시 정답률: 32.08%\n"
     ]
    }
   ],
   "source": [
    "# 복합 라벨 방식 AutoGluon 모델 훈련\n",
    "print(f\"\\n🤖 복합 라벨 방식 AutoGluon 모델 훈련 시작...\")\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "try:\n",
    "    from autogluon.tabular import TabularPredictor\n",
    "    print(\"✅ AutoGluon 라이브러리 로드 성공\")\n",
    "    autogluon_available = True\n",
    "except ImportError:\n",
    "    print(\"❌ AutoGluon이 설치되지 않았습니다. 다음 명령으로 설치하세요:\")\n",
    "    print(\"pip install autogluon\")\n",
    "    autogluon_available = False\n",
    "    raise ImportError(\"AutoGluon이 필요합니다\")\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 복합 라벨 생성\n",
    "combined_labels = y + \"_\" + data['re_category2'].values\n",
    "print(f\"복합 라벨 예시: {combined_labels[:5]}\")\n",
    "print(f\"총 복합 라벨 종류: {len(np.unique(combined_labels))}개\")\n",
    "\n",
    "# 복합 라벨 분포 확인\n",
    "label_counts = pd.Series(combined_labels).value_counts()\n",
    "print(f\"\\n📈 복합 라벨 상위 10개 분포:\")\n",
    "print(label_counts.head(10))\n",
    "\n",
    "# 희소한 라벨 확인 (3개 미만)\n",
    "rare_labels = label_counts[label_counts < 3]\n",
    "if len(rare_labels) > 0:\n",
    "    print(f\"\\n⚠️ 희소한 라벨 ({len(rare_labels)}개): {list(rare_labels.index[:10])}\")\n",
    "    print(\"이러한 라벨들은 훈련이 어려울 수 있습니다.\")\n",
    "\n",
    "# AutoGluon용 훈련 데이터 준비\n",
    "print(f\"\\n📊 AutoGluon 훈련 데이터 준비...\")\n",
    "train_combined_df = pd.DataFrame(X, columns=[f'feature_{i}' for i in range(X.shape[1])])\n",
    "train_combined_df['combined_label'] = combined_labels\n",
    "\n",
    "print(f\"훈련 데이터 크기: {train_combined_df.shape}\")\n",
    "\n",
    "# AutoGluon 모델 저장 경로\n",
    "combined_save_path = \"autogluon_combined_f1_model\"\n",
    "if os.path.exists(combined_save_path):\n",
    "    import shutil\n",
    "    shutil.rmtree(combined_save_path)\n",
    "    print(f\"기존 모델 폴더 {combined_save_path} 삭제됨\")\n",
    "\n",
    "# AutoGluon 복합 라벨 모델 훈련 (F1 스코어 최적화)\n",
    "print(f\"\\n🚀 AutoGluon F1-Score 최적화 모델 훈련 시작...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "combined_predictor = TabularPredictor(\n",
    "    label='combined_label',\n",
    "    path=combined_save_path,\n",
    "    eval_metric='f1_macro',  # F1-macro 점수로 최적화\n",
    "    problem_type='multiclass'\n",
    ")\n",
    "\n",
    "print(\"복합 라벨 모델들 훈련 중... (예상 소요 시간: 5-10분)\")\n",
    "combined_predictor = combined_predictor.fit(\n",
    "    train_data=train_combined_df,\n",
    "    time_limit=600,  # 10분 제한 (더 좋은 성능을 위해)\n",
    "    presets='best_quality',  # 최고 품질 프리셋\n",
    "    num_bag_folds=5,  # 5-fold 교차 검증\n",
    "    num_bag_sets=1,\n",
    "    num_stack_levels=2,  # 스태킹 레벨 증가\n",
    "    hyperparameters='default'  # 다중 클래스 최적화\n",
    ")\n",
    "\n",
    "print(\"✅ AutoGluon 복합 라벨 모델 훈련 완료!\")\n",
    "\n",
    "# 모델 리더보드 출력\n",
    "print(f\"\\n📋 AutoGluon 모델 리더보드 (F1-macro 기준):\")\n",
    "leaderboard = combined_predictor.leaderboard()\n",
    "print(leaderboard.head(10))\n",
    "\n",
    "# 최고 성능 모델 정보\n",
    "best_model = leaderboard.iloc[0]['model']\n",
    "best_f1_score = leaderboard.iloc[0]['score_val']\n",
    "print(f\"\\n🏆 최고 성능 모델: {best_model}\")\n",
    "print(f\"검증 F1-macro Score: {best_f1_score:.4f}\")\n",
    "\n",
    "# 테스트 데이터 예측\n",
    "print(f\"\\n🎯 AutoGluon 모델로 테스트 데이터 예측...\")\n",
    "test_combined_df = pd.DataFrame(test_X, columns=[f'feature_{i}' for i in range(test_X.shape[1])])\n",
    "\n",
    "# 예측 수행\n",
    "test_pred_combined_labels = combined_predictor.predict(test_combined_df)\n",
    "test_pred_proba = combined_predictor.predict_proba(test_combined_df)\n",
    "\n",
    "print(f\"✅ AutoGluon 모델 예측 완료!\")\n",
    "\n",
    "# 예측된 복합 라벨을 개별 카테고리로 분리\n",
    "test_pred_split = test_pred_combined_labels.str.split('_', expand=True)\n",
    "test_pred_cat1 = test_pred_split[0].values\n",
    "test_pred_cat2 = test_pred_split[1].values\n",
    "\n",
    "# 실제 라벨도 복합 라벨 형태로 생성 (비교용)\n",
    "test_actual_combined_labels = test_y_actual + \"_\" + test_y_actual_cat2\n",
    "\n",
    "# 성능 평가\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "cat1_accuracy = accuracy_score(test_y_actual, test_pred_cat1)\n",
    "cat2_accuracy = accuracy_score(test_y_actual_cat2, test_pred_cat2)\n",
    "combined_accuracy = accuracy_score(test_actual_combined_labels, test_pred_combined_labels)\n",
    "\n",
    "# F1 스코어 계산\n",
    "f1_cat1 = f1_score(test_y_actual, test_pred_cat1, average='macro')\n",
    "f1_cat2 = f1_score(test_y_actual_cat2, test_pred_cat2, average='macro') \n",
    "f1_combined = f1_score(test_actual_combined_labels, test_pred_combined_labels, average='macro')\n",
    "\n",
    "print(f\"\\n📊 AutoGluon 복합 라벨 모델 성능:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"정확도:\")\n",
    "print(f\"  Category1: {cat1_accuracy:.4f} ({cat1_accuracy*100:.2f}%)\")\n",
    "print(f\"  Category2: {cat2_accuracy:.4f} ({cat2_accuracy*100:.2f}%)\")\n",
    "print(f\"  복합 라벨: {combined_accuracy:.4f} ({combined_accuracy*100:.2f}%)\")\n",
    "\n",
    "print(f\"\\nF1-Score (macro):\")\n",
    "print(f\"  Category1: {f1_cat1:.4f}\")\n",
    "print(f\"  Category2: {f1_cat2:.4f}\")\n",
    "print(f\"  복합 라벨: {f1_combined:.4f}\")\n",
    "\n",
    "# 두 카테고리 모두 정답인 경우\n",
    "both_correct = (test_pred_cat1 == test_y_actual) & (test_pred_cat2 == test_y_actual_cat2)\n",
    "both_accuracy = both_correct.mean()\n",
    "print(f\"\\n🎯 두 카테고리 모두 정답: {both_accuracy:.4f} ({both_accuracy*100:.2f}%)\")\n",
    "print(f\"정답 개수: {both_correct.sum()}/{len(test_y_actual)}\")\n",
    "\n",
    "print(f\"\\n✅ AutoGluon F1-최적화 모델 성능 평가 완료!\")\n",
    "\n",
    "# 모델 저장 정보\n",
    "print(f\"\\n💾 모델 저장 위치: {combined_save_path}\")\n",
    "print(f\"📥 모델 재로드 방법:\")\n",
    "print(f\"combined_predictor = TabularPredictor.load('{combined_save_path}')\")\n",
    "\n",
    "# 최종 성과 요약\n",
    "print(f\"\\n🎉 최종 성과 요약:\")\n",
    "print(f\"🏆 최고 성능 모델: {best_model}\")\n",
    "print(f\"📈 검증 F1-macro: {best_f1_score:.4f}\")\n",
    "print(f\"📊 테스트 F1-macro: {f1_combined:.4f}\")\n",
    "print(f\"🎯 두 카테고리 동시 정답률: {both_accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tbujoi3bkj",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 AutoGluon 복합 라벨 모델 데모 텍스트 예측 시스템\n",
      "============================================================\n",
      "🌟 AutoGluon 복합 라벨 모델을 사용한 감정 텍스트 예측 데모:\n",
      "총 7개의 예시 텍스트로 감정 예측을 수행합니다.\n",
      "🏆 사용 모델: WeightedEnsemble_L2 (F1-macro: 0.6213)\n",
      "================================================================================\n",
      "[예시 1]\n",
      "📝 입력 텍스트: 손수 만든 작은 포장을 끝냈다. 계획대로 마무리돼 마음속으로 은근히 기뻤다.\n",
      "🎯 AutoGluon 예측 결과:\n",
      "   복합 라벨: 기쁨_만족감 (신뢰도: 0.609)\n",
      "   Category1 (대분류): 기쁨\n",
      "   Category2 (세분류): 만족감\n",
      "📊 상위 5개 복합 라벨 후보:\n",
      "   1. 기쁨_만족감 (기쁨|만족감): 0.609\n",
      "   2. 기쁨_기대감 (기쁨|기대감): 0.084\n",
      "   3. 기쁨_자랑스러움 (기쁨|자랑스러움): 0.033\n",
      "   4. 기쁨_감동 (기쁨|감동): 0.018\n",
      "   5. 슬픔_외로움 (슬픔|외로움): 0.014\n",
      "\n",
      "[예시 2]\n",
      "📝 입력 텍스트: 학습 노트를 마치고 정리했다. 차곡차곡 쌓인 흔적이 마음속으로 만족스러웠다.\n",
      "🎯 AutoGluon 예측 결과:\n",
      "   복합 라벨: 기쁨_만족감 (신뢰도: 0.541)\n",
      "   Category1 (대분류): 기쁨\n",
      "   Category2 (세분류): 만족감\n",
      "📊 상위 5개 복합 라벨 후보:\n",
      "   1. 기쁨_만족감 (기쁨|만족감): 0.541\n",
      "   2. 기쁨_자랑스러움 (기쁨|자랑스러움): 0.049\n",
      "   3. 기쁨_자신감 (기쁨|자신감): 0.028\n",
      "   4. 기쁨_고마움 (기쁨|고마움): 0.028\n",
      "   5. 기쁨_기대감 (기쁨|기대감): 0.023\n",
      "\n",
      "[예시 3]\n",
      "📝 입력 텍스트: 작은 모형 배를 조립해 완성했다. 계획대로 맞아 마음이 은은히 기뻤다.\n",
      "🎯 AutoGluon 예측 결과:\n",
      "   복합 라벨: 기쁨_만족감 (신뢰도: 0.641)\n",
      "   Category1 (대분류): 기쁨\n",
      "   Category2 (세분류): 만족감\n",
      "📊 상위 5개 복합 라벨 후보:\n",
      "   1. 기쁨_만족감 (기쁨|만족감): 0.641\n",
      "   2. 기쁨_기대감 (기쁨|기대감): 0.071\n",
      "   3. 기쁨_자랑스러움 (기쁨|자랑스러움): 0.025\n",
      "   4. 기쁨_감동 (기쁨|감동): 0.022\n",
      "   5. 기쁨_공감 (기쁨|공감): 0.018\n",
      "\n",
      "[예시 4]\n",
      "📝 입력 텍스트: 인파가 북적이는 지하철역 입구에서 큰 소리로 침을 뱉으며 지나가는 사람들이 짜증이 났다.\n",
      "🎯 AutoGluon 예측 결과:\n",
      "   복합 라벨: 미움(상대방)_비위상함 (신뢰도: 0.750)\n",
      "   Category1 (대분류): 미움(상대방)\n",
      "   Category2 (세분류): 비위상함\n",
      "📊 상위 5개 복합 라벨 후보:\n",
      "   1. 미움(상대방)_비위상함 (미움(상대방)|비위상함): 0.750\n",
      "   2. 분노_불쾌 (분노|불쾌): 0.140\n",
      "   3. 싫어함(상태)_불편함 (싫어함(상태)|불편함): 0.025\n",
      "   4. 수치심_부끄러움 (수치심|부끄러움): 0.007\n",
      "   5. 사랑_두근거림 (사랑|두근거림): 0.007\n",
      "\n",
      "[예시 5]\n",
      "📝 입력 텍스트: 정말 믿음이 깨져버렸어. 아무리 약속해도 뒤통수를 맞는 기분, 이젠 누굴 믿어야 할지 모르겠어.\n",
      "🎯 AutoGluon 예측 결과:\n",
      "   복합 라벨: 미움(상대방)_불신감 (신뢰도: 0.860)\n",
      "   Category1 (대분류): 미움(상대방)\n",
      "   Category2 (세분류): 불신감\n",
      "📊 상위 5개 복합 라벨 후보:\n",
      "   1. 미움(상대방)_불신감 (미움(상대방)|불신감): 0.860\n",
      "   2. 분노_원망 (분노|원망): 0.014\n",
      "   3. 슬픔_실망 (슬픔|실망): 0.014\n",
      "   4. 슬픔_억울함 (슬픔|억울함): 0.010\n",
      "   5. 슬픔_절망 (슬픔|절망): 0.007\n",
      "\n",
      "[예시 6]\n",
      "📝 입력 텍스트: 저녁 모임에서 내 기여를 무시한 채 다른 사람이 칭찬받는 걸 보며 마음속에 차오르는 싸늘한 불쾌감이 멈추지 않았다.\n",
      "🎯 AutoGluon 예측 결과:\n",
      "   복합 라벨: 분노_불쾌 (신뢰도: 0.730)\n",
      "   Category1 (대분류): 분노\n",
      "   Category2 (세분류): 불쾌\n",
      "📊 상위 5개 복합 라벨 후보:\n",
      "   1. 분노_불쾌 (분노|불쾌): 0.730\n",
      "   2. 미움(상대방)_시기심 (미움(상대방)|시기심): 0.055\n",
      "   3. 슬픔_억울함 (슬픔|억울함): 0.026\n",
      "   4. 분노_원망 (분노|원망): 0.016\n",
      "   5. 슬픔_외로움 (슬픔|외로움): 0.012\n",
      "\n",
      "[예시 7]\n",
      "📝 입력 텍스트: 식당에서 그가 주문을 받고도 무표정하게 돌아서자, 나는 깊은 쓸쓸함과 함께 차가운 벽에 막힌 기분이 들었다.\n",
      "🎯 AutoGluon 예측 결과:\n",
      "   복합 라벨: 슬픔_외로움 (신뢰도: 0.777)\n",
      "   Category1 (대분류): 슬픔\n",
      "   Category2 (세분류): 외로움\n",
      "📊 상위 5개 복합 라벨 후보:\n",
      "   1. 슬픔_외로움 (슬픔|외로움): 0.777\n",
      "   2. 미움(상대방)_외면 (미움(상대방)|외면): 0.058\n",
      "   3. 미움(상대방)_냉담 (미움(상대방)|냉담): 0.020\n",
      "   4. 슬픔_실망 (슬픔|실망): 0.018\n",
      "   5. 슬픔_아픔 (슬픔|아픔): 0.008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# AutoGluon 복합 라벨 모델 데모 텍스트 예측 시스템\n",
    "print(\"🎯 AutoGluon 복합 라벨 모델 데모 텍스트 예측 시스템\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def predict_emotion_autogluon(text, predictor=combined_predictor, embedder=embeddings_model):\n",
    "    \"\"\"\n",
    "    AutoGluon 복합 라벨 모델을 사용하여 입력 텍스트의 감정을 예측하는 함수\n",
    "    \n",
    "    Args:\n",
    "        text (str): 예측할 텍스트\n",
    "        predictor: AutoGluon 예측기\n",
    "        embedder: 텍스트 임베딩 모델\n",
    "    \n",
    "    Returns:\n",
    "        dict: 예측 결과\n",
    "    \"\"\"\n",
    "    # 텍스트를 벡터로 변환\n",
    "    text_vector = embedder.encode(text)\n",
    "    \n",
    "    # AutoGluon 입력 형태로 변환\n",
    "    text_df = pd.DataFrame([text_vector], columns=[f'feature_{i}' for i in range(len(text_vector))])\n",
    "    \n",
    "    # 복합 라벨 예측\n",
    "    combined_pred = predictor.predict(text_df).iloc[0]\n",
    "    \n",
    "    # 예측 확률\n",
    "    pred_proba = predictor.predict_proba(text_df)\n",
    "    combined_confidence = pred_proba.iloc[0].max()\n",
    "    \n",
    "    # 복합 라벨을 개별 카테고리로 분리\n",
    "    cat1_pred, cat2_pred = combined_pred.split('_')\n",
    "    \n",
    "    # 상위 5개 복합 라벨 후보\n",
    "    top5_proba = pred_proba.iloc[0].nlargest(5)\n",
    "    top5_predictions = [(label, score) for label, score in top5_proba.items()]\n",
    "    \n",
    "    return {\n",
    "        'text': text,\n",
    "        'combined_label': combined_pred,\n",
    "        'category1': cat1_pred,\n",
    "        'category2': cat2_pred,\n",
    "        'confidence': combined_confidence,\n",
    "        'top5_predictions': top5_predictions\n",
    "    }\n",
    "\n",
    "def print_autogluon_prediction(result):\n",
    "    \"\"\"AutoGluon 복합 라벨 예측 결과를 보기 좋게 출력하는 함수\"\"\"\n",
    "    print(f\"📝 입력 텍스트: {result['text']}\")\n",
    "    print(f\"🎯 AutoGluon 예측 결과:\")\n",
    "    print(f\"   복합 라벨: {result['combined_label']} (신뢰도: {result['confidence']:.3f})\")\n",
    "    print(f\"   Category1 (대분류): {result['category1']}\")\n",
    "    print(f\"   Category2 (세분류): {result['category2']}\")\n",
    "    \n",
    "    print(f\"📊 상위 5개 복합 라벨 후보:\")\n",
    "    for i, (label, score) in enumerate(result['top5_predictions']):\n",
    "        cat1, cat2 = label.split('_')\n",
    "        print(f\"   {i+1}. {label} ({cat1}|{cat2}): {score:.3f}\")\n",
    "    print()\n",
    "\n",
    "# 다양한 감정 표현 데모 텍스트들\n",
    "demo_texts = [\n",
    "    # \"오늘 친구가 생일선물을 깜짝 준비해줘서 정말 감동받았어요. 너무 고마워서 눈물이 났어요.\",\n",
    "    # \"시험에서 떨어져서 너무 실망스럽고 우울해요. 앞으로 어떻게 해야 할지 모르겠어요.\",\n",
    "    # \"새로운 직장에서 첫날인데 너무 떨려요. 잘할 수 있을까 걱정이 많이 돼요.\",\n",
    "    # \"연인과 헤어져서 너무 화나고 원망스러워요. 배신감이 들어서 잠도 못 자겠어요.\",\n",
    "    # \"로또에 당첨되어서 너무 기뻐요! 꿈만 같아서 믿기지가 않아요.\",\n",
    "    # \"새로운 취미를 시작하게 되어서 설레고 기대돼요. 뭔가 새로운 도전이라 흥미로워요.\",\n",
    "    # \"혼자 집에 있는데 갑자기 이상한 소리가 들려서 무서워요. 심장이 빨리 뛰어요.\",\n",
    "    # \"부모님께서 제 꿈을 응원해주셔서 너무 든든하고 사랑받는 기분이에요.\",\n",
    "    \"손수 만든 작은 포장을 끝냈다. 계획대로 마무리돼 마음속으로 은근히 기뻤다.\",\n",
    "    \"작은 모형 배를 조립해 완성했다. 계획대로 맞아 마음이 은은히 기뻤다.\",\n",
    "    \"인파가 북적이는 지하철역 입구에서 큰 소리로 침을 뱉으며 지나가는 사람들이 짜증이 났다.\",\n",
    "    \"정말 믿음이 깨져버렸어. 아무리 약속해도 뒤통수를 맞는 기분, 이젠 누굴 믿어야 할지 모르겠어.\",\n",
    "    \"저녁 모임에서 내 기여를 무시한 채 다른 사람이 칭찬받는 걸 보며 마음속에 차오르는 싸늘한 불쾌감이 멈추지 않았다.\",\n",
    "    \"식당에서 그가 주문을 받고도 무표정하게 돌아서자, 나는 깊은 쓸쓸함과 함께 차가운 벽에 막힌 기분이 들었다.\"\n",
    "]\n",
    "\n",
    "print(f\"🌟 AutoGluon 복합 라벨 모델을 사용한 감정 텍스트 예측 데모:\")\n",
    "print(f\"총 {len(demo_texts)}개의 예시 텍스트로 감정 예측을 수행합니다.\")\n",
    "print(f\"🏆 사용 모델: {best_model} (F1-macro: {best_f1_score:.4f})\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 각 데모 텍스트에 대해 AutoGluon 복합 라벨 예측 수행\n",
    "for i, demo_text in enumerate(demo_texts, 1):\n",
    "    print(f\"[예시 {i}]\")\n",
    "    result = predict_emotion_autogluon(demo_text)\n",
    "    print_autogluon_prediction(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ivgsrxka90q",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 AutoGluon 복합 라벨 모델을 사용한 사용자 입력 텍스트 감정 예측\n",
      "============================================================\n",
      "아래 코드를 수정해서 원하는 텍스트의 감정을 예측해보세요!\n",
      "\n",
      "🎨 사용자 입력 텍스트 예측:\n",
      "--------------------------------------------------\n",
      "📝 입력 텍스트: 친구들과 함께 여행을 가서 정말 즐거웠어요. 오랜만에 스트레스가 풀렸어요.\n",
      "🎯 AutoGluon 예측 결과:\n",
      "   복합 라벨: 기쁨_즐거움 (신뢰도: 0.331)\n",
      "   Category1 (대분류): 기쁨\n",
      "   Category2 (세분류): 즐거움\n",
      "📊 상위 5개 복합 라벨 후보:\n",
      "   1. 기쁨_즐거움 (기쁨|즐거움): 0.331\n",
      "   2. 기쁨_만족감 (기쁨|만족감): 0.131\n",
      "   3. 기쁨_편안함 (기쁨|편안함): 0.113\n",
      "   4. 기쁨_신명남 (기쁨|신명남): 0.038\n",
      "   5. 기쁨_공감 (기쁨|공감): 0.032\n",
      "\n",
      "💡 다른 텍스트로 테스트하려면:\n",
      "1. 위의 'custom_text' 변수에 원하는 텍스트를 입력하세요\n",
      "2. 셀을 다시 실행하세요\n",
      "\n",
      "📌 예측 함수 사용법:\n",
      "result = predict_emotion_autogluon('여기에 텍스트 입력')\n",
      "print_autogluon_prediction(result)\n",
      "\n",
      "📋 AutoGluon 복합 라벨 모델 정보 요약:\n",
      "============================================================\n",
      "📊 훈련 데이터: 3359개 샘플\n",
      "🏷️ 복합 라벨 클래스: 76개\n",
      "   - 예시: 기쁨_감동, 기쁨_고마움, 기쁨_공감, 기쁨_기대감, 기쁨_놀람, 기쁨_만족감, 기쁨_반가움, 기쁨_신뢰감, 기쁨_신명남, 기쁨_안정감...\n",
      "🤖 임베딩 모델: 1024차원\n",
      "🏆 최고 성능 모델: WeightedEnsemble_L2\n",
      "\n",
      "🎯 테스트 성능:\n",
      "   - Category1 정확도: 53.31%\n",
      "   - Category2 정확도: 34.34%\n",
      "   - 복합 라벨 정확도: 32.08%\n",
      "   - 두 카테고리 모두 정답: 32.08%\n",
      "\n",
      "📈 F1-Score (macro):\n",
      "   - Category1: 0.3936\n",
      "   - Category2: 0.2410\n",
      "   - 복합 라벨: 0.2134\n",
      "   - 검증 F1-macro: 0.6213\n",
      "\n",
      "🎯 AutoGluon 복합 라벨 모델의 장점:\n",
      "✅ F1-macro 점수 최적화로 불균형 클래스 성능 향상\n",
      "✅ 자동 하이퍼파라미터 튜닝 및 앙상블\n",
      "✅ 여러 알고리즘 조합으로 최고 성능 달성\n",
      "✅ 카테고리 간 의존성을 직접 학습\n",
      "✅ 5-fold 교차 검증으로 일반화 성능 보장\n",
      "✅ 스태킹 앙상블로 예측 안정성 향상\n",
      "\n",
      "💾 모델 재사용:\n",
      "모델 저장 위치: autogluon_combined_f1_model\n",
      "loaded_predictor = TabularPredictor.load('autogluon_combined_f1_model')\n",
      "prediction = loaded_predictor.predict(new_data)\n"
     ]
    }
   ],
   "source": [
    "# 사용자 입력 텍스트 예측 (AutoGluon 복합 라벨 모델)\n",
    "print(\"🔍 AutoGluon 복합 라벨 모델을 사용한 사용자 입력 텍스트 감정 예측\")\n",
    "print(\"=\"*60)\n",
    "print(\"아래 코드를 수정해서 원하는 텍스트의 감정을 예측해보세요!\")\n",
    "print()\n",
    "\n",
    "# 여기에 원하는 텍스트를 입력하세요\n",
    "custom_text = \"친구들과 함께 여행을 가서 정말 즐거웠어요. 오랜만에 스트레스가 풀렸어요.\"\n",
    "\n",
    "print(f\"🎨 사용자 입력 텍스트 예측:\")\n",
    "print(\"-\"*50)\n",
    "custom_result = predict_emotion_autogluon(custom_text)\n",
    "print_autogluon_prediction(custom_result)\n",
    "\n",
    "print(\"💡 다른 텍스트로 테스트하려면:\")\n",
    "print(\"1. 위의 'custom_text' 변수에 원하는 텍스트를 입력하세요\")\n",
    "print(\"2. 셀을 다시 실행하세요\")\n",
    "print()\n",
    "print(\"📌 예측 함수 사용법:\")\n",
    "print(\"result = predict_emotion_autogluon('여기에 텍스트 입력')\")\n",
    "print(\"print_autogluon_prediction(result)\")\n",
    "print()\n",
    "\n",
    "# AutoGluon 복합 라벨 모델 정보 요약\n",
    "print(\"📋 AutoGluon 복합 라벨 모델 정보 요약:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"📊 훈련 데이터: {len(data)}개 샘플\")\n",
    "print(f\"🏷️ 복합 라벨 클래스: {len(combined_predictor.class_labels)}개\")\n",
    "\n",
    "# 복합 라벨 클래스 예시 표시\n",
    "sample_labels = list(combined_predictor.class_labels)[:10]\n",
    "print(f\"   - 예시: {', '.join(sample_labels)}{'...' if len(combined_predictor.class_labels) > 10 else ''}\")\n",
    "\n",
    "print(f\"🤖 임베딩 모델: {embeddings_model.get_sentence_embedding_dimension()}차원\")\n",
    "print(f\"🏆 최고 성능 모델: {best_model}\")\n",
    "\n",
    "print(f\"\\n🎯 테스트 성능:\")\n",
    "print(f\"   - Category1 정확도: {cat1_accuracy*100:.2f}%\")\n",
    "print(f\"   - Category2 정확도: {cat2_accuracy*100:.2f}%\") \n",
    "print(f\"   - 복합 라벨 정확도: {combined_accuracy*100:.2f}%\")\n",
    "print(f\"   - 두 카테고리 모두 정답: {both_accuracy*100:.2f}%\")\n",
    "\n",
    "print(f\"\\n📈 F1-Score (macro):\")\n",
    "print(f\"   - Category1: {f1_cat1:.4f}\")\n",
    "print(f\"   - Category2: {f1_cat2:.4f}\")\n",
    "print(f\"   - 복합 라벨: {f1_combined:.4f}\")\n",
    "print(f\"   - 검증 F1-macro: {best_f1_score:.4f}\")\n",
    "\n",
    "print(f\"\\n🎯 AutoGluon 복합 라벨 모델의 장점:\")\n",
    "print(\"✅ F1-macro 점수 최적화로 불균형 클래스 성능 향상\")\n",
    "print(\"✅ 자동 하이퍼파라미터 튜닝 및 앙상블\")\n",
    "print(\"✅ 여러 알고리즘 조합으로 최고 성능 달성\")\n",
    "print(\"✅ 카테고리 간 의존성을 직접 학습\")\n",
    "print(\"✅ 5-fold 교차 검증으로 일반화 성능 보장\")\n",
    "print(\"✅ 스태킹 앙상블로 예측 안정성 향상\")\n",
    "\n",
    "print(f\"\\n💾 모델 재사용:\")\n",
    "print(f\"모델 저장 위치: {combined_save_path}\")\n",
    "print(\"loaded_predictor = TabularPredictor.load('autogluon_combined_f1_model')\")\n",
    "print(\"prediction = loaded_predictor.predict(new_data)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444e6c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
