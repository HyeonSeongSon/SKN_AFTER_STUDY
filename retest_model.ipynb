{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13495b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f72f27ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° í•„í„°ë§ ì „: 3360ê°œ\n",
      "re_category1ì—ì„œ ì¤‘ë¦½: 3ê°œ\n",
      "re_category2ì—ì„œ ì¤‘ë¦½: 1ê°œ\n",
      "ë°ì´í„° í•„í„°ë§ í›„: 3359ê°œ\n",
      "ì œê±°ëœ ë°ì´í„°: 1ê°œ\n",
      "ë‚¨ì€ re_category1 í´ë˜ìŠ¤ (10ê°œ): ['ê¸°ì¨', 'ë‘ë ¤ì›€', 'ë¯¸ì›€(ìƒëŒ€ë°©)', 'ë¶„ë…¸', 'ì‚¬ë‘', 'ìˆ˜ì¹˜ì‹¬', 'ìŠ¬í””', 'ì‹«ì–´í•¨(ìƒíƒœ)', 'ìš•ë§', 'ì¤‘ë¦½']\n",
      "ë‚¨ì€ re_category2 í´ë˜ìŠ¤ (64ê°œ): ['ê°ˆë“±', 'ê°ë™', 'ê±±ì •', 'ê²½ë©¸', 'ê³ ë§ˆì›€', 'ê³ í†µ', 'ê³µê°', 'ê³µí¬', 'ê¶ê¸ˆí•¨', 'ê·€ì¤‘í•¨', 'ê·¸ë¦¬ì›€', 'ê¸°ëŒ€ê°', 'ë‚œì²˜í•¨', 'ë‚ ì¹´ë¡œì›€', 'ëƒ‰ë‹´', 'ë„ˆê·¸ëŸ¬ì›€', 'ë†€ëŒ', 'ë‹¤ì •í•¨', 'ë‹µë‹µí•¨', 'ë™ì •(ìŠ¬í””)', 'ë‘ê·¼ê±°ë¦¼', 'ë§Œì¡±ê°', 'ë§¤ë ¥ì ', 'ë¬´ê¸°ë ¥', 'ë¯¸ì•ˆí•¨', 'ë°˜ê°€ì›€', 'ë°˜ê°', 'ë°œì—´', 'ë¶€ë„ëŸ¬ì›€', 'ë¶ˆë§Œ', 'ë¶ˆì‹ ê°', 'ë¶ˆì¾Œ', 'ë¶ˆí¸í•¨', 'ë¹„ìœ„ìƒí•¨', 'ì‚¬ë‚˜ì›€', 'ìˆ˜ì¹˜ì‹¬', 'ì‹œê¸°ì‹¬', 'ì‹ ë¢°ê°', 'ì‹ ëª…ë‚¨', 'ì‹¤ë§', 'ì‹«ì¦', 'ì‹¬ì‹¬í•¨', 'ì•„ì‰¬ì›€', 'ì•„í””', 'ì•ˆì •ê°', 'ì–µìš¸í•¨', 'ì™¸ë¡œì›€', 'ì™¸ë©´', 'ìš•ì‹¬', 'ì›ë§', 'ìœ„ì¶•ê°', 'ìë‘ìŠ¤ëŸ¬ì›€', 'ìì‹ ê°', 'ì ˆë§', 'ì£„ì±…ê°', 'ì¦ê±°ì›€', 'ì´ˆì¡°í•¨', 'ì¹˜ì‚¬í•¨', 'íƒ€ì˜¤ë¦„', 'í†µì¾Œí•¨', 'í¸ì•ˆí•¨', 'í—ˆë§', 'í˜¸ê°', 'í›„íšŒ']\n",
      "í•„í„°ë§ í›„ re_category1 ì¤‘ë¦½: 2ê°œ\n",
      "í•„í„°ë§ í›„ re_category2 ì¤‘ë¦½: 0ê°œ\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>generator_context</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>input_context</th>\n",
       "      <th>original_index</th>\n",
       "      <th>augmentation_index</th>\n",
       "      <th>re_category1</th>\n",
       "      <th>re_category2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ê°‘ìê¸° ë‚´ ì±…ìƒ ìœ„ì— ë†“ì¸ ë”°ëœ»í•œ ì†í¸ì§€ì— ë§ˆìŒì´ ë­‰í´í•´ì¡Œë‹¤.</td>\n",
       "      <td>ê¸°ì¨</td>\n",
       "      <td>ê°ë™</td>\n",
       "      <td>ì„¤íƒ• ìŠ¤í‹± ê»´ì¤€ê±° ì„¼ìŠ¤ ë°±ì  ë§Œì ì— ì²œì </td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ê¸°ì¨</td>\n",
       "      <td>ê°ë™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ë¹„ê°€ ì˜¤ëŠ”ë°ë„ ì¹œêµ¬ê°€ ë‚´ ì¢‹ì•„í•˜ëŠ” ì¹´í˜ê¹Œì§€ ìš°ì‚° ë“¤ê³  ë”°ë¼ì™€ì¤˜ì„œ ë§ˆìŒì´ ë”°ëœ»í•´ì¡Œì–´.</td>\n",
       "      <td>ê¸°ì¨</td>\n",
       "      <td>ê°ë™</td>\n",
       "      <td>ì•„ì“° ì‚°ì°¨ì´ ê¸°ë¶„ ì•ˆ ì¢‹ì€ ê±° ì•Œì•„ì±„ê³  ì‚°ì°¨ì´ê°€ ê°€ê³  ì‹¶ë‹¤ë˜ í† ë¼ì§‘ ë°ë ¤ì˜¨ ê±° ê°ë™</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ê¸°ì¨</td>\n",
       "      <td>ê°ë™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>í–‡ì‚´ ì•„ë˜ ë°˜ì§ì´ëŠ” ì•„ì´ì˜ ëˆˆë™ìê°€ ë§ˆì¹˜ ì‘ì€ ë³´ì„ì²˜ëŸ¼ ë¹›ë‚¬ë‹¤. ê·¸ ìˆœê°„, ì„¸ìƒ ëª¨...</td>\n",
       "      <td>ê¸°ì¨</td>\n",
       "      <td>ê°ë™</td>\n",
       "      <td>ì‹ ë°ë ë¼ ë“œë ˆìŠ¤ëŠ” ë‹¤ì‹œ ë´ë„ ë„ˆë¬´ ì•„ë¦„ë‹¤ì›Œ. ì‚¬ëŒì—ê²Œ ê¿ˆì˜ ë¬¼ê²°ì„ ì…íˆë‹¤ë‹ˆìš”.</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ê¸°ì¨</td>\n",
       "      <td>ê°ë™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ì´ë²ˆ ì „ì‹œíšŒ ì¤€ë¹„í•˜ë©´ì„œ ì² ì €í•˜ê²Œ ì„¸ë¶€ê¹Œì§€ ì±™ê²¨ì¤€ ë•ë¶„ì— ëª¨ë“  ê²Œ ì™„ë²½í•˜ê²Œ ë§ˆë¬´ë¦¬ë¼ì„œ...</td>\n",
       "      <td>ê¸°ì¨</td>\n",
       "      <td>ê°ë™</td>\n",
       "      <td>ì™€ ë¯¼í¬ì§„ ì”¨ ì• ë“¤ ìˆ™ì†Œ ìŠ¤íƒ€ì¼ë§ê¹Œì§€ ë§¡ê¸°ë©´ì„œ ì‹ ê²½ì¨ ì¤€ ê±° ì§„ì§œ ì¢€ ëŒ€ë‹¨í•˜ë„¤</td>\n",
       "      <td>107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ê¸°ì¨</td>\n",
       "      <td>ê°ë™</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ë¹„ ì˜¤ëŠ” ë‚  ë‚¯ì„  ì‚¬ëŒì´ ë‚´ê²Œ ë‹´ìš”ë¥¼ ê±´ë„¤ë©° ì¶”ìœ„ ê±±ì •í•´ ì¤¬ë‹¤. ë§ˆìŒì´ ë”°ëœ»í•´ì ¸ì„œ ...</td>\n",
       "      <td>ê¸°ì¨</td>\n",
       "      <td>ê°ë™</td>\n",
       "      <td>ê°œê°ë™ì¸ ê±° ìê¸°ê°€ ì“°ê³  ìˆë˜ ìš°ì‚° ë‚˜ ì£¼ê³ \\nìê¸°ê°€ ë¹„ ë§ì•„ê°€ë©´ì„œ ë’¤ì§‘ì–´ì¤€ ê±°ì•¼\\...</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ê¸°ì¨</td>\n",
       "      <td>ê°ë™</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  generator_context category1  \\\n",
       "0           0                 ê°‘ìê¸° ë‚´ ì±…ìƒ ìœ„ì— ë†“ì¸ ë”°ëœ»í•œ ì†í¸ì§€ì— ë§ˆìŒì´ ë­‰í´í•´ì¡Œë‹¤.        ê¸°ì¨   \n",
       "1           1     ë¹„ê°€ ì˜¤ëŠ”ë°ë„ ì¹œêµ¬ê°€ ë‚´ ì¢‹ì•„í•˜ëŠ” ì¹´í˜ê¹Œì§€ ìš°ì‚° ë“¤ê³  ë”°ë¼ì™€ì¤˜ì„œ ë§ˆìŒì´ ë”°ëœ»í•´ì¡Œì–´.        ê¸°ì¨   \n",
       "2           2  í–‡ì‚´ ì•„ë˜ ë°˜ì§ì´ëŠ” ì•„ì´ì˜ ëˆˆë™ìê°€ ë§ˆì¹˜ ì‘ì€ ë³´ì„ì²˜ëŸ¼ ë¹›ë‚¬ë‹¤. ê·¸ ìˆœê°„, ì„¸ìƒ ëª¨...        ê¸°ì¨   \n",
       "3           3  ì´ë²ˆ ì „ì‹œíšŒ ì¤€ë¹„í•˜ë©´ì„œ ì² ì €í•˜ê²Œ ì„¸ë¶€ê¹Œì§€ ì±™ê²¨ì¤€ ë•ë¶„ì— ëª¨ë“  ê²Œ ì™„ë²½í•˜ê²Œ ë§ˆë¬´ë¦¬ë¼ì„œ...        ê¸°ì¨   \n",
       "4           4  ë¹„ ì˜¤ëŠ” ë‚  ë‚¯ì„  ì‚¬ëŒì´ ë‚´ê²Œ ë‹´ìš”ë¥¼ ê±´ë„¤ë©° ì¶”ìœ„ ê±±ì •í•´ ì¤¬ë‹¤. ë§ˆìŒì´ ë”°ëœ»í•´ì ¸ì„œ ...        ê¸°ì¨   \n",
       "\n",
       "  category2                                      input_context  \\\n",
       "0        ê°ë™                             ì„¤íƒ• ìŠ¤í‹± ê»´ì¤€ê±° ì„¼ìŠ¤ ë°±ì  ë§Œì ì— ì²œì    \n",
       "1        ê°ë™     ì•„ì“° ì‚°ì°¨ì´ ê¸°ë¶„ ì•ˆ ì¢‹ì€ ê±° ì•Œì•„ì±„ê³  ì‚°ì°¨ì´ê°€ ê°€ê³  ì‹¶ë‹¤ë˜ í† ë¼ì§‘ ë°ë ¤ì˜¨ ê±° ê°ë™   \n",
       "2        ê°ë™        ì‹ ë°ë ë¼ ë“œë ˆìŠ¤ëŠ” ë‹¤ì‹œ ë´ë„ ë„ˆë¬´ ì•„ë¦„ë‹¤ì›Œ. ì‚¬ëŒì—ê²Œ ê¿ˆì˜ ë¬¼ê²°ì„ ì…íˆë‹¤ë‹ˆìš”.   \n",
       "3        ê°ë™        ì™€ ë¯¼í¬ì§„ ì”¨ ì• ë“¤ ìˆ™ì†Œ ìŠ¤íƒ€ì¼ë§ê¹Œì§€ ë§¡ê¸°ë©´ì„œ ì‹ ê²½ì¨ ì¤€ ê±° ì§„ì§œ ì¢€ ëŒ€ë‹¨í•˜ë„¤   \n",
       "4        ê°ë™  ê°œê°ë™ì¸ ê±° ìê¸°ê°€ ì“°ê³  ìˆë˜ ìš°ì‚° ë‚˜ ì£¼ê³ \\nìê¸°ê°€ ë¹„ ë§ì•„ê°€ë©´ì„œ ë’¤ì§‘ì–´ì¤€ ê±°ì•¼\\...   \n",
       "\n",
       "   original_index  augmentation_index re_category1 re_category2  \n",
       "0            20.0                 NaN           ê¸°ì¨           ê°ë™  \n",
       "1            79.0                 NaN           ê¸°ì¨           ê°ë™  \n",
       "2           104.0                 NaN           ê¸°ì¨           ê°ë™  \n",
       "3           107.0                 NaN           ê¸°ì¨           ê°ë™  \n",
       "4           137.0                 NaN           ê¸°ì¨           ê°ë™  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(r'C:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\data\\retest_augmentation.xlsx')\n",
    "\n",
    "# re_category2ì—ì„œë§Œ ì¤‘ë¦½ ë°ì´í„° ì œê±° (re_category1ì€ ì¤‘ë¦½ ìœ ì§€)\n",
    "print(f\"ë°ì´í„° í•„í„°ë§ ì „: {len(data)}ê°œ\")\n",
    "print(f\"re_category1ì—ì„œ ì¤‘ë¦½: {(data['re_category1'] == 'ì¤‘ë¦½').sum()}ê°œ\")\n",
    "print(f\"re_category2ì—ì„œ ì¤‘ë¦½: {(data['re_category2'] == 'ì¤‘ë¦½').sum()}ê°œ\")\n",
    "\n",
    "# re_category2ì—ì„œë§Œ ì¤‘ë¦½ ë°ì´í„° ì œê±° (Category2ì— ì¤‘ë¦½ì´ ì—†ìœ¼ë¯€ë¡œ ë¼ë²¨ ë¶ˆì¼ì¹˜ ë°©ì§€)\n",
    "original_count = len(data)\n",
    "data = data[data['re_category2'] != 'ì¤‘ë¦½'].copy()\n",
    "\n",
    "# ì¸ë±ìŠ¤ ì¬ì„¤ì •\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "print(f\"ë°ì´í„° í•„í„°ë§ í›„: {len(data)}ê°œ\")\n",
    "print(f\"ì œê±°ëœ ë°ì´í„°: {original_count - len(data)}ê°œ\")\n",
    "\n",
    "# í•„í„°ë§ëœ ë°ì´í„° í™•ì¸\n",
    "print(f\"ë‚¨ì€ re_category1 í´ë˜ìŠ¤ ({len(data['re_category1'].unique())}ê°œ): {sorted(data['re_category1'].unique())}\")\n",
    "print(f\"ë‚¨ì€ re_category2 í´ë˜ìŠ¤ ({len(data['re_category2'].unique())}ê°œ): {sorted(data['re_category2'].unique())}\")\n",
    "\n",
    "# ì¤‘ë¦½ í™•ì¸\n",
    "print(f\"í•„í„°ë§ í›„ re_category1 ì¤‘ë¦½: {(data['re_category1'] == 'ì¤‘ë¦½').sum()}ê°œ\")\n",
    "print(f\"í•„í„°ë§ í›„ re_category2 ì¤‘ë¦½: {(data['re_category2'] == 'ì¤‘ë¦½').sum()}ê°œ\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dbf27be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_model():\n",
    "  \"\"\"\n",
    "  ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”\n",
    "  \"\"\"\n",
    "  model = SentenceTransformer(\"dragonkue/snowflake-arctic-embed-l-v2.0-ko\") \n",
    "  vec_dim = len(model.encode(\"dummy_text\"))\n",
    "  print(f\"ëª¨ë¸ ì°¨ì›: {vec_dim}\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c873e343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ëª¨ë¸ ì°¨ì›: 1024\n"
     ]
    }
   ],
   "source": [
    "embeddings_model = embeddings_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4926f06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ê¸°ì¡´ ë³€ìˆ˜ë“¤ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3359 entries, 0 to 3358\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Unnamed: 0          3359 non-null   int64  \n",
      " 1   generator_context   3359 non-null   object \n",
      " 2   category1           3359 non-null   object \n",
      " 3   category2           3359 non-null   object \n",
      " 4   input_context       3359 non-null   object \n",
      " 5   original_index      664 non-null    float64\n",
      " 6   augmentation_index  2695 non-null   float64\n",
      " 7   re_category1        3359 non-null   object \n",
      " 8   re_category2        3359 non-null   object \n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 236.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# ê¸°ì¡´ ë³€ìˆ˜ ì´ˆê¸°í™” (ì¤‘ë¦½ ë°ì´í„° ì œê±°ë¡œ ì¸í•œ í¬ê¸° ë¶ˆì¼ì¹˜ ë°©ì§€)\n",
    "vars_to_reset = ['X', 'y', 'y_encoded', 'X_combined', 'y_cat2', 'y_cat2_encoded', 'le', 'le_cat2', 'cat1_encoder']\n",
    "for var_name in vars_to_reset:\n",
    "    if var_name in locals():\n",
    "        del locals()[var_name]\n",
    "        print(f\"ë³€ìˆ˜ {var_name} ì´ˆê¸°í™”ë¨\")\n",
    "\n",
    "print(\"âœ… ê¸°ì¡´ ë³€ìˆ˜ë“¤ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ë°ì´í„° ì •ë³´ í™•ì¸\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd04d86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ í•„í„°ë§ëœ ë°ì´í„°ë¡œ ë²¡í„° ìƒì„±...\n",
      "âœ… ë²¡í„° ìƒì„± ì™„ë£Œ: 3359ê°œ\n"
     ]
    }
   ],
   "source": [
    "# ì¤‘ë¦½ ë°ì´í„° ì œê±° í›„ ë²¡í„° ìƒì„±\n",
    "print(\"ğŸ“ í•„í„°ë§ëœ ë°ì´í„°ë¡œ ë²¡í„° ìƒì„±...\")\n",
    "data['vector'] = data['generator_context'].apply(lambda x: embeddings_model.encode(x).tolist())\n",
    "print(f\"âœ… ë²¡í„° ìƒì„± ì™„ë£Œ: {len(data)}ê°œ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3b7dde",
   "metadata": {},
   "source": [
    "### category1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c27bb42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ë°ì´í„° ìƒíƒœ í™•ì¸:\n",
      "í•„í„°ë§ëœ ë°ì´í„° ê°œìˆ˜: 3359\n",
      "ë²¡í„° íƒ€ì…: <class 'list'>\n",
      "ë²¡í„° ê¸¸ì´: 1024\n",
      "ë²¡í„°ê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì…ë‹ˆë‹¤. ì§ì ‘ ë³€í™˜í•©ë‹ˆë‹¤...\n",
      "X shape: (3359, 1024)\n",
      "y shape: (3359,)\n",
      "âœ… Xì™€ yì˜ í¬ê¸°ê°€ ì¼ì¹˜í•©ë‹ˆë‹¤!\n",
      "âœ… ì„±ê³µì ìœ¼ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
     ]
    }
   ],
   "source": [
    "# í•„í„°ë§ëœ ë°ì´í„°ë¡œ ë²¡í„°ì™€ ë¼ë²¨ ìƒì„±\n",
    "print(\"ë°ì´í„° ìƒíƒœ í™•ì¸:\")\n",
    "print(f\"í•„í„°ë§ëœ ë°ì´í„° ê°œìˆ˜: {len(data)}\")\n",
    "print(f\"ë²¡í„° íƒ€ì…: {type(data['vector'].iloc[0])}\")\n",
    "print(f\"ë²¡í„° ê¸¸ì´: {len(data['vector'].iloc[0])}\")\n",
    "\n",
    "# ë²¡í„°ê°€ ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ í˜•íƒœë¼ë©´ ì§ì ‘ numpy arrayë¡œ ë³€í™˜\n",
    "if isinstance(data['vector'].iloc[0], list):\n",
    "    print(\"ë²¡í„°ê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœì…ë‹ˆë‹¤. ì§ì ‘ ë³€í™˜í•©ë‹ˆë‹¤...\")\n",
    "    X = np.vstack(data['vector'].values)\n",
    "    y = data['re_category1'].values  # ë³€ê²½: category1 â†’ re_category1\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    \n",
    "    # í¬ê¸° ì¼ì¹˜ í™•ì¸\n",
    "    if X.shape[0] == y.shape[0]:\n",
    "        print(\"âœ… Xì™€ yì˜ í¬ê¸°ê°€ ì¼ì¹˜í•©ë‹ˆë‹¤!\")\n",
    "    else:\n",
    "        print(f\"âŒ í¬ê¸° ë¶ˆì¼ì¹˜: X {X.shape[0]} vs y {y.shape[0]}\")\n",
    "    \n",
    "    print(\"âœ… ì„±ê³µì ìœ¼ë¡œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"ë²¡í„° í˜•íƒœì— ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wqea3alqoni",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ì‹¤ì œ test_data ë¡œë“œ ë° í‰ê°€\n",
      "\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ë³¸ ì •ë³´:\n",
      "ë°ì´í„° í¬ê¸°: (664, 5)\n",
      "ì»¬ëŸ¼ë“¤: ['index', 'context', 'annotations_split', 'category1', 'category2']\n",
      "\n",
      "ë°ì´í„° ìƒ˜í”Œ:\n",
      "   index                                            context  \\\n",
      "0      0  ë³´ëŠ”ë™ì•ˆ ë„ˆë¬´ í–‰ë³µí–ˆê³  ì´ˆì½œë ›ì´ ë„ˆë¬´ ë¨¹ê³ ì‹¶ì—ˆê³  í‹°ëª¨ì‹œê°€ ì˜ìƒê²¼ê³  ìš¸ì–´!!í•˜ëŠ”ë¶€ë¶„ì´...   \n",
      "1      1  ì–´ë¦´ ë•Œ ê°€ ë³´ê³  ë¹•ìŠ¤ëŠ” ê±°ì˜ ì²˜ìŒì¸ë°(ê¸°ì–µì— ì—†ìŒ) ì§€ê¸ˆ ë”¸ê¸°ì¶•ì œ ê¸°ê°„ì´ë¼ ë§Œì¡±ìŠ¤...   \n",
      "2      2  ë¯¸ë¦¬ ê³„ì¢Œë¡œ í™˜ì „í•´ë‘” ëˆì„ í•´ì™¸ì—ì„œ í™˜ì „ìˆ˜ìˆ˜ë£Œ ì—†ì´ ì¸ì¶œ ê°€ëŠ¥í•œ íŠ¸ë ˆë¸”ë¡œê·¸ë¼ëŠ” ì¹´ë“œ...   \n",
      "3      3  ìš”ì¦˜ ë²ˆì•„ì›ƒë„ ìê¾¸ ì˜¬ë¼ì˜¤ê³  ë¬´ê¸°ë ¥í•´ì„œ ì¢…ê°•í•˜ê³  êµë¥˜í•˜ê¸°ë„ ë²„ê±°ìš´ ìƒíƒœê°€ ì™€ë¶€ë €ìœ¼ìš”ã… ã…     \n",
      "4      4  í¬ë¼ì„ì”¬ ì¥ë˜¥ë¯¼ì´ ë²”í–‰ ë„êµ¬ ì°¾ìœ¼ë ¤ê³  í™”ì¥ì‹¤ íƒ±í¬ ë’¤ì§€ëŠ”ë° ê±°ê¸°ì— ì§„ì§œ ë˜¥ ë„£ì–´ë†“ì€...   \n",
      "\n",
      "                                   annotations_split category1 category2  \n",
      "0  [['ê¸°ì¨', 'ë§Œì¡±ê°'], ['ê¸°ì¨', 'ë§Œì¡±ê°'], ['ê¸°ì¨', 'ê°ë™'], [...        ê¸°ì¨       ë§Œì¡±ê°  \n",
      "1  [['ê¸°ì¨', 'ë§Œì¡±ê°'], ['ê¸°ì¨', 'ë§Œì¡±ê°'], ['ê¸°ì¨', 'ë§Œì¡±ê°'], ...        ê¸°ì¨       ë§Œì¡±ê°  \n",
      "2  [['ê¸°ì¨', 'ë§Œì¡±ê°'], ['ê¸°ì¨', 'ë§Œì¡±ê°'], ['ê¸°ì¨', 'ë§Œì¡±ê°'], ...        ê¸°ì¨       ë§Œì¡±ê°  \n",
      "3  [['ìŠ¬í””', 'ë¬´ê¸°ë ¥'], ['ì‹«ì–´í•¨(ìƒíƒœ)', 'ë¬´ê¸°ë ¥'], ['ìŠ¬í””', 'ë¬´ê¸°...        ìŠ¬í””       ë¬´ê¸°ë ¥  \n",
      "4  [['ê¸°ì¨', 'ì¦ê±°ì›€'], ['ê¸°ì¨', 'í†µì¾Œí•¨'], ['ê¸°ì¨', 'í†µì¾Œí•¨'], ...        ê¸°ì¨       ì¦ê±°ì›€  \n",
      "\n",
      "test_data ì»¬ëŸ¼ í™•ì¸:\n",
      "- index: int64\n",
      "- context: object\n",
      "- annotations_split: object\n",
      "- category1: object\n",
      "- category2: object\n",
      "\n",
      "ì‹ë³„ëœ ì»¬ëŸ¼:\n",
      "í…ìŠ¤íŠ¸ ì»¬ëŸ¼: context\n",
      "Category1 ì»¬ëŸ¼: category1\n",
      "\n",
      "âœ… í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°œìˆ˜: 664\n",
      "Category1 í´ë˜ìŠ¤ë“¤: ['ê¸°ì¨' 'ìŠ¬í””' 'ì‹«ì–´í•¨(ìƒíƒœ)' 'ë¯¸ì›€(ìƒëŒ€ë°©)' 'ë‘ë ¤ì›€' 'ìˆ˜ì¹˜ì‹¬' 'ìš•ë§' 'ë¶„ë…¸' 'ì‚¬ë‘' 'ì¤‘ë¦½']\n"
     ]
    }
   ],
   "source": [
    "# 9. ì‹¤ì œ test_dataë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\n",
    "\n",
    "print(\"ğŸ“ ì‹¤ì œ test_data ë¡œë“œ ë° í‰ê°€\\n\")\n",
    "\n",
    "# test_data ë¡œë“œ\n",
    "test_data = pd.read_excel(r'C:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\data\\ì¦ê°•í• ë°ì´í„°33.xlsx')\n",
    "print(\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ë³¸ ì •ë³´:\")\n",
    "print(f\"ë°ì´í„° í¬ê¸°: {test_data.shape}\")\n",
    "print(f\"ì»¬ëŸ¼ë“¤: {list(test_data.columns)}\")\n",
    "print(\"\\në°ì´í„° ìƒ˜í”Œ:\")\n",
    "print(test_data.head())\n",
    "\n",
    "# test_dataì—ì„œ í…ìŠ¤íŠ¸ì™€ category1 ì»¬ëŸ¼ í™•ì¸\n",
    "print(f\"\\ntest_data ì»¬ëŸ¼ í™•ì¸:\")\n",
    "for col in test_data.columns:\n",
    "    print(f\"- {col}: {test_data[col].dtype}\")\n",
    "\n",
    "# í…ìŠ¤íŠ¸ ì»¬ëŸ¼ê³¼ category1 ì»¬ëŸ¼ ì‹ë³„ (ì»¬ëŸ¼ëª…ì— ë”°ë¼ ì¡°ì • í•„ìš”)\n",
    "text_column = None\n",
    "category1_column = None\n",
    "\n",
    "# ê°€ëŠ¥í•œ í…ìŠ¤íŠ¸ ì»¬ëŸ¼ëª…ë“¤\n",
    "possible_text_columns = ['context', 'text', 'content', 'sentence', 'ë‚´ìš©', 'ë¬¸ì¥']\n",
    "for col in test_data.columns:\n",
    "    if any(keyword in col.lower() for keyword in possible_text_columns):\n",
    "        text_column = col\n",
    "        break\n",
    "\n",
    "# ê°€ëŠ¥í•œ category1 ì»¬ëŸ¼ëª…ë“¤\n",
    "possible_cat1_columns = ['category1', 'cat1', 'label', 'ê°ì •', 'ì¹´í…Œê³ ë¦¬1']\n",
    "for col in test_data.columns:\n",
    "    if any(keyword in col.lower() for keyword in possible_cat1_columns):\n",
    "        category1_column = col\n",
    "        break\n",
    "\n",
    "print(f\"\\nì‹ë³„ëœ ì»¬ëŸ¼:\")\n",
    "print(f\"í…ìŠ¤íŠ¸ ì»¬ëŸ¼: {text_column}\")\n",
    "print(f\"Category1 ì»¬ëŸ¼: {category1_column}\")\n",
    "\n",
    "if text_column and category1_column:\n",
    "    print(f\"\\nâœ… í•„ìš”í•œ ì»¬ëŸ¼ë“¤ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤!\")\n",
    "    print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ê°œìˆ˜: {len(test_data)}\")\n",
    "    print(f\"Category1 í´ë˜ìŠ¤ë“¤: {test_data[category1_column].unique()}\")\n",
    "else:\n",
    "    print(f\"\\nâŒ í•„ìš”í•œ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ë™ìœ¼ë¡œ ì§€ì •í•´ì£¼ì„¸ìš”.\")\n",
    "    print(\"ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ë“¤:\")\n",
    "    for i, col in enumerate(test_data.columns):\n",
    "        print(f\"{i}: {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fed4954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ Category1 ëª¨ë¸ì˜ test_data ì„±ëŠ¥ í‰ê°€\n",
      "\n",
      "y_encoded ë³€ìˆ˜ë¥¼ ì¬ì •ì˜í•©ë‹ˆë‹¤...\n",
      "y_encoded shape: (3359,)\n",
      "ğŸ“ test_data í…ìŠ¤íŠ¸ ì„ë² ë”© ì¤‘...\n",
      "âœ… ì„ë² ë”© ì™„ë£Œ: (664, 1024)\n",
      "ì‹¤ì œ ë¼ë²¨: 664\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤‘ë¦½ ê°œìˆ˜: 5ê°œ\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„° category1 í´ë˜ìŠ¤ (10ê°œ): ['ê¸°ì¨', 'ë‘ë ¤ì›€', 'ë¯¸ì›€(ìƒëŒ€ë°©)', 'ë¶„ë…¸', 'ì‚¬ë‘', 'ìˆ˜ì¹˜ì‹¬', 'ìŠ¬í””', 'ì‹«ì–´í•¨(ìƒíƒœ)', 'ìš•ë§', 'ì¤‘ë¦½']\n",
      "\n",
      "ğŸ”„ ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ...\n",
      "âœ… ìµœì¢… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n",
      "\n",
      "ğŸ¯ test_data ì˜ˆì¸¡ ìˆ˜í–‰...\n",
      "\n",
      "ğŸ“‹ í´ë˜ìŠ¤ ì •ë³´:\n",
      "í•™ìŠµ í´ë˜ìŠ¤ ìˆ˜: 10\n",
      "í•™ìŠµ í´ë˜ìŠ¤: ['ê¸°ì¨', 'ë‘ë ¤ì›€', 'ë¯¸ì›€(ìƒëŒ€ë°©)', 'ë¶„ë…¸', 'ì‚¬ë‘', 'ìˆ˜ì¹˜ì‹¬', 'ìŠ¬í””', 'ì‹«ì–´í•¨(ìƒíƒœ)', 'ìš•ë§', 'ì¤‘ë¦½']\n",
      "í…ŒìŠ¤íŠ¸ ì‹¤ì œ í´ë˜ìŠ¤ ìˆ˜: 10\n",
      "í…ŒìŠ¤íŠ¸ ì‹¤ì œ í´ë˜ìŠ¤: ['ê¸°ì¨', 'ë‘ë ¤ì›€', 'ë¯¸ì›€(ìƒëŒ€ë°©)', 'ë¶„ë…¸', 'ì‚¬ë‘', 'ìˆ˜ì¹˜ì‹¬', 'ìŠ¬í””', 'ì‹«ì–´í•¨(ìƒíƒœ)', 'ìš•ë§', 'ì¤‘ë¦½']\n",
      "ê³µí†µ í´ë˜ìŠ¤ ìˆ˜: 10\n",
      "âœ… í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ Category1 í´ë˜ìŠ¤ê°€ ì™„ë²½íˆ ì¼ì¹˜í•©ë‹ˆë‹¤!\n",
      "\n",
      "ğŸ“Š Classification Report:\n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ê¸°ì¨       0.65      0.78      0.71       188\n",
      "         ë‘ë ¤ì›€       0.92      0.15      0.26        72\n",
      "     ë¯¸ì›€(ìƒëŒ€ë°©)       0.37      0.70      0.48        43\n",
      "          ë¶„ë…¸       0.25      0.33      0.29        36\n",
      "          ì‚¬ë‘       0.43      0.06      0.11        47\n",
      "         ìˆ˜ì¹˜ì‹¬       0.33      0.08      0.13        25\n",
      "          ìŠ¬í””       0.52      0.65      0.58       117\n",
      "     ì‹«ì–´í•¨(ìƒíƒœ)       0.26      0.10      0.15        49\n",
      "          ìš•ë§       0.33      0.48      0.39        82\n",
      "          ì¤‘ë¦½       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.49       664\n",
      "   macro avg       0.41      0.33      0.31       664\n",
      "weighted avg       0.51      0.49      0.45       664\n",
      "\n",
      "\n",
      "ğŸ¯ ì „ì²´ ì •í™•ë„: 0.4880 (48.80%)\n",
      "í‰ê°€ ë°ì´í„°: 664ê°œ ëª¨ë‘ í‰ê°€\n",
      "\n",
      "ğŸ” ì˜ˆì¸¡ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):\n",
      "------------------------------------------------------------------------------------------\n",
      " 1. âœ… ì‹¤ì œ: ê¸°ì¨           ì˜ˆì¸¡: ê¸°ì¨          \n",
      "    í…ìŠ¤íŠ¸: ë³´ëŠ”ë™ì•ˆ ë„ˆë¬´ í–‰ë³µí–ˆê³  ì´ˆì½œë ›ì´ ë„ˆë¬´ ë¨¹ê³ ì‹¶ì—ˆê³  í‹°ëª¨ì‹œê°€ ì˜ìƒê²¼ê³  ìš¸ì–´!!í•˜ëŠ”ë¶€ë¶„ì´ ìˆì–´ì„œ ìš¸ì—ˆë‹¤ë„¤ìš”\n",
      "\n",
      " 2. âœ… ì‹¤ì œ: ê¸°ì¨           ì˜ˆì¸¡: ê¸°ì¨          \n",
      "    í…ìŠ¤íŠ¸: ì–´ë¦´ ë•Œ ê°€ ë³´ê³  ë¹•ìŠ¤ëŠ” ê±°ì˜ ì²˜ìŒì¸ë°(ê¸°ì–µì— ì—†ìŒ) ì§€ê¸ˆ ë”¸ê¸°ì¶•ì œ ê¸°ê°„ì´ë¼ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì‹ì‚¬ í•˜ê³  ì˜´\n",
      "\n",
      " 3. âœ… ì‹¤ì œ: ê¸°ì¨           ì˜ˆì¸¡: ê¸°ì¨          \n",
      "    í…ìŠ¤íŠ¸: ë¯¸ë¦¬ ê³„ì¢Œë¡œ í™˜ì „í•´ë‘” ëˆì„ í•´ì™¸ì—ì„œ í™˜ì „ìˆ˜ìˆ˜ë£Œ ì—†ì´ ì¸ì¶œ ê°€ëŠ¥í•œ íŠ¸ë ˆë¸”ë¡œê·¸ë¼ëŠ” ì¹´ë“œì¸ë°, ì„ íƒí•  ìˆ˜ ìˆëŠ” ë””...\n",
      "\n",
      " 4. âŒ ì‹¤ì œ: ìŠ¬í””           ì˜ˆì¸¡: ì‹«ì–´í•¨(ìƒíƒœ)     \n",
      "    í…ìŠ¤íŠ¸: ìš”ì¦˜ ë²ˆì•„ì›ƒë„ ìê¾¸ ì˜¬ë¼ì˜¤ê³  ë¬´ê¸°ë ¥í•´ì„œ ì¢…ê°•í•˜ê³  êµë¥˜í•˜ê¸°ë„ ë²„ê±°ìš´ ìƒíƒœê°€ ì™€ë¶€ë €ìœ¼ìš”ã… ã…  \n",
      "\n",
      " 5. âŒ ì‹¤ì œ: ê¸°ì¨           ì˜ˆì¸¡: ë¯¸ì›€(ìƒëŒ€ë°©)     \n",
      "    í…ìŠ¤íŠ¸: í¬ë¼ì„ì”¬ ì¥ë˜¥ë¯¼ì´ ë²”í–‰ ë„êµ¬ ì°¾ìœ¼ë ¤ê³  í™”ì¥ì‹¤ íƒ±í¬ ë’¤ì§€ëŠ”ë° ê±°ê¸°ì— ì§„ì§œ ë˜¥ ë„£ì–´ë†“ì€ ê±° ì§„ì§œ ì›ƒê²¨ ë’¤ì§€ê² ìŒã…‹...\n",
      "\n",
      " 6. âŒ ì‹¤ì œ: ì‹«ì–´í•¨(ìƒíƒœ)      ì˜ˆì¸¡: ìŠ¬í””          \n",
      "    í…ìŠ¤íŠ¸: ê°€ìŠ´ì´ ë‹µë‹µí•´ì§ ì§„ì§œ ê°œë‹µë‹µí•´ì§\n",
      "ìš°ë¦¬ì§„ì§œíˆ¬í‘œì˜í•˜ì\n",
      "\n",
      " 7. âŒ ì‹¤ì œ: ê¸°ì¨           ì˜ˆì¸¡: ìš•ë§          \n",
      "    í…ìŠ¤íŠ¸: ì§€ê·¸ì¬ê·¸ë‘ ì—ì´ë¸”ë¦¬ë‘ í• ì¸ ëŒ€ê²°í•˜ë‚˜\n",
      "ì•„ íë­‡í•´\n",
      "ê³„ì†ë˜ê¸¸...\n",
      "ì˜ì›íˆ....\n",
      "\n",
      " 8. âŒ ì‹¤ì œ: ê¸°ì¨           ì˜ˆì¸¡: ìš•ë§          \n",
      "    í…ìŠ¤íŠ¸: ì²¨ìœ¼ë¡œ ìˆ˜ì œ ì´ˆì½œë¦¿ ë§Œë“¬\n",
      "ì´ˆì½œë¦¿ì„ 5ì‹œê°„ì´ë‚˜ ë§Œë“œëŠ” ì‚¬ëŒì´ ìˆë‹¤??? ê·¸ê²Œ ë°”ë¡œ ë‚˜\n",
      "\n",
      " 9. âŒ ì‹¤ì œ: ìŠ¬í””           ì˜ˆì¸¡: ê¸°ì¨          \n",
      "    í…ìŠ¤íŠ¸: ë‹¨í†¡ë°©ì— ê³µì§€ë“¤ ìŠ¬ìŠ¬ ì˜¬ë¼ì˜¤ëŠ”ê±° ë³´ë‹ˆê¹Œ ê³§ ê°œê°•ì´ë¼ëŠ”ê²Œ ì‹¤ê°ë‚˜ì„œ ê°‘ìê¸° ì¬ê¸°í•˜ê³ ì‹¶ê³  ì¸ìƒì´ ë‹¤ ëë‚œê±°ì²˜ëŸ¼ ì•”...\n",
      "\n",
      "10. âœ… ì‹¤ì œ: ê¸°ì¨           ì˜ˆì¸¡: ê¸°ì¨          \n",
      "    í…ìŠ¤íŠ¸: ì¥í¥ì‹  ê³µì†í•œ ì†ê°€ë½ì§ˆ ê°œì›ƒê²¨ìš”\n",
      "ì• ë“œë¦½ ë¯¸ì¹œê²ƒ ê°™ìŒ\n",
      "\n",
      "\n",
      "ğŸ“ˆ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ìš”ì•½:\n",
      "------------------------------------------------------------\n",
      "í´ë˜ìŠ¤             ì „ì²´       ì •ë‹µ       ì •í™•ë„       \n",
      "--------------------------------------------------\n",
      "ê¸°ì¨              188      146      0.7766\n",
      "ë‘ë ¤ì›€             72       11       0.1528\n",
      "ë¯¸ì›€(ìƒëŒ€ë°©)         43       30       0.6977\n",
      "ë¶„ë…¸              36       12       0.3333\n",
      "ì‚¬ë‘              47       3        0.0638\n",
      "ìˆ˜ì¹˜ì‹¬             25       2        0.0800\n",
      "ìŠ¬í””              117      76       0.6496\n",
      "ì‹«ì–´í•¨(ìƒíƒœ)         49       5        0.1020\n",
      "ìš•ë§              82       39       0.4756\n",
      "ì¤‘ë¦½              5        0        0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# K-Foldë¡œ í‰ê°€í•œ Category1 ëª¨ë¸ë¡œ test_data ì˜ˆì¸¡ ë° classification_report\n",
    "\n",
    "print(\"ğŸ¯ Category1 ëª¨ë¸ì˜ test_data ì„±ëŠ¥ í‰ê°€\\n\")\n",
    "\n",
    "# 1. í•™ìŠµ ë°ì´í„° X, y ë³€ìˆ˜ ì •ì˜ (í•„ìš”ì‹œ)\n",
    "if 'X' not in locals():\n",
    "    print(\"X ë³€ìˆ˜ë¥¼ ì¬ì •ì˜í•©ë‹ˆë‹¤...\")\n",
    "    X = np.vstack(data['vector'].values)\n",
    "    y = data['re_category1'].values  # ë³€ê²½: category1 â†’ re_category1 (ì¤‘ë¦½ í¬í•¨)\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    print(f\"í›ˆë ¨ ë°ì´í„° re_category1 í´ë˜ìŠ¤ ({len(np.unique(y))}ê°œ): {sorted(np.unique(y))}\")\n",
    "\n",
    "# 2. y_encoded ì •ì˜ (í•„ìš”ì‹œ)\n",
    "if 'y_encoded' not in locals():\n",
    "    print(\"y_encoded ë³€ìˆ˜ë¥¼ ì¬ì •ì˜í•©ë‹ˆë‹¤...\")\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    print(f\"y_encoded shape: {y_encoded.shape}\")\n",
    "\n",
    "# 3. test_dataì˜ í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜\n",
    "print(\"ğŸ“ test_data í…ìŠ¤íŠ¸ ì„ë² ë”© ì¤‘...\")\n",
    "test_texts = test_data['context'].fillna('').astype(str).tolist()\n",
    "test_vectors = []\n",
    "\n",
    "for text in test_texts:\n",
    "    vector = embeddings_model.encode(text)\n",
    "    test_vectors.append(vector)\n",
    "\n",
    "test_X = np.vstack(test_vectors)\n",
    "test_y_actual = test_data['category1'].values\n",
    "\n",
    "print(f\"âœ… ì„ë² ë”© ì™„ë£Œ: {test_X.shape}\")\n",
    "print(f\"ì‹¤ì œ ë¼ë²¨: {len(test_y_actual)}\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì¤‘ë¦½ í™•ì¸\n",
    "test_neutral_count = (test_y_actual == 'ì¤‘ë¦½').sum()\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤‘ë¦½ ê°œìˆ˜: {test_neutral_count}ê°œ\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° category1 í´ë˜ìŠ¤ ({len(np.unique(test_y_actual))}ê°œ): {sorted(np.unique(test_y_actual))}\")\n",
    "\n",
    "# 4. ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ\n",
    "print(\"\\nğŸ”„ ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ...\")\n",
    "final_cat1_model = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ ëª¨ë¸ í•™ìŠµ\n",
    "final_cat1_model.fit(X, y_encoded)\n",
    "print(\"âœ… ìµœì¢… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "\n",
    "# 5. test_dataë¡œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "print(\"\\nğŸ¯ test_data ì˜ˆì¸¡ ìˆ˜í–‰...\")\n",
    "test_y_pred_encoded = final_cat1_model.predict(test_X)\n",
    "test_y_pred = le.inverse_transform(test_y_pred_encoded)\n",
    "\n",
    "# 6. í•™ìŠµ í´ë˜ìŠ¤ì™€ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ ë¹„êµ\n",
    "train_classes = set(le.classes_)\n",
    "test_actual_classes = set(test_y_actual)\n",
    "test_pred_classes = set(test_y_pred)\n",
    "\n",
    "print(f\"\\nğŸ“‹ í´ë˜ìŠ¤ ì •ë³´:\")\n",
    "print(f\"í•™ìŠµ í´ë˜ìŠ¤ ìˆ˜: {len(train_classes)}\")\n",
    "print(f\"í•™ìŠµ í´ë˜ìŠ¤: {sorted(train_classes)}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ì‹¤ì œ í´ë˜ìŠ¤ ìˆ˜: {len(test_actual_classes)}\")  \n",
    "print(f\"í…ŒìŠ¤íŠ¸ ì‹¤ì œ í´ë˜ìŠ¤: {sorted(test_actual_classes)}\")\n",
    "\n",
    "# í•™ìŠµì— ì—†ëŠ” í´ë˜ìŠ¤ í™•ì¸\n",
    "unseen_classes = test_actual_classes - train_classes\n",
    "if unseen_classes:\n",
    "    print(f\"âš ï¸ í•™ìŠµì— ì—†ë˜ í´ë˜ìŠ¤ë“¤: {unseen_classes}\")\n",
    "    \n",
    "common_classes = train_classes & test_actual_classes\n",
    "print(f\"ê³µí†µ í´ë˜ìŠ¤ ìˆ˜: {len(common_classes)}\")\n",
    "\n",
    "# í´ë˜ìŠ¤ ë§¤ì¹˜ í™•ì¸\n",
    "if len(train_classes) == len(test_actual_classes) == len(common_classes):\n",
    "    print(\"âœ… í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ Category1 í´ë˜ìŠ¤ê°€ ì™„ë²½íˆ ì¼ì¹˜í•©ë‹ˆë‹¤!\")\n",
    "    perfect_match = True\n",
    "else:\n",
    "    print(\"âŒ í´ë˜ìŠ¤ ë¶ˆì¼ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤.\")\n",
    "    perfect_match = False\n",
    "\n",
    "# 7. classification_report ìƒì„±\n",
    "print(f\"\\nğŸ“Š Classification Report:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if perfect_match:\n",
    "    # ëª¨ë“  í´ë˜ìŠ¤ê°€ ê³µí†µì¸ ê²½ìš° - ì „ì²´ í‰ê°€ ê°€ëŠ¥\n",
    "    test_y_actual_encoded = le.transform(test_y_actual)\n",
    "    report = classification_report(\n",
    "        test_y_actual_encoded, \n",
    "        test_y_pred_encoded, \n",
    "        target_names=le.classes_\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    # ì „ì²´ ì •í™•ë„\n",
    "    accuracy = (test_y_pred == test_y_actual).mean()\n",
    "    print(f\"\\nğŸ¯ ì „ì²´ ì •í™•ë„: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"í‰ê°€ ë°ì´í„°: {len(test_y_actual)}ê°œ ëª¨ë‘ í‰ê°€\")\n",
    "    \n",
    "else:\n",
    "    # ê³µí†µ í´ë˜ìŠ¤ë§Œ í•„í„°ë§í•´ì„œ í‰ê°€\n",
    "    mask = np.array([actual in common_classes for actual in test_y_actual])\n",
    "    filtered_actual = test_y_actual[mask]\n",
    "    filtered_pred = test_y_pred[mask]\n",
    "    \n",
    "    print(f\"ê³µí†µ í´ë˜ìŠ¤ í‰ê°€: {len(filtered_actual)}/{len(test_y_actual)}ê°œ\")\n",
    "    \n",
    "    filtered_actual_encoded = le.transform(filtered_actual)\n",
    "    filtered_pred_encoded = le.transform(filtered_pred)\n",
    "    \n",
    "    # ê³µí†µ í´ë˜ìŠ¤ì— ëŒ€í•œ ë¼ë²¨ê³¼ ì¸ë±ìŠ¤ ë§¤í•‘\n",
    "    common_class_labels = [cls for cls in le.classes_ if cls in common_classes]\n",
    "    common_class_indices = [le.transform([cls])[0] for cls in common_class_labels]\n",
    "    \n",
    "    report = classification_report(\n",
    "        filtered_actual_encoded,\n",
    "        filtered_pred_encoded,\n",
    "        target_names=common_class_labels,\n",
    "        labels=common_class_indices\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    # í•„í„°ë§ëœ ë°ì´í„°ì˜ ì •í™•ë„\n",
    "    accuracy = (filtered_pred == filtered_actual).mean()\n",
    "    print(f\"\\nğŸ¯ ì •í™•ë„ (ê³µí†µ í´ë˜ìŠ¤ë§Œ): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"í‰ê°€ ë°ì´í„°: {len(filtered_actual)}/{len(test_y_actual)}ê°œ\")\n",
    "\n",
    "# 8. ì˜ˆì¸¡ ìƒ˜í”Œ ì¶œë ¥\n",
    "print(f\"\\nğŸ” ì˜ˆì¸¡ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for i in range(min(10, len(test_texts))):\n",
    "    text = test_texts[i][:60] + \"...\" if len(test_texts[i]) > 60 else test_texts[i]\n",
    "    actual = test_y_actual[i]\n",
    "    predicted = test_y_pred[i]\n",
    "    status = \"âœ…\" if actual == predicted else \"âŒ\"\n",
    "    \n",
    "    print(f\"{i+1:2d}. {status} ì‹¤ì œ: {actual:<12} ì˜ˆì¸¡: {predicted:<12}\")\n",
    "    print(f\"    í…ìŠ¤íŠ¸: {text}\")\n",
    "    print()\n",
    "\n",
    "# 9. í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ìš”ì•½\n",
    "print(f\"\\nğŸ“ˆ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ìš”ì•½:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "from collections import defaultdict\n",
    "class_stats = defaultdict(lambda: {'total': 0, 'correct': 0})\n",
    "\n",
    "for actual, pred in zip(test_y_actual, test_y_pred):\n",
    "    if actual in common_classes:  # ê³µí†µ í´ë˜ìŠ¤ë§Œ ê³„ì‚°\n",
    "        class_stats[actual]['total'] += 1\n",
    "        if actual == pred:\n",
    "            class_stats[actual]['correct'] += 1\n",
    "\n",
    "print(f\"{'í´ë˜ìŠ¤':<15} {'ì „ì²´':<8} {'ì •ë‹µ':<8} {'ì •í™•ë„':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for class_name, stats in sorted(class_stats.items()):\n",
    "    if stats['total'] > 0:\n",
    "        class_accuracy = stats['correct'] / stats['total']\n",
    "        print(f\"{class_name:<15} {stats['total']:<8} {stats['correct']:<8} {class_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53gspj90vxl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ğŸ¯ Category2 ëª¨ë¸ì˜ test_data ì„±ëŠ¥ í‰ê°€\n",
      "================================================================================\n",
      "Category2 í•™ìŠµìš© ë³€ìˆ˜ë“¤ì„ ì¬ì •ì˜í•©ë‹ˆë‹¤...\n",
      "ğŸ“Š Category2 ë°ì´í„° í™•ì¸:\n",
      "  - ì „ì²´ Category2 ë°ì´í„°: 3359ê°œ\n",
      "  - ê³ ìœ  Category2 í´ë˜ìŠ¤: 64ê°œ\n",
      "  - Category2 í´ë˜ìŠ¤ ëª©ë¡: ['ê°ˆë“±', 'ê°ë™', 'ê±±ì •', 'ê²½ë©¸', 'ê³ ë§ˆì›€', 'ê³ í†µ', 'ê³µê°', 'ê³µí¬', 'ê¶ê¸ˆí•¨', 'ê·€ì¤‘í•¨', 'ê·¸ë¦¬ì›€', 'ê¸°ëŒ€ê°', 'ë‚œì²˜í•¨', 'ë‚ ì¹´ë¡œì›€', 'ëƒ‰ë‹´', 'ë„ˆê·¸ëŸ¬ì›€', 'ë†€ëŒ', 'ë‹¤ì •í•¨', 'ë‹µë‹µí•¨', 'ë™ì •(ìŠ¬í””)', 'ë‘ê·¼ê±°ë¦¼', 'ë§Œì¡±ê°', 'ë§¤ë ¥ì ', 'ë¬´ê¸°ë ¥', 'ë¯¸ì•ˆí•¨', 'ë°˜ê°€ì›€', 'ë°˜ê°', 'ë°œì—´', 'ë¶€ë„ëŸ¬ì›€', 'ë¶ˆë§Œ', 'ë¶ˆì‹ ê°', 'ë¶ˆì¾Œ', 'ë¶ˆí¸í•¨', 'ë¹„ìœ„ìƒí•¨', 'ì‚¬ë‚˜ì›€', 'ìˆ˜ì¹˜ì‹¬', 'ì‹œê¸°ì‹¬', 'ì‹ ë¢°ê°', 'ì‹ ëª…ë‚¨', 'ì‹¤ë§', 'ì‹«ì¦', 'ì‹¬ì‹¬í•¨', 'ì•„ì‰¬ì›€', 'ì•„í””', 'ì•ˆì •ê°', 'ì–µìš¸í•¨', 'ì™¸ë¡œì›€', 'ì™¸ë©´', 'ìš•ì‹¬', 'ì›ë§', 'ìœ„ì¶•ê°', 'ìë‘ìŠ¤ëŸ¬ì›€', 'ìì‹ ê°', 'ì ˆë§', 'ì£„ì±…ê°', 'ì¦ê±°ì›€', 'ì´ˆì¡°í•¨', 'ì¹˜ì‚¬í•¨', 'íƒ€ì˜¤ë¦„', 'í†µì¾Œí•¨', 'í¸ì•ˆí•¨', 'í—ˆë§', 'í˜¸ê°', 'í›„íšŒ']\n",
      "âœ… Category2ì—ì„œ ì¤‘ë¦½ì´ ì„±ê³µì ìœ¼ë¡œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
      "  - ì¸ì½”ë”©ëœ Category2 í´ë˜ìŠ¤: 64ê°œ\n",
      "X shape: (3359, 1024)\n",
      "y shape: (3359,)\n",
      "y_cat1_onehot shape: (3359, 10)\n",
      "X_combined shape: (3359, 1034)\n",
      "y_cat2 shape: (3359,)\n",
      "y_cat2_encoded shape: (3359,)\n",
      "\n",
      "ğŸ“ Category2 ì˜ˆì¸¡ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„...\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„°:\n",
      "- Category1 ì‹¤ì œê°’: 664ê°œ\n",
      "- Category2 ì‹¤ì œê°’: 664ê°œ\n",
      "- í…ŒìŠ¤íŠ¸ Category2 í´ë˜ìŠ¤: 64ê°œ\n",
      "- í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤‘ë¦½: Category1=5ê°œ, Category2=0ê°œ\n",
      "\n",
      "ğŸ”§ Category1 ì˜ˆì¸¡ê°’ìœ¼ë¡œ Category2 ì˜ˆì¸¡ìš© íŠ¹ì„± ìƒì„±...\n",
      "test_X shape: (664, 1024)\n",
      "test_cat1_onehot shape: (664, 10)\n",
      "âœ… ê²°í•©ëœ íŠ¹ì„±: (664, 1034)\n",
      "\n",
      "ğŸ”„ ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ Category2 ìµœì¢… ëª¨ë¸ í•™ìŠµ...\n",
      "í•™ìŠµ ë°ì´í„° í™•ì¸: X_combined (3359, 1034), y_cat2_encoded (3359,)\n",
      "âœ… Category2 ìµœì¢… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\n",
      "\n",
      "ğŸ¯ test_data Category2 ì˜ˆì¸¡ ìˆ˜í–‰...\n",
      "\n",
      "ğŸ“‹ Category2 í´ë˜ìŠ¤ ì •ë³´:\n",
      "í•™ìŠµ í´ë˜ìŠ¤ ìˆ˜: 64\n",
      "í…ŒìŠ¤íŠ¸ ì‹¤ì œ í´ë˜ìŠ¤ ìˆ˜: 64\n",
      "ê³µí†µ í´ë˜ìŠ¤ ìˆ˜: 64\n",
      "âœ… í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ Category2 í´ë˜ìŠ¤ê°€ ì™„ë²½íˆ ì¼ì¹˜í•©ë‹ˆë‹¤!\n",
      "\n",
      "ğŸ“Š Category2 Classification Report:\n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          ê°ˆë“±       0.00      0.00      0.00         1\n",
      "          ê°ë™       0.29      0.40      0.34        30\n",
      "          ê±±ì •       0.43      0.13      0.20        23\n",
      "          ê²½ë©¸       0.20      0.44      0.27        18\n",
      "         ê³ ë§ˆì›€       0.46      0.63      0.53        19\n",
      "          ê³ í†µ       0.00      0.00      0.00         9\n",
      "          ê³µê°       0.00      0.00      0.00         7\n",
      "          ê³µí¬       0.00      0.00      0.00        17\n",
      "         ê¶ê¸ˆí•¨       0.12      0.56      0.20         9\n",
      "         ê·€ì¤‘í•¨       0.00      0.00      0.00         5\n",
      "         ê·¸ë¦¬ì›€       0.50      0.09      0.15        11\n",
      "         ê¸°ëŒ€ê°       0.50      0.39      0.44        18\n",
      "         ë‚œì²˜í•¨       0.25      0.07      0.11        14\n",
      "        ë‚ ì¹´ë¡œì›€       0.00      0.00      0.00         3\n",
      "          ëƒ‰ë‹´       0.00      0.00      0.00         3\n",
      "        ë„ˆê·¸ëŸ¬ì›€       0.00      0.00      0.00         1\n",
      "          ë†€ëŒ       0.33      0.19      0.24        31\n",
      "         ë‹¤ì •í•¨       0.00      0.00      0.00         9\n",
      "         ë‹µë‹µí•¨       0.22      0.11      0.15        18\n",
      "      ë™ì •(ìŠ¬í””)       0.57      0.48      0.52        27\n",
      "        ë‘ê·¼ê±°ë¦¼       0.00      0.00      0.00         2\n",
      "         ë§Œì¡±ê°       0.35      0.35      0.35        49\n",
      "         ë§¤ë ¥ì        1.00      0.08      0.14        13\n",
      "         ë¬´ê¸°ë ¥       0.25      0.36      0.29        14\n",
      "         ë¯¸ì•ˆí•¨       1.00      0.29      0.44         7\n",
      "         ë°˜ê°€ì›€       0.20      0.06      0.10        16\n",
      "          ë°˜ê°       0.20      0.20      0.20         5\n",
      "          ë°œì—´       0.00      0.00      0.00         3\n",
      "        ë¶€ë„ëŸ¬ì›€       0.00      0.00      0.00        16\n",
      "          ë¶ˆë§Œ       0.20      0.12      0.15         8\n",
      "         ë¶ˆì‹ ê°       0.20      0.12      0.15         8\n",
      "          ë¶ˆì¾Œ       0.11      0.15      0.13        20\n",
      "         ë¶ˆí¸í•¨       0.40      0.29      0.33         7\n",
      "        ë¹„ìœ„ìƒí•¨       0.00      0.00      0.00         1\n",
      "         ì‚¬ë‚˜ì›€       0.20      0.25      0.22         4\n",
      "         ìˆ˜ì¹˜ì‹¬       0.00      0.00      0.00         3\n",
      "         ì‹œê¸°ì‹¬       0.20      0.50      0.29         2\n",
      "         ì‹ ë¢°ê°       0.00      0.00      0.00         1\n",
      "         ì‹ ëª…ë‚¨       1.00      0.20      0.33         5\n",
      "          ì‹¤ë§       0.11      0.31      0.16        13\n",
      "          ì‹«ì¦       0.00      0.00      0.00         9\n",
      "         ì‹¬ì‹¬í•¨       0.00      0.00      0.00         1\n",
      "         ì•„ì‰¬ì›€       0.43      0.30      0.36        33\n",
      "          ì•„í””       0.00      0.00      0.00         3\n",
      "         ì•ˆì •ê°       0.20      0.12      0.15         8\n",
      "         ì–µìš¸í•¨       0.18      0.46      0.26        13\n",
      "         ì™¸ë¡œì›€       0.50      0.17      0.25         6\n",
      "          ì™¸ë©´       0.00      0.00      0.00         1\n",
      "          ìš•ì‹¬       0.21      0.44      0.29        18\n",
      "          ì›ë§       0.00      0.00      0.00         3\n",
      "         ìœ„ì¶•ê°       0.00      0.00      0.00         4\n",
      "       ìë‘ìŠ¤ëŸ¬ì›€       0.16      0.42      0.23        12\n",
      "         ìì‹ ê°       0.00      0.00      0.00         1\n",
      "          ì ˆë§       0.00      0.00      0.00         7\n",
      "         ì£„ì±…ê°       0.00      0.00      0.00         2\n",
      "         ì¦ê±°ì›€       0.40      0.44      0.42        27\n",
      "         ì´ˆì¡°í•¨       0.00      0.00      0.00         5\n",
      "         ì¹˜ì‚¬í•¨       0.00      0.00      0.00         5\n",
      "         íƒ€ì˜¤ë¦„       0.00      0.00      0.00         3\n",
      "         í†µì¾Œí•¨       0.00      0.00      0.00         1\n",
      "         í¸ì•ˆí•¨       0.50      0.25      0.33         4\n",
      "          í—ˆë§       0.30      0.27      0.29        11\n",
      "          í˜¸ê°       0.33      0.10      0.15        10\n",
      "          í›„íšŒ       0.33      0.29      0.31         7\n",
      "\n",
      "    accuracy                           0.24       664\n",
      "   macro avg       0.20      0.16      0.15       664\n",
      "weighted avg       0.28      0.24      0.23       664\n",
      "\n",
      "\n",
      "ğŸ¯ Category2 ì „ì²´ ì •í™•ë„: 0.2425 (24.25%)\n",
      "í‰ê°€ ë°ì´í„°: 664ê°œ ëª¨ë‘ í‰ê°€\n",
      "\n",
      "ğŸ” Category2 ì˜ˆì¸¡ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):\n",
      "----------------------------------------------------------------------------------------------------\n",
      " 1. âŒ Cat1: ê¸°ì¨ â†’ ê¸°ì¨ | Cat2: ë§Œì¡±ê°          â†’ ì¦ê±°ì›€         \n",
      "    í…ìŠ¤íŠ¸: ë³´ëŠ”ë™ì•ˆ ë„ˆë¬´ í–‰ë³µí–ˆê³  ì´ˆì½œë ›ì´ ë„ˆë¬´ ë¨¹ê³ ì‹¶ì—ˆê³  í‹°ëª¨ì‹œê°€ ì˜ìƒê²¼ê³  ìš¸ì–´!!í•˜ëŠ”ë¶€ë¶„ì´ ìˆì–´ì„œ...\n",
      "\n",
      " 2. âŒ Cat1: ê¸°ì¨ â†’ ê¸°ì¨ | Cat2: ë§Œì¡±ê°          â†’ ê¸°ëŒ€ê°         \n",
      "    í…ìŠ¤íŠ¸: ì–´ë¦´ ë•Œ ê°€ ë³´ê³  ë¹•ìŠ¤ëŠ” ê±°ì˜ ì²˜ìŒì¸ë°(ê¸°ì–µì— ì—†ìŒ) ì§€ê¸ˆ ë”¸ê¸°ì¶•ì œ ê¸°ê°„ì´ë¼ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì‹...\n",
      "\n",
      " 3. âœ… Cat1: ê¸°ì¨ â†’ ê¸°ì¨ | Cat2: ë§Œì¡±ê°          â†’ ë§Œì¡±ê°         \n",
      "    í…ìŠ¤íŠ¸: ë¯¸ë¦¬ ê³„ì¢Œë¡œ í™˜ì „í•´ë‘” ëˆì„ í•´ì™¸ì—ì„œ í™˜ì „ìˆ˜ìˆ˜ë£Œ ì—†ì´ ì¸ì¶œ ê°€ëŠ¥í•œ íŠ¸ë ˆë¸”ë¡œê·¸ë¼ëŠ” ì¹´ë“œì¸ë°, ...\n",
      "\n",
      " 4. âŒ Cat1: ìŠ¬í”” â†’ ì‹«ì–´í•¨(ìƒíƒœ) | Cat2: ë¬´ê¸°ë ¥          â†’ ë‚œì²˜í•¨         \n",
      "    í…ìŠ¤íŠ¸: ìš”ì¦˜ ë²ˆì•„ì›ƒë„ ìê¾¸ ì˜¬ë¼ì˜¤ê³  ë¬´ê¸°ë ¥í•´ì„œ ì¢…ê°•í•˜ê³  êµë¥˜í•˜ê¸°ë„ ë²„ê±°ìš´ ìƒíƒœê°€ ì™€ë¶€ë €ìœ¼ìš”ã… ã…  \n",
      "\n",
      " 5. âŒ Cat1: ê¸°ì¨ â†’ ë¯¸ì›€(ìƒëŒ€ë°©) | Cat2: ì¦ê±°ì›€          â†’ ë¹„ìœ„ìƒí•¨        \n",
      "    í…ìŠ¤íŠ¸: í¬ë¼ì„ì”¬ ì¥ë˜¥ë¯¼ì´ ë²”í–‰ ë„êµ¬ ì°¾ìœ¼ë ¤ê³  í™”ì¥ì‹¤ íƒ±í¬ ë’¤ì§€ëŠ”ë° ê±°ê¸°ì— ì§„ì§œ ë˜¥ ë„£ì–´ë†“ì€ ê±° ì§„...\n",
      "\n",
      " 6. âŒ Cat1: ì‹«ì–´í•¨(ìƒíƒœ) â†’ ìŠ¬í”” | Cat2: ë‹µë‹µí•¨          â†’ ë¬´ê¸°ë ¥         \n",
      "    í…ìŠ¤íŠ¸: ê°€ìŠ´ì´ ë‹µë‹µí•´ì§ ì§„ì§œ ê°œë‹µë‹µí•´ì§\n",
      "ìš°ë¦¬ì§„ì§œíˆ¬í‘œì˜í•˜ì\n",
      "\n",
      " 7. âŒ Cat1: ê¸°ì¨ â†’ ìš•ë§ | Cat2: ë§Œì¡±ê°          â†’ ìš•ì‹¬          \n",
      "    í…ìŠ¤íŠ¸: ì§€ê·¸ì¬ê·¸ë‘ ì—ì´ë¸”ë¦¬ë‘ í• ì¸ ëŒ€ê²°í•˜ë‚˜\n",
      "ì•„ íë­‡í•´\n",
      "ê³„ì†ë˜ê¸¸...\n",
      "ì˜ì›íˆ....\n",
      "\n",
      " 8. âŒ Cat1: ê¸°ì¨ â†’ ìš•ë§ | Cat2: ìë‘ìŠ¤ëŸ¬ì›€        â†’ ìš•ì‹¬          \n",
      "    í…ìŠ¤íŠ¸: ì²¨ìœ¼ë¡œ ìˆ˜ì œ ì´ˆì½œë¦¿ ë§Œë“¬\n",
      "ì´ˆì½œë¦¿ì„ 5ì‹œê°„ì´ë‚˜ ë§Œë“œëŠ” ì‚¬ëŒì´ ìˆë‹¤??? ê·¸ê²Œ ë°”ë¡œ ë‚˜\n",
      "\n",
      " 9. âŒ Cat1: ìŠ¬í”” â†’ ê¸°ì¨ | Cat2: ì ˆë§           â†’ ê¸°ëŒ€ê°         \n",
      "    í…ìŠ¤íŠ¸: ë‹¨í†¡ë°©ì— ê³µì§€ë“¤ ìŠ¬ìŠ¬ ì˜¬ë¼ì˜¤ëŠ”ê±° ë³´ë‹ˆê¹Œ ê³§ ê°œê°•ì´ë¼ëŠ”ê²Œ ì‹¤ê°ë‚˜ì„œ ê°‘ìê¸° ì¬ê¸°í•˜ê³ ì‹¶ê³  ì¸ìƒì´...\n",
      "\n",
      "10. âŒ Cat1: ê¸°ì¨ â†’ ê¸°ì¨ | Cat2: ì¦ê±°ì›€          â†’ ê°ë™          \n",
      "    í…ìŠ¤íŠ¸: ì¥í¥ì‹  ê³µì†í•œ ì†ê°€ë½ì§ˆ ê°œì›ƒê²¨ìš”\n",
      "ì• ë“œë¦½ ë¯¸ì¹œê²ƒ ê°™ìŒ\n",
      "\n",
      "\n",
      "ğŸ“ˆ Category2 í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ìš”ì•½:\n",
      "------------------------------------------------------------\n",
      "í´ë˜ìŠ¤             ì „ì²´       ì •ë‹µ       ì •í™•ë„       \n",
      "--------------------------------------------------\n",
      "ê°ˆë“±              1        0        0.0000\n",
      "ê°ë™              30       12       0.4000\n",
      "ê±±ì •              23       3        0.1304\n",
      "ê²½ë©¸              18       8        0.4444\n",
      "ê³ ë§ˆì›€             19       12       0.6316\n",
      "ê³ í†µ              9        0        0.0000\n",
      "ê³µê°              7        0        0.0000\n",
      "ê³µí¬              17       0        0.0000\n",
      "ê¶ê¸ˆí•¨             9        5        0.5556\n",
      "ê·€ì¤‘í•¨             5        0        0.0000\n",
      "ê·¸ë¦¬ì›€             11       1        0.0909\n",
      "ê¸°ëŒ€ê°             18       7        0.3889\n",
      "ë‚œì²˜í•¨             14       1        0.0714\n",
      "ë‚ ì¹´ë¡œì›€            3        0        0.0000\n",
      "ëƒ‰ë‹´              3        0        0.0000\n",
      "ë„ˆê·¸ëŸ¬ì›€            1        0        0.0000\n",
      "ë†€ëŒ              31       6        0.1935\n",
      "ë‹¤ì •í•¨             9        0        0.0000\n",
      "ë‹µë‹µí•¨             18       2        0.1111\n",
      "ë™ì •(ìŠ¬í””)          27       13       0.4815\n",
      "ë‘ê·¼ê±°ë¦¼            2        0        0.0000\n",
      "ë§Œì¡±ê°             49       17       0.3469\n",
      "ë§¤ë ¥ì              13       1        0.0769\n",
      "ë¬´ê¸°ë ¥             14       5        0.3571\n",
      "ë¯¸ì•ˆí•¨             7        2        0.2857\n",
      "ë°˜ê°€ì›€             16       1        0.0625\n",
      "ë°˜ê°              5        1        0.2000\n",
      "ë°œì—´              3        0        0.0000\n",
      "ë¶€ë„ëŸ¬ì›€            16       0        0.0000\n",
      "ë¶ˆë§Œ              8        1        0.1250\n",
      "ë¶ˆì‹ ê°             8        1        0.1250\n",
      "ë¶ˆì¾Œ              20       3        0.1500\n",
      "ë¶ˆí¸í•¨             7        2        0.2857\n",
      "ë¹„ìœ„ìƒí•¨            1        0        0.0000\n",
      "ì‚¬ë‚˜ì›€             4        1        0.2500\n",
      "ìˆ˜ì¹˜ì‹¬             3        0        0.0000\n",
      "ì‹œê¸°ì‹¬             2        1        0.5000\n",
      "ì‹ ë¢°ê°             1        0        0.0000\n",
      "ì‹ ëª…ë‚¨             5        1        0.2000\n",
      "ì‹¤ë§              13       4        0.3077\n",
      "ì‹«ì¦              9        0        0.0000\n",
      "ì‹¬ì‹¬í•¨             1        0        0.0000\n",
      "ì•„ì‰¬ì›€             33       10       0.3030\n",
      "ì•„í””              3        0        0.0000\n",
      "ì•ˆì •ê°             8        1        0.1250\n",
      "ì–µìš¸í•¨             13       6        0.4615\n",
      "ì™¸ë¡œì›€             6        1        0.1667\n",
      "ì™¸ë©´              1        0        0.0000\n",
      "ìš•ì‹¬              18       8        0.4444\n",
      "ì›ë§              3        0        0.0000\n",
      "ìœ„ì¶•ê°             4        0        0.0000\n",
      "ìë‘ìŠ¤ëŸ¬ì›€           12       5        0.4167\n",
      "ìì‹ ê°             1        0        0.0000\n",
      "ì ˆë§              7        0        0.0000\n",
      "ì£„ì±…ê°             2        0        0.0000\n",
      "ì¦ê±°ì›€             27       12       0.4444\n",
      "ì´ˆì¡°í•¨             5        0        0.0000\n",
      "ì¹˜ì‚¬í•¨             5        0        0.0000\n",
      "íƒ€ì˜¤ë¦„             3        0        0.0000\n",
      "í†µì¾Œí•¨             1        0        0.0000\n",
      "í¸ì•ˆí•¨             4        1        0.2500\n",
      "í—ˆë§              11       3        0.2727\n",
      "í˜¸ê°              10       1        0.1000\n",
      "í›„íšŒ              7        2        0.2857\n",
      "\n",
      "ğŸ“Š ìµœì¢… ì„±ëŠ¥ ë¹„êµ:\n",
      "============================================================\n",
      "Category1 ì •í™•ë„: 0.4880 (48.80%)\n",
      "Category2 ì •í™•ë„: 0.2425 (24.25%)\n",
      "âœ… Category1 ë¶„ë¥˜ê°€ ë” ì •í™•í•©ë‹ˆë‹¤.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Category2 ëª¨ë¸ë¡œ test_data ì˜ˆì¸¡ ë° classification_report\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ğŸ¯ Category2 ëª¨ë¸ì˜ test_data ì„±ëŠ¥ í‰ê°€\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. í•„ìš”í•œ ë³€ìˆ˜ë“¤ ì •ì˜ (í•„ìš”ì‹œ)\n",
    "if 'X_combined' not in locals():\n",
    "    print(\"Category2 í•™ìŠµìš© ë³€ìˆ˜ë“¤ì„ ì¬ì •ì˜í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    # OneHotEncoder for Category1\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    cat1_encoder = OneHotEncoder(sparse_output=False)\n",
    "    y_cat1_onehot = cat1_encoder.fit_transform(y.reshape(-1, 1))\n",
    "    \n",
    "    # Combined features for Category2\n",
    "    X_combined = np.hstack([X, y_cat1_onehot])\n",
    "    \n",
    "    # Category2 encoder - ë³€ê²½: category2 â†’ re_category2 (ì¤‘ë¦½ ì œê±°ëœ ë°ì´í„° ì‚¬ìš©)\n",
    "    y_cat2 = data['re_category2'].values\n",
    "    print(f\"ğŸ“Š Category2 ë°ì´í„° í™•ì¸:\")\n",
    "    print(f\"  - ì „ì²´ Category2 ë°ì´í„°: {len(y_cat2)}ê°œ\")\n",
    "    print(f\"  - ê³ ìœ  Category2 í´ë˜ìŠ¤: {len(np.unique(y_cat2))}ê°œ\")\n",
    "    print(f\"  - Category2 í´ë˜ìŠ¤ ëª©ë¡: {sorted(np.unique(y_cat2))}\")\n",
    "    \n",
    "    # ì¤‘ë¦½ ì œê±° í™•ì¸\n",
    "    neutral_count = (y_cat2 == 'ì¤‘ë¦½').sum()\n",
    "    if neutral_count > 0:\n",
    "        print(f\"âš ï¸ ê²½ê³ : Category2ì— ì—¬ì „íˆ ì¤‘ë¦½ì´ {neutral_count}ê°œ ìˆìŠµë‹ˆë‹¤!\")\n",
    "    else:\n",
    "        print(\"âœ… Category2ì—ì„œ ì¤‘ë¦½ì´ ì„±ê³µì ìœ¼ë¡œ ì œê±°ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "    \n",
    "    le_cat2 = LabelEncoder()\n",
    "    y_cat2_encoded = le_cat2.fit_transform(y_cat2)\n",
    "    \n",
    "    print(f\"  - ì¸ì½”ë”©ëœ Category2 í´ë˜ìŠ¤: {len(le_cat2.classes_)}ê°œ\")\n",
    "    \n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    print(f\"y_cat1_onehot shape: {y_cat1_onehot.shape}\")\n",
    "    print(f\"X_combined shape: {X_combined.shape}\")\n",
    "    print(f\"y_cat2 shape: {y_cat2.shape}\")\n",
    "    print(f\"y_cat2_encoded shape: {y_cat2_encoded.shape}\")\n",
    "    \n",
    "    # í¬ê¸° í™•ì¸ ë° ìˆ˜ì •\n",
    "    if X_combined.shape[0] != y_cat2_encoded.shape[0]:\n",
    "        print(f\"âš ï¸ í¬ê¸° ë¶ˆì¼ì¹˜ ê°ì§€: X_combined {X_combined.shape[0]} vs y_cat2_encoded {y_cat2_encoded.shape[0]}\")\n",
    "        min_size = min(X_combined.shape[0], y_cat2_encoded.shape[0])\n",
    "        X_combined = X_combined[:min_size]\n",
    "        y_cat2_encoded = y_cat2_encoded[:min_size]\n",
    "        print(f\"âœ… í¬ê¸° ì¡°ì • ì™„ë£Œ: {X_combined.shape[0]} rows\")\n",
    "\n",
    "# 2. Category1ì„ ë¨¼ì € ì˜ˆì¸¡í•´ì•¼ Category2ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŒ\n",
    "print(\"\\nğŸ“ Category2 ì˜ˆì¸¡ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„...\")\n",
    "\n",
    "# test_dataì˜ ì‹¤ì œ category1ê³¼ category2\n",
    "test_y_actual_cat1 = test_data['category1'].values\n",
    "test_y_actual_cat2 = test_data['category2'].values\n",
    "\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„°:\")\n",
    "print(f\"- Category1 ì‹¤ì œê°’: {len(test_y_actual_cat1)}ê°œ\")\n",
    "print(f\"- Category2 ì‹¤ì œê°’: {len(test_y_actual_cat2)}ê°œ\")\n",
    "print(f\"- í…ŒìŠ¤íŠ¸ Category2 í´ë˜ìŠ¤: {len(np.unique(test_y_actual_cat2))}ê°œ\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì¤‘ë¦½ í™•ì¸ ë° í•„í„°ë§ ì •ë³´\n",
    "test_cat1_neutral_count = (test_y_actual_cat1 == 'ì¤‘ë¦½').sum()\n",
    "test_cat2_neutral_count = (test_y_actual_cat2 == 'ì¤‘ë¦½').sum()\n",
    "print(f\"- í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤‘ë¦½: Category1={test_cat1_neutral_count}ê°œ, Category2={test_cat2_neutral_count}ê°œ\")\n",
    "\n",
    "# Category1 ì˜ˆì¸¡ê°’ì„ ì‚¬ìš©í•˜ì—¬ Category2 ì˜ˆì¸¡ìš© íŠ¹ì„± ìƒì„±\n",
    "print(\"\\nğŸ”§ Category1 ì˜ˆì¸¡ê°’ìœ¼ë¡œ Category2 ì˜ˆì¸¡ìš© íŠ¹ì„± ìƒì„±...\")\n",
    "\n",
    "# Category1 ì˜ˆì¸¡ê°’ì„ ì›í•«ì¸ì½”ë”©\n",
    "test_cat1_onehot = cat1_encoder.transform(test_y_pred.reshape(-1, 1))\n",
    "test_X_combined = np.hstack([test_X, test_cat1_onehot])\n",
    "\n",
    "print(f\"test_X shape: {test_X.shape}\")\n",
    "print(f\"test_cat1_onehot shape: {test_cat1_onehot.shape}\")\n",
    "print(f\"âœ… ê²°í•©ëœ íŠ¹ì„±: {test_X_combined.shape}\")\n",
    "\n",
    "# 3. ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ Category2 ìµœì¢… ëª¨ë¸ í•™ìŠµ\n",
    "print(\"\\nğŸ”„ ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ Category2 ìµœì¢… ëª¨ë¸ í•™ìŠµ...\")\n",
    "print(f\"í•™ìŠµ ë°ì´í„° í™•ì¸: X_combined {X_combined.shape}, y_cat2_encoded {y_cat2_encoded.shape}\")\n",
    "\n",
    "final_cat2_model = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ì „ì²´ í•™ìŠµ ë°ì´í„°ë¡œ Category2 ëª¨ë¸ í•™ìŠµ\n",
    "final_cat2_model.fit(X_combined, y_cat2_encoded)\n",
    "print(\"âœ… Category2 ìµœì¢… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\")\n",
    "\n",
    "# 4. test_dataë¡œ Category2 ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "print(\"\\nğŸ¯ test_data Category2 ì˜ˆì¸¡ ìˆ˜í–‰...\")\n",
    "test_y_pred_cat2_encoded = final_cat2_model.predict(test_X_combined)\n",
    "test_y_pred_cat2 = le_cat2.inverse_transform(test_y_pred_cat2_encoded)\n",
    "\n",
    "# 5. í•™ìŠµ í´ë˜ìŠ¤ì™€ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤ ë¹„êµ (Category2)\n",
    "train_classes_cat2 = set(le_cat2.classes_)\n",
    "test_actual_classes_cat2 = set(test_y_actual_cat2)\n",
    "\n",
    "print(f\"\\nğŸ“‹ Category2 í´ë˜ìŠ¤ ì •ë³´:\")\n",
    "print(f\"í•™ìŠµ í´ë˜ìŠ¤ ìˆ˜: {len(train_classes_cat2)}\")\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ì‹¤ì œ í´ë˜ìŠ¤ ìˆ˜: {len(test_actual_classes_cat2)}\")\n",
    "\n",
    "# í•™ìŠµì— ì—†ëŠ” í´ë˜ìŠ¤ í™•ì¸\n",
    "unseen_classes_cat2 = test_actual_classes_cat2 - train_classes_cat2\n",
    "if unseen_classes_cat2:\n",
    "    print(f\"âš ï¸ í•™ìŠµì— ì—†ë˜ Category2 í´ë˜ìŠ¤ë“¤: {unseen_classes_cat2}\")\n",
    "\n",
    "common_classes_cat2 = train_classes_cat2 & test_actual_classes_cat2\n",
    "print(f\"ê³µí†µ í´ë˜ìŠ¤ ìˆ˜: {len(common_classes_cat2)}\")\n",
    "\n",
    "# í´ë˜ìŠ¤ ë§¤ì¹˜ í™•ì¸\n",
    "if len(train_classes_cat2) == len(test_actual_classes_cat2) == len(common_classes_cat2):\n",
    "    print(\"âœ… í›ˆë ¨ ë°ì´í„°ì™€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ Category2 í´ë˜ìŠ¤ê°€ ì™„ë²½íˆ ì¼ì¹˜í•©ë‹ˆë‹¤!\")\n",
    "else:\n",
    "    print(\"âŒ í´ë˜ìŠ¤ ë¶ˆì¼ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# 6. Category2 Classification Report ìƒì„±\n",
    "print(f\"\\nğŸ“Š Category2 Classification Report:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ëª¨ë“  í´ë˜ìŠ¤ê°€ ì¼ì¹˜í•˜ë¯€ë¡œ ì „ì²´ í‰ê°€ ê°€ëŠ¥\n",
    "test_y_actual_cat2_encoded = le_cat2.transform(test_y_actual_cat2)\n",
    "report = classification_report(\n",
    "    test_y_actual_cat2_encoded,\n",
    "    test_y_pred_cat2_encoded,\n",
    "    target_names=le_cat2.classes_\n",
    ")\n",
    "print(report)\n",
    "\n",
    "# ì „ì²´ ì •í™•ë„\n",
    "accuracy_cat2 = (test_y_pred_cat2 == test_y_actual_cat2).mean()\n",
    "print(f\"\\nğŸ¯ Category2 ì „ì²´ ì •í™•ë„: {accuracy_cat2:.4f} ({accuracy_cat2*100:.2f}%)\")\n",
    "print(f\"í‰ê°€ ë°ì´í„°: {len(test_y_actual_cat2)}ê°œ ëª¨ë‘ í‰ê°€\")\n",
    "\n",
    "# 7. Category2 ì˜ˆì¸¡ ìƒ˜í”Œ ì¶œë ¥\n",
    "print(f\"\\nğŸ” Category2 ì˜ˆì¸¡ ìƒ˜í”Œ (ì²˜ìŒ 10ê°œ):\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for i in range(min(10, len(test_texts))):\n",
    "    text = test_texts[i][:50] + \"...\" if len(test_texts[i]) > 50 else test_texts[i]\n",
    "    actual_cat1 = test_y_actual_cat1[i]\n",
    "    pred_cat1 = test_y_pred[i]\n",
    "    actual_cat2 = test_y_actual_cat2[i]\n",
    "    pred_cat2 = test_y_pred_cat2[i]\n",
    "    status_cat2 = \"âœ…\" if actual_cat2 == pred_cat2 else \"âŒ\"\n",
    "    \n",
    "    print(f\"{i+1:2d}. {status_cat2} Cat1: {actual_cat1} â†’ {pred_cat1} | Cat2: {actual_cat2:<12} â†’ {pred_cat2:<12}\")\n",
    "    print(f\"    í…ìŠ¤íŠ¸: {text}\")\n",
    "    print()\n",
    "\n",
    "# 8. Category2 í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ìš”ì•½\n",
    "print(f\"\\nğŸ“ˆ Category2 í´ë˜ìŠ¤ë³„ ì„±ëŠ¥ ìš”ì•½:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "class_stats_cat2 = defaultdict(lambda: {'total': 0, 'correct': 0})\n",
    "\n",
    "for actual, pred in zip(test_y_actual_cat2, test_y_pred_cat2):\n",
    "    class_stats_cat2[actual]['total'] += 1\n",
    "    if actual == pred:\n",
    "        class_stats_cat2[actual]['correct'] += 1\n",
    "\n",
    "print(f\"{'í´ë˜ìŠ¤':<15} {'ì „ì²´':<8} {'ì •ë‹µ':<8} {'ì •í™•ë„':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for class_name, stats in sorted(class_stats_cat2.items()):\n",
    "    if stats['total'] > 0:\n",
    "        class_accuracy = stats['correct'] / stats['total']\n",
    "        print(f\"{class_name:<15} {stats['total']:<8} {stats['correct']:<8} {class_accuracy:.4f}\")\n",
    "\n",
    "# 9. Category1 vs Category2 ì„±ëŠ¥ ë¹„êµ\n",
    "print(f\"\\nğŸ“Š ìµœì¢… ì„±ëŠ¥ ë¹„êµ:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Category1 ì •í™•ë„: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Category2 ì •í™•ë„: {accuracy_cat2:.4f} ({accuracy_cat2*100:.2f}%)\")\n",
    "\n",
    "if accuracy > accuracy_cat2:\n",
    "    print(\"âœ… Category1 ë¶„ë¥˜ê°€ ë” ì •í™•í•©ë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"âœ… Category2 ë¶„ë¥˜ê°€ ë” ì •í™•í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "404da083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì–˜ë“¤ì•„ ë”¸ê¸°ì¶•ì œì¸ê°€ ë”¸ê¸°ì¥ë¡€ì‹ì¸ê°€ëŠ” ë­ ê°€ì§€ë§ˆë¼\n",
      "ì–´ìš° ë³„ë¡œë¥¼ ë„˜ì–´ì„œ ì•„ê¹ë‹¤ ê·¸ëƒ¥\n",
      "í•¸ë“œí° ë°”ê¿¨ëŠ”ë°.. ì–´ì°Œë‚˜ ì „ë‡Œì´ì‹ì´ ì˜ë˜ëŠ”ì§€ ì´ì „ í°ì—ì„œ ë“£ë˜ ìŒì•… ë©ˆì¶°ë‘” ë¶€ë¶„ê¹Œì§€ ì‚´ë ¤ë†”ì„œ ìƒˆë¡œ ì‚° ê¸°ë¶„ì´ ì „í˜€ ì•ˆë‚¨..\n",
      "ì¹œêµ¬ê°€ ë§Œë“¤ì–´ì¤¬ì–´ ì–´ì´ì—†ì–´ì„œ ë°›ìë§ˆì ì˜¤ì—´í•¨\n",
      "ì•„ë‹ˆ ë§ê¸´í•œë°\n",
      "ì†”ì§íˆ ì£¼ë§ ê»´ì„œ 4ì¼â€¦ì—°íœ´ë¼ê¸°ì—” ë„ˆë¬´ ëˆˆì†ì„ì„â€¦ì‚¬ì‹¤ìƒ ì´í‹€ ì‰° ê±°ì–ì•„\n",
      "ì†Œì¸ í¸ì˜ì ì—ì„œ ë§¤ì¼ìš°ìœ  í¬ë¦¼ë¹µì„ ë§Œì› ì–´ì¹˜ ì‚¬ë ¤ê³  ê°”ëŠ”ë° 3ê°œë¥¼ ì‚¬ê¸°ì—ëŠ” ë¶€ì¡±í•œ ëˆì´ë¼ ìŠ¬íì†Œì´ë‹¤. ë¬¼ê°€ê°€ ë„ˆë¬´ ë¹„ì‹¼ê²ƒ ê°™ì†Œ.\n",
      "ì—°íœ´ ì´í‹€ì´ ë‹¤ ì£¼ë§ì— ê²¹ì³ì ¸ ìˆì—ˆëŠ”ë° ì™œ ëŒ€ì²´ ê³µíœ´ì¼ì€ í•˜ë£¨ë§Œ ì£¼ëŠ”ê±°ì•¼. ë¶€ì¡±í•´, ì£¼ë§ ìƒê´€ì—†ì´ ì„¤ ì—°íœ´ 3ì¼ ë‹¤ ì™„ë²½í•˜ê²Œ ë³´ì¥í•´ ì¤˜.\n",
      "ì´ë ‡ê²Œ ìê·¹ì ì¸ ë“œë¼ë§ˆ ì•„ì´ë“¤ë„ ë‹¤ ì ‘í• í…ë° ì´ì   ìˆ˜ìœ„ì¡°ì ˆë„ ì•ˆí•˜ê³  ë§‰ì°ëŠ”ê±°ê°™ì•„ì„œ ì¢€ ì•ˆíƒ€ê¹Œì›€ì´ ìƒê¸°ë„¤ìš”â€¦ ã… ã… \n",
      "ì´ì²œ í–…ì‚´ ì»¤í”¼í”„ë¼í”„ì¹˜ë…¸~! ì™ ì§€ ê³ ì†Œí•œ ì»¤í”¼ë§›ì¼êº¼ë€ ê¸°ëŒ€ë¥¼ ì—„ì²­ì•ˆê³  ì£¼ë¬¸í–ˆëŠ”ë°.. ìê·¸ë§ˆì¹˜ 6300ì›ã…œã…œ ë¹„ì‹¼ ê¸ˆì•¡ì¸ë° ë§Œì¡±ìŠ¤ëŸ½ì§„ ëª»í–ˆë‹¤ëˆˆã…œã…œ\n"
     ]
    }
   ],
   "source": [
    "for context in test_data[test_data['category2']=='ë¶ˆë§Œ']['context']:\n",
    "  print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "448dfaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ ê°ì • ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”...\n",
      "âœ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# 10. í†µí•© ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ êµ¬í˜„\n",
    "\n",
    "class EmotionClassificationPipeline:\n",
    "    \"\"\"\n",
    "    í…ìŠ¤íŠ¸ ì…ë ¥ â†’ Category1 ì˜ˆì¸¡ â†’ Category2 ì˜ˆì¸¡ â†’ ì¢…í•© í‰ê°€ íŒŒì´í”„ë¼ì¸\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embeddings_model, cat1_model, cat2_model, \n",
    "                 cat1_encoder, cat2_encoder, cat1_onehot_encoder):\n",
    "        self.embeddings_model = embeddings_model\n",
    "        self.cat1_model = cat1_model\n",
    "        self.cat2_model = cat2_model\n",
    "        self.cat1_encoder = cat1_encoder\n",
    "        self.cat2_encoder = cat2_encoder\n",
    "        self.cat1_onehot_encoder = cat1_onehot_encoder\n",
    "        \n",
    "    def predict_single(self, text):\n",
    "        \"\"\"\n",
    "        ë‹¨ì¼ í…ìŠ¤íŠ¸ì— ëŒ€í•´ ì¹´í…Œê³ ë¦¬1ê³¼ ì¹´í…Œê³ ë¦¬2ë¥¼ ì˜ˆì¸¡\n",
    "        \n",
    "        Args:\n",
    "            text (str): ì˜ˆì¸¡í•  í…ìŠ¤íŠ¸\n",
    "        \n",
    "        Returns:\n",
    "            dict: ì˜ˆì¸¡ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬\n",
    "        \"\"\"\n",
    "        # 1. í…ìŠ¤íŠ¸ ì„ë² ë”©\n",
    "        text_vector = self.embeddings_model.encode(text).reshape(1, -1)\n",
    "        \n",
    "        # 2. Category1 ì˜ˆì¸¡\n",
    "        cat1_pred_encoded = self.cat1_model.predict(text_vector)[0]\n",
    "        cat1_pred = self.cat1_encoder.inverse_transform([cat1_pred_encoded])[0]\n",
    "        cat1_prob = self.cat1_model.predict_proba(text_vector)[0].max()\n",
    "        \n",
    "        # 3. Category1 ì˜ˆì¸¡ê°’ì„ ì‚¬ìš©í•˜ì—¬ Category2 ì˜ˆì¸¡ìš© íŠ¹ì„± ìƒì„±\n",
    "        cat1_onehot = self.cat1_onehot_encoder.transform([[cat1_pred]])\n",
    "        combined_features = np.hstack([text_vector, cat1_onehot])\n",
    "        \n",
    "        # 4. Category2 ì˜ˆì¸¡\n",
    "        cat2_pred_encoded = self.cat2_model.predict(combined_features)[0]\n",
    "        cat2_pred = self.cat2_encoder.inverse_transform([cat2_pred_encoded])[0]\n",
    "        cat2_prob = self.cat2_model.predict_proba(combined_features)[0].max()\n",
    "        \n",
    "        return {\n",
    "            'text': text,\n",
    "            'category1_predicted': cat1_pred,\n",
    "            'category1_confidence': cat1_prob,\n",
    "            'category2_predicted': cat2_pred,\n",
    "            'category2_confidence': cat2_prob\n",
    "        }\n",
    "    \n",
    "    def predict_batch(self, texts):\n",
    "        \"\"\"\n",
    "        ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì— ëŒ€í•´ ë°°ì¹˜ ì˜ˆì¸¡\n",
    "        \n",
    "        Args:\n",
    "            texts (list): ì˜ˆì¸¡í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸\n",
    "        \n",
    "        Returns:\n",
    "            list: ì˜ˆì¸¡ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for text in texts:\n",
    "            result = self.predict_single(text)\n",
    "            results.append(result)\n",
    "        return results\n",
    "    \n",
    "    def evaluate_with_ground_truth(self, texts, true_cat1, true_cat2):\n",
    "        \"\"\"\n",
    "        ì‹¤ì œ ì •ë‹µê³¼ ë¹„êµí•˜ì—¬ ì„±ëŠ¥ í‰ê°€\n",
    "        ë‘ ì¹´í…Œê³ ë¦¬ê°€ ëª¨ë‘ ë§ì€ ê²½ìš°ë§Œ ì •ë‹µìœ¼ë¡œ ì²˜ë¦¬\n",
    "        \n",
    "        Args:\n",
    "            texts (list): ì˜ˆì¸¡í•  í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸\n",
    "            true_cat1 (list): ì‹¤ì œ category1 ë¼ë²¨\n",
    "            true_cat2 (list): ì‹¤ì œ category2 ë¼ë²¨\n",
    "        \n",
    "        Returns:\n",
    "            dict: í‰ê°€ ê²°ê³¼\n",
    "        \"\"\"\n",
    "        predictions = self.predict_batch(texts)\n",
    "        \n",
    "        total_count = len(texts)\n",
    "        cat1_correct = 0\n",
    "        cat2_correct = 0\n",
    "        both_correct = 0\n",
    "        \n",
    "        detailed_results = []\n",
    "        \n",
    "        for i, (pred, actual_cat1, actual_cat2) in enumerate(zip(predictions, true_cat1, true_cat2)):\n",
    "            cat1_match = pred['category1_predicted'] == actual_cat1\n",
    "            cat2_match = pred['category2_predicted'] == actual_cat2\n",
    "            both_match = cat1_match and cat2_match\n",
    "            \n",
    "            if cat1_match:\n",
    "                cat1_correct += 1\n",
    "            if cat2_match:\n",
    "                cat2_correct += 1\n",
    "            if both_match:\n",
    "                both_correct += 1\n",
    "            \n",
    "            detailed_results.append({\n",
    "                'index': i,\n",
    "                'text': pred['text'],\n",
    "                'actual_cat1': actual_cat1,\n",
    "                'predicted_cat1': pred['category1_predicted'],\n",
    "                'cat1_match': cat1_match,\n",
    "                'cat1_confidence': pred['category1_confidence'],\n",
    "                'actual_cat2': actual_cat2,\n",
    "                'predicted_cat2': pred['category2_predicted'],\n",
    "                'cat2_match': cat2_match,\n",
    "                'cat2_confidence': pred['category2_confidence'],\n",
    "                'both_correct': both_match\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'total_samples': total_count,\n",
    "            'category1_accuracy': cat1_correct / total_count,\n",
    "            'category2_accuracy': cat2_correct / total_count,\n",
    "            'both_correct_accuracy': both_correct / total_count,  # í•µì‹¬ ì§€í‘œ\n",
    "            'category1_correct_count': cat1_correct,\n",
    "            'category2_correct_count': cat2_correct,\n",
    "            'both_correct_count': both_correct,\n",
    "            'detailed_results': detailed_results\n",
    "        }\n",
    "\n",
    "# ë³€ìˆ˜ ì´ˆê¸°í™” í™•ì¸ ë° íŒŒì´í”„ë¼ì¸ ê°ì²´ ìƒì„±\n",
    "print(\"ğŸš€ ê°ì • ë¶„ë¥˜ íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”...\")\n",
    "\n",
    "# í•„ìš”í•œ ë³€ìˆ˜ë“¤ì´ ì •ì˜ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
    "required_vars = ['final_cat1_model', 'final_cat2_model', 'le', 'le_cat2', 'cat1_encoder']\n",
    "missing_vars = [var for var in required_vars if var not in locals()]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"âš ï¸ ë‹¤ìŒ ë³€ìˆ˜ë“¤ì´ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤: {missing_vars}\")\n",
    "    print(\"ëª¨ë¸ì„ ë¨¼ì € í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.\")\n",
    "else:\n",
    "    pipeline = EmotionClassificationPipeline(\n",
    "        embeddings_model=embeddings_model,\n",
    "        cat1_model=final_cat1_model,\n",
    "        cat2_model=final_cat2_model,\n",
    "        cat1_encoder=le,\n",
    "        cat2_encoder=le_cat2,\n",
    "        cat1_onehot_encoder=cat1_encoder\n",
    "    )\n",
    "    print(\"âœ… íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™” ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c20c6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ test_data ì¢…í•© í‰ê°€\n",
      "================================================================================\n",
      "í‰ê°€ ë°ì´í„°: 664ê°œ\n",
      "Category1 í´ë˜ìŠ¤ ìˆ˜: 10\n",
      "Category2 í´ë˜ìŠ¤ ìˆ˜: 64\n",
      "í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤‘ë¦½: Category1=5ê°œ, Category2=0ê°œ\n",
      "\n",
      "ğŸ”„ íŒŒì´í”„ë¼ì¸ í‰ê°€ ì‹¤í–‰ ì¤‘...\n",
      "Category1: ì¤‘ë¦½ í¬í•¨í•˜ì—¬ í‰ê°€\n",
      "Category2: ì¤‘ë¦½ ì—†ìŒ (í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ë„ ì—†ìŒ)\n",
      "\n",
      "ğŸ“Š íŒŒì´í”„ë¼ì¸ ì¢…í•© í‰ê°€ ê²°ê³¼:\n",
      "============================================================\n",
      "ì „ì²´ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: 664\n",
      "\n",
      "ğŸ“ˆ ê°œë³„ ì •í™•ë„:\n",
      "  Category1 ì •í™•ë„: 0.4880 (324/664)\n",
      "  Category2 ì •í™•ë„: 0.2425 (161/664)\n",
      "\n",
      "ğŸ¯ í•µì‹¬ ì§€í‘œ - ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì •ë‹µ:\n",
      "  ì¢…í•© ì •í™•ë„: 0.2244 (149/664)\n",
      "  ì¢…í•© ì •í™•ë„: 22.44%\n",
      "\n",
      "ğŸ” ìƒì„¸ ë¶„ì„:\n",
      "------------------------------------------------------------\n",
      "ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì •ë‹µ: 149ê°œ (22.44%)\n",
      "Category1ë§Œ ì •ë‹µ: 175ê°œ (26.36%)\n",
      "Category2ë§Œ ì •ë‹µ: 12ê°œ (1.81%)\n",
      "ë‘˜ ë‹¤ í‹€ë¦¼: 328ê°œ (49.40%)\n",
      "\n",
      "âœ… ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì •ë‹µì¸ ìƒ˜í”Œë“¤ (ì²˜ìŒ 10ê°œ):\n",
      "====================================================================================================\n",
      " 1. Cat1: ê¸°ì¨ âœ“ | Cat2: ë§Œì¡±ê° âœ“\n",
      "    ì‹ ë¢°ë„: Cat1=0.467, Cat2=0.208\n",
      "    í…ìŠ¤íŠ¸: ë¯¸ë¦¬ ê³„ì¢Œë¡œ í™˜ì „í•´ë‘” ëˆì„ í•´ì™¸ì—ì„œ í™˜ì „ìˆ˜ìˆ˜ë£Œ ì—†ì´ ì¸ì¶œ ê°€ëŠ¥í•œ íŠ¸ë ˆë¸”ë¡œê·¸ë¼ëŠ” ì¹´ë“œì¸ë°, ì„ íƒí•  ìˆ˜ ìˆëŠ” ë””...\n",
      "\n",
      " 2. Cat1: ê¸°ì¨ âœ“ | Cat2: ë§Œì¡±ê° âœ“\n",
      "    ì‹ ë¢°ë„: Cat1=0.943, Cat2=0.283\n",
      "    í…ìŠ¤íŠ¸: ìš°ì—°íˆ ë³´ê²Œ ëœ ì˜ìƒì¸ë°, ë…¸ë˜ê°€ ë„ˆë¬´ ì¢‹ì•„ì„œ í”Œë¦¬ì—ë„ ì¶”ê°€í•˜ê³ , ì¹´ì¹´ì˜¤í†¡ í”„ë®¤ë¡œë„ í•´ë†¨ìŒ. ìŒì›ë„ ì¢‹ê¸´ í•œ...\n",
      "\n",
      " 3. Cat1: ìš•ë§ âœ“ | Cat2: ê¶ê¸ˆí•¨ âœ“\n",
      "    ì‹ ë¢°ë„: Cat1=0.653, Cat2=0.422\n",
      "    í…ìŠ¤íŠ¸: ì¼ë³¸ì€ ê·¼ë¬´ì‹œê°„ì— ê°œì¸ë©”ì„¸ì§€ ì•ˆ í•œë‹¤ê³ ??? ì‹ ê¸°\n",
      "ì• ì´ˆì— ê°œì¸ ë©”ì„¸ì§€ ë„êµ¬ì¸ ì¹´ì¹´ì˜¤í†¡ìœ¼ë¡œ ì—…ë¬´ë¥¼ í•˜ëŠ”ë° ì¹œêµ¬...\n",
      "\n",
      " 4. Cat1: ê¸°ì¨ âœ“ | Cat2: ì¦ê±°ì›€ âœ“\n",
      "    ì‹ ë¢°ë„: Cat1=0.415, Cat2=0.367\n",
      "    í…ìŠ¤íŠ¸: ì´ë ‡ê²Œê¹Œì§€ ì¬ë°Œì„ì¤„ì€ ëª°ëìŒ\n",
      "í—‰ ì— ì”¨ ì—†ì´ ì§„í–‰í•˜ë‚˜??\n",
      "í–ˆëŠ”ë° ë‘˜ì˜ í‹°í‚¤íƒ€ì¹´ê°€ ë¯¸ì³¤ìŒ\n",
      "\n",
      " 5. Cat1: ê¸°ì¨ âœ“ | Cat2: ë§Œì¡±ê° âœ“\n",
      "    ì‹ ë¢°ë„: Cat1=0.756, Cat2=0.262\n",
      "    í…ìŠ¤íŠ¸: ì´ˆëŒ€ë°• ê·€ì—¬ìš´ ê°•ì•„ë””ë„ ìˆìŒ ìš°ë¦¬ ìë¦¬ ì™€ì„œ ì¸ì‚¬ë„ í•´ì¤Œ .. ğŸ¥¹\n",
      "ì¢Œì„ì´ ì•½ê°„ ë‹¹í™©ìŠ¤ëŸ¬ìš´ ê²ƒ ë§ê³  ë‹¤ ì¢‹ì•˜ë˜...\n",
      "\n",
      " 6. Cat1: ê¸°ì¨ âœ“ | Cat2: ë§Œì¡±ê° âœ“\n",
      "    ì‹ ë¢°ë„: Cat1=0.641, Cat2=0.773\n",
      "    í…ìŠ¤íŠ¸: í¸ì˜ì  ì´ˆì½œë¦¿ ì¤‘ ê°€ì¥ ë§›ìˆëŠ” ì´ˆì½œë¦¿ì´ë¼ê³  ìƒê°í•˜ì˜¤. ì…ì— ë„£ìë§ˆì ê¸°ë¶„ ì¢‹ì•„ì§€ëŠ” ë§›ì´ì˜¤. \n",
      "\n",
      " 7. Cat1: ë‘ë ¤ì›€ âœ“ | Cat2: ë†€ëŒ âœ“\n",
      "    ì‹ ë¢°ë„: Cat1=0.304, Cat2=0.517\n",
      "    í…ìŠ¤íŠ¸: ì•„ë‹ˆ ë¹„ì˜€ëŠ”ë°!!! ì˜ìƒ8ë„ì˜€ëŠ”ë°!!!! ëˆˆìœ¼ë¡œ ë°”ë€Œì—ˆë‹¤ë‹ˆê¹Œ!!!!! ë‚´ê°€ ê³¼ëª°ì…ì„ í•˜ëŠ”ê²Œ ì•„ë‹ˆë¼!!!! 2...\n",
      "\n",
      " 8. Cat1: ë‘ë ¤ì›€ âœ“ | Cat2: ê±±ì • âœ“\n",
      "    ì‹ ë¢°ë„: Cat1=0.249, Cat2=0.648\n",
      "    í…ìŠ¤íŠ¸: ë‚´ê°€ ì•„ë‹ˆë¼ ë„¤ê°€ ë‹¤ì¹ ê¹Œë´ ê±±ì •ë¼\n",
      "\n",
      " 9. Cat1: ìŠ¬í”” âœ“ | Cat2: í›„íšŒ âœ“\n",
      "    ì‹ ë¢°ë„: Cat1=0.476, Cat2=0.167\n",
      "    í…ìŠ¤íŠ¸: ë„ˆë‘ ë˜ ê·¸ë ‡ê²Œ í—¤ì–´ì§€ê¸° ì‹«ì–´ ê·¸ë•Œë¡œ ì¶©ë¶„í•´\n",
      "\n",
      "10. Cat1: ìš•ë§ âœ“ | Cat2: ìš•ì‹¬ âœ“\n",
      "    ì‹ ë¢°ë„: Cat1=0.706, Cat2=0.293\n",
      "    í…ìŠ¤íŠ¸: ìœ ì£¼ì–¸ë‹ˆ í™˜ì—°ê³ ì • íŒ¨ë„ë¡œ ì„­ì™¸í•´ì•¼ í•œë‹¤ê³  ë´„\n",
      "ì œë°œìš” ë‚´ê°€ í•˜ê³  ì‹¶ì€ ë§ ìœ ì£¼ì–¸ë‹ˆê°€ ë‹¤ í•´ì£¼ì‹¬\n",
      "\n",
      "\n",
      "âŒ ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ í‹€ë¦° ìƒ˜í”Œë“¤ (ì²˜ìŒ 10ê°œ):\n",
      "====================================================================================================\n",
      " 1. Cat1: ìŠ¬í”” â†’ ì‹«ì–´í•¨(ìƒíƒœ) | Cat2: ë¬´ê¸°ë ¥ â†’ ë‚œì²˜í•¨\n",
      "    ì‹ ë¢°ë„: Cat1=0.428, Cat2=0.295\n",
      "    í…ìŠ¤íŠ¸: ìš”ì¦˜ ë²ˆì•„ì›ƒë„ ìê¾¸ ì˜¬ë¼ì˜¤ê³  ë¬´ê¸°ë ¥í•´ì„œ ì¢…ê°•í•˜ê³  êµë¥˜í•˜ê¸°ë„ ë²„ê±°ìš´ ìƒíƒœê°€ ì™€ë¶€ë €ìœ¼ìš”ã… ã…  \n",
      "\n",
      " 2. Cat1: ê¸°ì¨ â†’ ë¯¸ì›€(ìƒëŒ€ë°©) | Cat2: ì¦ê±°ì›€ â†’ ë¹„ìœ„ìƒí•¨\n",
      "    ì‹ ë¢°ë„: Cat1=0.515, Cat2=0.677\n",
      "    í…ìŠ¤íŠ¸: í¬ë¼ì„ì”¬ ì¥ë˜¥ë¯¼ì´ ë²”í–‰ ë„êµ¬ ì°¾ìœ¼ë ¤ê³  í™”ì¥ì‹¤ íƒ±í¬ ë’¤ì§€ëŠ”ë° ê±°ê¸°ì— ì§„ì§œ ë˜¥ ë„£ì–´ë†“ì€ ê±° ì§„ì§œ ì›ƒê²¨ ë’¤ì§€ê² ìŒã…‹...\n",
      "\n",
      " 3. Cat1: ì‹«ì–´í•¨(ìƒíƒœ) â†’ ìŠ¬í”” | Cat2: ë‹µë‹µí•¨ â†’ ë¬´ê¸°ë ¥\n",
      "    ì‹ ë¢°ë„: Cat1=0.476, Cat2=0.244\n",
      "    í…ìŠ¤íŠ¸: ê°€ìŠ´ì´ ë‹µë‹µí•´ì§ ì§„ì§œ ê°œë‹µë‹µí•´ì§\n",
      "ìš°ë¦¬ì§„ì§œíˆ¬í‘œì˜í•˜ì\n",
      "\n",
      " 4. Cat1: ê¸°ì¨ â†’ ìš•ë§ | Cat2: ë§Œì¡±ê° â†’ ìš•ì‹¬\n",
      "    ì‹ ë¢°ë„: Cat1=0.463, Cat2=0.417\n",
      "    í…ìŠ¤íŠ¸: ì§€ê·¸ì¬ê·¸ë‘ ì—ì´ë¸”ë¦¬ë‘ í• ì¸ ëŒ€ê²°í•˜ë‚˜\n",
      "ì•„ íë­‡í•´\n",
      "ê³„ì†ë˜ê¸¸...\n",
      "ì˜ì›íˆ....\n",
      "\n",
      " 5. Cat1: ê¸°ì¨ â†’ ìš•ë§ | Cat2: ìë‘ìŠ¤ëŸ¬ì›€ â†’ ìš•ì‹¬\n",
      "    ì‹ ë¢°ë„: Cat1=0.798, Cat2=0.434\n",
      "    í…ìŠ¤íŠ¸: ì²¨ìœ¼ë¡œ ìˆ˜ì œ ì´ˆì½œë¦¿ ë§Œë“¬\n",
      "ì´ˆì½œë¦¿ì„ 5ì‹œê°„ì´ë‚˜ ë§Œë“œëŠ” ì‚¬ëŒì´ ìˆë‹¤??? ê·¸ê²Œ ë°”ë¡œ ë‚˜\n",
      "\n",
      " 6. Cat1: ìŠ¬í”” â†’ ê¸°ì¨ | Cat2: ì ˆë§ â†’ ê¸°ëŒ€ê°\n",
      "    ì‹ ë¢°ë„: Cat1=0.689, Cat2=0.471\n",
      "    í…ìŠ¤íŠ¸: ë‹¨í†¡ë°©ì— ê³µì§€ë“¤ ìŠ¬ìŠ¬ ì˜¬ë¼ì˜¤ëŠ”ê±° ë³´ë‹ˆê¹Œ ê³§ ê°œê°•ì´ë¼ëŠ”ê²Œ ì‹¤ê°ë‚˜ì„œ ê°‘ìê¸° ì¬ê¸°í•˜ê³ ì‹¶ê³  ì¸ìƒì´ ë‹¤ ëë‚œê±°ì²˜ëŸ¼ ì•”...\n",
      "\n",
      " 7. Cat1: ë¯¸ì›€(ìƒëŒ€ë°©) â†’ ë¶„ë…¸ | Cat2: ì¹˜ì‚¬í•¨ â†’ ì›ë§\n",
      "    ì‹ ë¢°ë„: Cat1=0.667, Cat2=0.336\n",
      "    í…ìŠ¤íŠ¸: ë¯¸ì¹œìƒˆë¼ 4ê°•ì „ë§Œ ì•ˆì¢‹ì•˜ë˜ê±° ì•„ë‹ˆê³  ê·¸ì „ë¶€í„° ì•ˆì¢‹ì•˜ë˜ê±¸ ì‚¬ëŒë“¤ì´ ë‹¤ë´¤ëŠ”ë° ì§€ ì±…ì„ ì—†ë‹¤ê³  ì™ ë¹ ì ¸ë‚˜ê°€ë ¤ê³  ì§€...\n",
      "\n",
      " 8. Cat1: ë‘ë ¤ì›€ â†’ ì‹«ì–´í•¨(ìƒíƒœ) | Cat2: ê±±ì • â†’ ë‹µë‹µí•¨\n",
      "    ì‹ ë¢°ë„: Cat1=0.518, Cat2=0.882\n",
      "    í…ìŠ¤íŠ¸: ë‚˜ í˜„ì¥ì—ì„œ ì—„ì²­ í—¤ë§¬ ê±° ê°™ì€ë° ã… \n",
      "\n",
      " 9. Cat1: ìˆ˜ì¹˜ì‹¬ â†’ ìš•ë§ | Cat2: ë¶€ë„ëŸ¬ì›€ â†’ ê¶ê¸ˆí•¨\n",
      "    ì‹ ë¢°ë„: Cat1=0.500, Cat2=0.817\n",
      "    í…ìŠ¤íŠ¸: ë³´ë¼ìƒ‰ êµë³µ ì¹˜ë‹ˆê¹Œ ì´ëŸ°ê±°ë§Œ ëœ¨ëŠ”ë° ì§€ê¸ˆ ì´ê±¸ ì…ìœ¼ë¼ëŠ”ê±°ì˜ˆìš”?\n",
      "\n",
      "10. Cat1: ë¶„ë…¸ â†’ ë¯¸ì›€(ìƒëŒ€ë°©) | Cat2: ë¶ˆì¾Œ â†’ ì¹˜ì‚¬í•¨\n",
      "    ì‹ ë¢°ë„: Cat1=0.465, Cat2=0.450\n",
      "    í…ìŠ¤íŠ¸: ê·¸ëƒ¥ êµ­ëŒ€ ì œì™¸ ì•„ë¬´ë„ ëª°ëì–´ì•¼ í•  ì‚¬ì‹¤ì„ ì•Œê²Œ ë¼ì„œ ì´ ê¼¬ë½ì„œë‹ˆ ë‚œ ê²Œ ì§œì¦ë‚¨\n",
      "\n",
      "\n",
      "âš–ï¸ ì¤‘ë¦½ ë°ì´í„° ë¶„ì„ (Category1):\n",
      "------------------------------------------------------------\n",
      "ì¤‘ë¦½ ë°ì´í„° ì´ 5ê°œ ì¤‘ 0ê°œ ì •ë‹µ (0.0%)\n",
      "\n",
      "ì¤‘ë¦½ ìƒ˜í”Œ ì˜ˆì¸¡ ê²°ê³¼ (ì²˜ìŒ 5ê°œ):\n",
      "1. âŒ ì˜ˆì¸¡: ìš•ë§ (ì‹ ë¢°ë„: 0.667)\n",
      "   í…ìŠ¤íŠ¸: ê°€ë©´ ì“´ ì‚¬ëŒì˜ ì˜ìƒì´ ì¼ë³¸êµ° ì œë³µì—ì„œ ë°”ë€Œì—ˆë„¤ìš” ì˜›ë‚ ì²˜ëŸ¼ ì¼ë³¸ë‚´ ì„±ì ë§Œ ì˜¬ë¦¬ë©´ ê·¸ë§Œì´ë˜ ...\n",
      "2. âŒ ì˜ˆì¸¡: ê¸°ì¨ (ì‹ ë¢°ë„: 0.337)\n",
      "   í…ìŠ¤íŠ¸: ì‚´ì¸ìã…‡ë‚œê° ì‚´ì¸ì¥ë©´ì¤‘ ê°€ì¥ ìƒˆë¡­ê³  ì‹ ì„ í•œ ì—°ì¶œì´ë¼ ê°ë…ë‹˜ì´ ë§í•œ íŒí•˜ë‹¤ëŠ” ì—°ì¶œ ë­”ì§€ ì•Œêº¼...\n",
      "3. âŒ ì˜ˆì¸¡: ê¸°ì¨ (ì‹ ë¢°ë„: 0.912)\n",
      "   í…ìŠ¤íŠ¸: 100ì¼ë„ì•ˆëœ ì•„ê¸°êº¼ í•œë³µì´ ìˆë‹¤ëŠ”ê²Œ ë†€ëë‹¤\n",
      "4. âŒ ì˜ˆì¸¡: ë¯¸ì›€(ìƒëŒ€ë°©) (ì‹ ë¢°ë„: 0.424)\n",
      "   í…ìŠ¤íŠ¸: ì˜ë§Œ ë¬¼ë˜ ìª½ìª½ì´ë¥¼ í•˜ë£¨ ì•„ì¹¨ì— ê±°ë¶€í•˜ë‹ˆ ì—„ë§ˆëŠ” ë‹¹í™©ìŠ¤ëŸ½ë‹¤\n",
      "5. âŒ ì˜ˆì¸¡: ê¸°ì¨ (ì‹ ë¢°ë„: 0.771)\n",
      "   í…ìŠ¤íŠ¸: ë‚˜ë§Œ ë†€ë¼ìš´ ê±´ê°€ìš”? ëª°ì…ì„ ì“°ì‹  í™©ë†ë¬¸êµìˆ˜ë‹˜ê»˜ ë©”ì¼ë³´ëƒˆë‹¤ëŠ” ê²ƒ!?? ëŒ€ë‹¨í•œ í–‰ë™ë ¥ì´ì‹œë„¤ìš”...\n",
      "\n",
      "ğŸ”¥ ê²°ë¡ :\n",
      "ì´ íŒŒì´í”„ë¼ì¸ì—ì„œ ë‘ ì¹´í…Œê³ ë¦¬ê°€ ëª¨ë‘ ì •í™•í•˜ê²Œ ì˜ˆì¸¡ëœ ê²½ìš°ëŠ” ì „ì²´ì˜ 22.44%ì…ë‹ˆë‹¤.\n",
      "â€» Category1ì€ ì¤‘ë¦½ì„ í¬í•¨í•˜ì—¬ í‰ê°€, Category2ëŠ” ì¤‘ë¦½ì´ ì—†ì–´ ì¼ì¹˜í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# 11. íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ test_data í‰ê°€ (ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ë§ì€ ê²½ìš°ë§Œ ì •ë‹µ ì²˜ë¦¬)\n",
    "\n",
    "print(\"ğŸ¯ íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ test_data ì¢…í•© í‰ê°€\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# test_data ì¤€ë¹„\n",
    "test_texts = test_data['context'].fillna('').astype(str).tolist()\n",
    "test_true_cat1 = test_data['category1'].values\n",
    "test_true_cat2 = test_data['category2'].values\n",
    "\n",
    "print(f\"í‰ê°€ ë°ì´í„°: {len(test_texts)}ê°œ\")\n",
    "print(f\"Category1 í´ë˜ìŠ¤ ìˆ˜: {len(np.unique(test_true_cat1))}\")\n",
    "print(f\"Category2 í´ë˜ìŠ¤ ìˆ˜: {len(np.unique(test_true_cat2))}\")\n",
    "\n",
    "# ì¤‘ë¦½ ë°ì´í„° í™•ì¸\n",
    "neutral_cat1_count = (test_true_cat1 == 'ì¤‘ë¦½').sum()\n",
    "neutral_cat2_count = (test_true_cat2 == 'ì¤‘ë¦½').sum()\n",
    "print(f\"í…ŒìŠ¤íŠ¸ ë°ì´í„° ì¤‘ë¦½: Category1={neutral_cat1_count}ê°œ, Category2={neutral_cat2_count}ê°œ\")\n",
    "\n",
    "# íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì¢…í•© í‰ê°€ ì‹¤í–‰ (ëª¨ë“  ë°ì´í„° ì‚¬ìš© - Category1ì— ì¤‘ë¦½ í¬í•¨)\n",
    "print(f\"\\nğŸ”„ íŒŒì´í”„ë¼ì¸ í‰ê°€ ì‹¤í–‰ ì¤‘...\")\n",
    "print(f\"Category1: ì¤‘ë¦½ í¬í•¨í•˜ì—¬ í‰ê°€\")\n",
    "print(f\"Category2: ì¤‘ë¦½ ì—†ìŒ (í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ë„ ì—†ìŒ)\")\n",
    "\n",
    "evaluation_results = pipeline.evaluate_with_ground_truth(\n",
    "    test_texts, test_true_cat1, test_true_cat2\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print(f\"\\nğŸ“Š íŒŒì´í”„ë¼ì¸ ì¢…í•© í‰ê°€ ê²°ê³¼:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"ì „ì²´ í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ìˆ˜: {evaluation_results['total_samples']}\")\n",
    "print(f\"\")\n",
    "print(f\"ğŸ“ˆ ê°œë³„ ì •í™•ë„:\")\n",
    "print(f\"  Category1 ì •í™•ë„: {evaluation_results['category1_accuracy']:.4f} ({evaluation_results['category1_correct_count']}/{evaluation_results['total_samples']})\")\n",
    "print(f\"  Category2 ì •í™•ë„: {evaluation_results['category2_accuracy']:.4f} ({evaluation_results['category2_correct_count']}/{evaluation_results['total_samples']})\")\n",
    "print(f\"\")\n",
    "print(f\"ğŸ¯ í•µì‹¬ ì§€í‘œ - ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì •ë‹µ:\")\n",
    "print(f\"  ì¢…í•© ì •í™•ë„: {evaluation_results['both_correct_accuracy']:.4f} ({evaluation_results['both_correct_count']}/{evaluation_results['total_samples']})\")\n",
    "print(f\"  ì¢…í•© ì •í™•ë„: {evaluation_results['both_correct_accuracy']*100:.2f}%\")\n",
    "\n",
    "# ìƒì„¸ ë¶„ì„\n",
    "print(f\"\\nğŸ” ìƒì„¸ ë¶„ì„:\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# ì¹´í…Œê³ ë¦¬ë³„ ë§¤ì¹˜ íŒ¨í„´ ë¶„ì„\n",
    "both_correct = sum(1 for r in evaluation_results['detailed_results'] if r['both_correct'])\n",
    "only_cat1_correct = sum(1 for r in evaluation_results['detailed_results'] if r['cat1_match'] and not r['cat2_match'])\n",
    "only_cat2_correct = sum(1 for r in evaluation_results['detailed_results'] if not r['cat1_match'] and r['cat2_match'])\n",
    "both_wrong = sum(1 for r in evaluation_results['detailed_results'] if not r['cat1_match'] and not r['cat2_match'])\n",
    "\n",
    "print(f\"ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì •ë‹µ: {both_correct}ê°œ ({both_correct/evaluation_results['total_samples']*100:.2f}%)\")\n",
    "print(f\"Category1ë§Œ ì •ë‹µ: {only_cat1_correct}ê°œ ({only_cat1_correct/evaluation_results['total_samples']*100:.2f}%)\")\n",
    "print(f\"Category2ë§Œ ì •ë‹µ: {only_cat2_correct}ê°œ ({only_cat2_correct/evaluation_results['total_samples']*100:.2f}%)\")\n",
    "print(f\"ë‘˜ ë‹¤ í‹€ë¦¼: {both_wrong}ê°œ ({both_wrong/evaluation_results['total_samples']*100:.2f}%)\")\n",
    "\n",
    "# ìƒ˜í”Œ ì¶œë ¥ - ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ë§ì€ ì¼€ì´ìŠ¤\n",
    "print(f\"\\nâœ… ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì •ë‹µì¸ ìƒ˜í”Œë“¤ (ì²˜ìŒ 10ê°œ):\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "correct_samples = [r for r in evaluation_results['detailed_results'] if r['both_correct']]\n",
    "for i, result in enumerate(correct_samples[:10]):\n",
    "    text = result['text'][:60] + \"...\" if len(result['text']) > 60 else result['text']\n",
    "    print(f\"{i+1:2d}. Cat1: {result['actual_cat1']} âœ“ | Cat2: {result['actual_cat2']} âœ“\")\n",
    "    print(f\"    ì‹ ë¢°ë„: Cat1={result['cat1_confidence']:.3f}, Cat2={result['cat2_confidence']:.3f}\")\n",
    "    print(f\"    í…ìŠ¤íŠ¸: {text}\")\n",
    "    print()\n",
    "\n",
    "# ìƒ˜í”Œ ì¶œë ¥ - ë‘˜ ë‹¤ í‹€ë¦° ì¼€ì´ìŠ¤  \n",
    "print(f\"\\nâŒ ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ í‹€ë¦° ìƒ˜í”Œë“¤ (ì²˜ìŒ 10ê°œ):\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "wrong_samples = [r for r in evaluation_results['detailed_results'] if not r['both_correct'] and not r['cat1_match'] and not r['cat2_match']]\n",
    "for i, result in enumerate(wrong_samples[:10]):\n",
    "    text = result['text'][:60] + \"...\" if len(result['text']) > 60 else result['text']\n",
    "    print(f\"{i+1:2d}. Cat1: {result['actual_cat1']} â†’ {result['predicted_cat1']} | Cat2: {result['actual_cat2']} â†’ {result['predicted_cat2']}\")\n",
    "    print(f\"    ì‹ ë¢°ë„: Cat1={result['cat1_confidence']:.3f}, Cat2={result['cat2_confidence']:.3f}\")\n",
    "    print(f\"    í…ìŠ¤íŠ¸: {text}\")\n",
    "    print()\n",
    "\n",
    "# ì¤‘ë¦½ ë°ì´í„° íŠ¹ë³„ ë¶„ì„\n",
    "print(f\"\\nâš–ï¸ ì¤‘ë¦½ ë°ì´í„° ë¶„ì„ (Category1):\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "neutral_results = [r for r in evaluation_results['detailed_results'] if r['actual_cat1'] == 'ì¤‘ë¦½']\n",
    "if len(neutral_results) > 0:\n",
    "    neutral_correct = sum(1 for r in neutral_results if r['cat1_match'])\n",
    "    print(f\"ì¤‘ë¦½ ë°ì´í„° ì´ {len(neutral_results)}ê°œ ì¤‘ {neutral_correct}ê°œ ì •ë‹µ ({neutral_correct/len(neutral_results)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\nì¤‘ë¦½ ìƒ˜í”Œ ì˜ˆì¸¡ ê²°ê³¼ (ì²˜ìŒ 5ê°œ):\")\n",
    "    for i, result in enumerate(neutral_results[:5]):\n",
    "        text = result['text'][:50] + \"...\" if len(result['text']) > 50 else result['text']\n",
    "        status = \"âœ…\" if result['cat1_match'] else \"âŒ\"\n",
    "        print(f\"{i+1}. {status} ì˜ˆì¸¡: {result['predicted_cat1']} (ì‹ ë¢°ë„: {result['cat1_confidence']:.3f})\")\n",
    "        print(f\"   í…ìŠ¤íŠ¸: {text}\")\n",
    "else:\n",
    "    print(\"í…ŒìŠ¤íŠ¸ ë°ì´í„°ì— ì¤‘ë¦½ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "print(f\"\\nğŸ”¥ ê²°ë¡ :\")\n",
    "print(f\"ì´ íŒŒì´í”„ë¼ì¸ì—ì„œ ë‘ ì¹´í…Œê³ ë¦¬ê°€ ëª¨ë‘ ì •í™•í•˜ê²Œ ì˜ˆì¸¡ëœ ê²½ìš°ëŠ” ì „ì²´ì˜ {evaluation_results['both_correct_accuracy']*100:.2f}%ì…ë‹ˆë‹¤.\")\n",
    "print(f\"â€» Category1ì€ ì¤‘ë¦½ì„ í¬í•¨í•˜ì—¬ í‰ê°€, Category2ëŠ” ì¤‘ë¦½ì´ ì—†ì–´ ì¼ì¹˜í•©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "623b7374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ íŒŒì´í”„ë¼ì¸ ì˜ˆì¸¡ ì‹œì—°\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ ì˜ˆì œ 1: ì¹œêµ¬ê°€ ìƒì¼ íŒŒí‹°ë¥¼ ì¤€ë¹„í•´ì¤˜ì„œ ë„ˆë¬´ ê°ë™ë°›ì•˜ì–´\n",
      "------------------------------------------------------------\n",
      "ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼:\n",
      "  Category1: ê¸°ì¨ (ì‹ ë¢°ë„: 0.994)\n",
      "  Category2: ê³ ë§ˆì›€ (ì‹ ë¢°ë„: 0.495)\n",
      "\n",
      "ğŸ“ ì˜ˆì œ 2: ì‹œí—˜ ê²°ê³¼ê°€ ë‚˜ì˜ê²Œ ë‚˜ì™€ì„œ ì •ë§ ì‹¤ë§ìŠ¤ëŸ½ë‹¤\n",
      "------------------------------------------------------------\n",
      "ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼:\n",
      "  Category1: ìŠ¬í”” (ì‹ ë¢°ë„: 0.584)\n",
      "  Category2: ì‹¤ë§ (ì‹ ë¢°ë„: 0.804)\n",
      "\n",
      "ğŸ“ ì˜ˆì œ 3: ìƒˆë¡œìš´ ì§ì¥ì´ í™•ì •ë˜ì–´ì„œ ì„¤ë ˆê³  ê¸°ëŒ€ëœë‹¤\n",
      "------------------------------------------------------------\n",
      "ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼:\n",
      "  Category1: ê¸°ì¨ (ì‹ ë¢°ë„: 0.983)\n",
      "  Category2: ê¸°ëŒ€ê° (ì‹ ë¢°ë„: 0.978)\n",
      "\n",
      "ğŸ“ ì˜ˆì œ 4: ëˆ„êµ°ê°€ ë‚´ ë’·ë‹´í™”ë¥¼ í•˜ëŠ” ê±¸ ë“¤ì–´ì„œ í™”ê°€ ë‚œë‹¤\n",
      "------------------------------------------------------------\n",
      "ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼:\n",
      "  Category1: ë¶„ë…¸ (ì‹ ë¢°ë„: 0.578)\n",
      "  Category2: ë¶ˆì¾Œ (ì‹ ë¢°ë„: 0.826)\n"
     ]
    }
   ],
   "source": [
    "# 12. ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ ì˜ˆì¸¡ ë°ëª¨ í•¨ìˆ˜\n",
    "\n",
    "def demo_pipeline_prediction():\n",
    "    \"\"\"\n",
    "    ìƒˆë¡œìš´ í…ìŠ¤íŠ¸ë“¤ì— ëŒ€í•´ íŒŒì´í”„ë¼ì¸ ì˜ˆì¸¡ ì‹œì—°\n",
    "    \"\"\"\n",
    "    print(\"ğŸš€ íŒŒì´í”„ë¼ì¸ ì˜ˆì¸¡ ì‹œì—°\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ì˜ˆì œ í…ìŠ¤íŠ¸ë“¤\n",
    "    demo_texts = [\n",
    "        \"ì¹œêµ¬ê°€ ìƒì¼ íŒŒí‹°ë¥¼ ì¤€ë¹„í•´ì¤˜ì„œ ë„ˆë¬´ ê°ë™ë°›ì•˜ì–´\",\n",
    "        \"ì‹œí—˜ ê²°ê³¼ê°€ ë‚˜ì˜ê²Œ ë‚˜ì™€ì„œ ì •ë§ ì‹¤ë§ìŠ¤ëŸ½ë‹¤\", \n",
    "        \"ìƒˆë¡œìš´ ì§ì¥ì´ í™•ì •ë˜ì–´ì„œ ì„¤ë ˆê³  ê¸°ëŒ€ëœë‹¤\",\n",
    "        \"ëˆ„êµ°ê°€ ë‚´ ë’·ë‹´í™”ë¥¼ í•˜ëŠ” ê±¸ ë“¤ì–´ì„œ í™”ê°€ ë‚œë‹¤\"\n",
    "    ]\n",
    "    \n",
    "    for i, text in enumerate(demo_texts, 1):\n",
    "        print(f\"\\nğŸ“ ì˜ˆì œ {i}: {text}\")\n",
    "        print(\"-\"*60)\n",
    "        \n",
    "        # íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ì˜ˆì¸¡\n",
    "        result = pipeline.predict_single(text)\n",
    "        \n",
    "        print(f\"ğŸ¯ ì˜ˆì¸¡ ê²°ê³¼:\")\n",
    "        print(f\"  Category1: {result['category1_predicted']} (ì‹ ë¢°ë„: {result['category1_confidence']:.3f})\")\n",
    "        print(f\"  Category2: {result['category2_predicted']} (ì‹ ë¢°ë„: {result['category2_confidence']:.3f})\")\n",
    "\n",
    "# ì‹œì—° ì‹¤í–‰\n",
    "demo_pipeline_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "i821u6i92xl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” PCA ì°¨ì› ì¶•ì†Œ íŒŒì´í”„ë¼ì¸ í‰ê°€\n",
      "================================================================================\n",
      "ì›ë³¸ ë²¡í„° ì°¨ì›: 1024\n",
      "í‰ê°€í•  PCA ì°¨ì›: [128, 256, 512, 768]\n",
      "í›ˆë ¨ ë°ì´í„°: 3359ê°œ, í…ŒìŠ¤íŠ¸ ë°ì´í„°: 664ê°œ\n",
      "\n",
      "\n",
      "==================== PCA 128ì°¨ì› í‰ê°€ ====================\n",
      "ğŸ“ PCA 128ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ ì¤‘...\n",
      "  í›ˆë ¨ ë°ì´í„°: (3359, 1024) â†’ (3359, 128)\n",
      "  í…ŒìŠ¤íŠ¸ ë°ì´í„°: (664, 1024) â†’ (664, 128)\n",
      "  ì„¤ëª… ê°€ëŠ¥í•œ ë¶„ì‚° ë¹„ìœ¨: 0.8185 (81.85%)\n",
      "ğŸ¤– Category1 ëª¨ë¸ í›ˆë ¨ ì¤‘...\n",
      "  Category1 ì •í™•ë„: 0.5015 (50.15%)\n",
      "ğŸ¤– Category2 ëª¨ë¸ í›ˆë ¨ ì¤‘...\n",
      "  Category2 ì •í™•ë„: 0.2485 (24.85%)\n",
      "  ğŸ¯ ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì •ë‹µ: 152/664 (0.2289, 22.89%)\n",
      "\n",
      "==================== PCA 256ì°¨ì› í‰ê°€ ====================\n",
      "ğŸ“ PCA 256ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ ì¤‘...\n",
      "  í›ˆë ¨ ë°ì´í„°: (3359, 1024) â†’ (3359, 256)\n",
      "  í…ŒìŠ¤íŠ¸ ë°ì´í„°: (664, 1024) â†’ (664, 256)\n",
      "  ì„¤ëª… ê°€ëŠ¥í•œ ë¶„ì‚° ë¹„ìœ¨: 0.9409 (94.09%)\n",
      "ğŸ¤– Category1 ëª¨ë¸ í›ˆë ¨ ì¤‘...\n",
      "  Category1 ì •í™•ë„: 0.4880 (48.80%)\n",
      "ğŸ¤– Category2 ëª¨ë¸ í›ˆë ¨ ì¤‘...\n",
      "  Category2 ì •í™•ë„: 0.2199 (21.99%)\n",
      "  ğŸ¯ ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì •ë‹µ: 133/664 (0.2003, 20.03%)\n",
      "\n",
      "==================== PCA 512ì°¨ì› í‰ê°€ ====================\n",
      "ğŸ“ PCA 512ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ ì¤‘...\n",
      "  í›ˆë ¨ ë°ì´í„°: (3359, 1024) â†’ (3359, 512)\n",
      "  í…ŒìŠ¤íŠ¸ ë°ì´í„°: (664, 1024) â†’ (664, 512)\n",
      "  ì„¤ëª… ê°€ëŠ¥í•œ ë¶„ì‚° ë¹„ìœ¨: 0.9961 (99.61%)\n",
      "ğŸ¤– Category1 ëª¨ë¸ í›ˆë ¨ ì¤‘...\n",
      "  Category1 ì •í™•ë„: 0.4880 (48.80%)\n",
      "ğŸ¤– Category2 ëª¨ë¸ í›ˆë ¨ ì¤‘...\n",
      "  Category2 ì •í™•ë„: 0.2139 (21.39%)\n",
      "  ğŸ¯ ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì •ë‹µ: 130/664 (0.1958, 19.58%)\n",
      "\n",
      "==================== PCA 768ì°¨ì› í‰ê°€ ====================\n",
      "ğŸ“ PCA 768ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ ì¤‘...\n",
      "  í›ˆë ¨ ë°ì´í„°: (3359, 1024) â†’ (3359, 768)\n",
      "  í…ŒìŠ¤íŠ¸ ë°ì´í„°: (664, 1024) â†’ (664, 768)\n",
      "  ì„¤ëª… ê°€ëŠ¥í•œ ë¶„ì‚° ë¹„ìœ¨: 0.9994 (99.94%)\n",
      "ğŸ¤– Category1 ëª¨ë¸ í›ˆë ¨ ì¤‘...\n",
      "  Category1 ì •í™•ë„: 0.4895 (48.95%)\n",
      "ğŸ¤– Category2 ëª¨ë¸ í›ˆë ¨ ì¤‘...\n",
      "  Category2 ì •í™•ë„: 0.2184 (21.84%)\n",
      "  ğŸ¯ ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì •ë‹µ: 134/664 (0.2018, 20.18%)\n",
      "\n",
      "========================= ê²°ê³¼ ë¹„êµ ë¶„ì„ =========================\n",
      "PCA ì°¨ì›     ë¶„ì‚°ë¹„ìœ¨         Cat1 ì •í™•ë„     Cat2 ì •í™•ë„     ì¢…í•© ì •í™•ë„      \n",
      "----------------------------------------------------------------------\n",
      "ì›ë³¸         100.00%      0.4880       0.2425       0.2244      \n",
      "128        81.85      % 0.5015       0.2485       0.2289      \n",
      "256        94.09      % 0.4880       0.2199       0.2003      \n",
      "512        99.61      % 0.4880       0.2139       0.1958      \n",
      "768        99.94      % 0.4895       0.2184       0.2018      \n",
      "\n",
      "ğŸ† ì„±ëŠ¥ ë¶„ì„:\n",
      "  ì›ë³¸ (1024ì°¨ì›) ì¢…í•© ì •í™•ë„: 0.2244 (22.44%)\n",
      "  ìµœê³  PCA (128ì°¨ì›) ì¢…í•© ì •í™•ë„: 0.2289 (22.89%)\n",
      "  âœ… PCA 128ì°¨ì›ì´ ì›ë³¸ë³´ë‹¤ 0.45%p ë” ì¢‹ìŠµë‹ˆë‹¤!\n",
      "\n",
      "ğŸ“Š ì°¨ì›ë³„ ì„±ëŠ¥ ë³€í™”:\n",
      "PCA ì°¨ì›  â†’ ì¢…í•© ì •í™•ë„\n",
      "-------------------------\n",
      "128ì°¨ì›   â†’ 0.229 |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘|\n",
      "256ì°¨ì›   â†’ 0.200 |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘|\n",
      "512ì°¨ì›   â†’ 0.196 |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘|\n",
      "768ì°¨ì›   â†’ 0.202 |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘|\n",
      "\n",
      "ğŸ” ìµœê³  ì„±ëŠ¥ PCA 128ì°¨ì› ìƒì„¸ ë¶„ì„:\n",
      "--------------------------------------------------------------------------------\n",
      "ì²˜ìŒ 20ê°œ ìƒ˜í”Œì—ì„œ ì›ë³¸ê³¼ PCA ì˜ˆì¸¡ ì¼ì¹˜ìœ¨: 17/20 (85.0%)\n",
      "\n",
      "ì›ë³¸ vs PCA ì˜ˆì¸¡ì´ ë‹¤ë¥¸ ìƒ˜í”Œë“¤ (ì²˜ìŒ 5ê°œ):\n",
      "1. ì›ë³¸: âŒ | PCA: âœ…\n",
      "   ì‹¤ì œ: Cat1=ê¸°ì¨, Cat2=ë§Œì¡±ê°\n",
      "   í…ìŠ¤íŠ¸: ì–´ë¦´ ë•Œ ê°€ ë³´ê³  ë¹•ìŠ¤ëŠ” ê±°ì˜ ì²˜ìŒì¸ë°(ê¸°ì–µì— ì—†ìŒ) ì§€ê¸ˆ ë”¸ê¸°ì¶•ì œ ê¸°ê°„ì´ë¼ ë§Œì¡±ìŠ¤ëŸ¬ìš´ ì‹ì‚¬ í•˜ê³  ì˜´\n",
      "2. ì›ë³¸: âŒ | PCA: âœ…\n",
      "   ì‹¤ì œ: Cat1=ì‹«ì–´í•¨(ìƒíƒœ), Cat2=ë‹µë‹µí•¨\n",
      "   í…ìŠ¤íŠ¸: ê°€ìŠ´ì´ ë‹µë‹µí•´ì§ ì§„ì§œ ê°œë‹µë‹µí•´ì§\n",
      "ìš°ë¦¬ì§„ì§œíˆ¬í‘œì˜í•˜ì\n",
      "3. ì›ë³¸: âœ… | PCA: âŒ\n",
      "   ì‹¤ì œ: Cat1=ê¸°ì¨, Cat2=ë§Œì¡±ê°\n",
      "   í…ìŠ¤íŠ¸: ìš°ì—°íˆ ë³´ê²Œ ëœ ì˜ìƒì¸ë°, ë…¸ë˜ê°€ ë„ˆë¬´ ì¢‹ì•„ì„œ í”Œë¦¬ì—ë„ ì¶”ê°€í•˜ê³ , ì¹´ì¹´ì˜¤í†¡ í”„ë®¤ë¡œë„ í•´ë†¨ìŒ. ìŒì›ë„ ì¢‹ê¸´ í•œ...\n",
      "\n",
      "ğŸ’¡ ê²°ë¡ : PCAë¥¼ í†µí•œ ì°¨ì› ì¶•ì†ŒëŠ” \n",
      "ì„±ëŠ¥ í–¥ìƒì— ë„ì›€ì´ ë©ë‹ˆë‹¤. ê³„ì‚° íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì„ ëª¨ë‘ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# 13. PCA ì°¨ì› ì¶•ì†Œ íŒŒì´í”„ë¼ì¸ - ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì •ë‹µ ì •í™•ë„ ë¹„êµ\n",
    "\n",
    "print(\"ğŸ” PCA ì°¨ì› ì¶•ì†Œ íŒŒì´í”„ë¼ì¸ í‰ê°€\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# PCA ì°¨ì› ë¦¬ìŠ¤íŠ¸ ì •ì˜\n",
    "pca_dimensions = [128, 256, 512, 768]\n",
    "\n",
    "# ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬\n",
    "pca_results = {}\n",
    "\n",
    "# ì›ë³¸ ë²¡í„° í¬ê¸° í™•ì¸\n",
    "original_dim = X.shape[1]\n",
    "print(f\"ì›ë³¸ ë²¡í„° ì°¨ì›: {original_dim}\")\n",
    "print(f\"í‰ê°€í•  PCA ì°¨ì›: {pca_dimensions}\")\n",
    "print(f\"í›ˆë ¨ ë°ì´í„°: {X.shape[0]}ê°œ, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(test_texts)}ê°œ\")\n",
    "print()\n",
    "\n",
    "# ê° PCA ì°¨ì›ì— ëŒ€í•´ í‰ê°€\n",
    "for n_components in pca_dimensions:\n",
    "    print(f\"\\n{'='*20} PCA {n_components}ì°¨ì› í‰ê°€ {'='*20}\")\n",
    "    \n",
    "    # 1. PCA ì ìš©\n",
    "    print(f\"ğŸ“ PCA {n_components}ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œ ì¤‘...\")\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    \n",
    "    # í›ˆë ¨ ë°ì´í„° PCA ë³€í™˜\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    print(f\"  í›ˆë ¨ ë°ì´í„°: {X.shape} â†’ {X_pca.shape}\")\n",
    "    \n",
    "    # í…ŒìŠ¤íŠ¸ ë°ì´í„° PCA ë³€í™˜\n",
    "    test_X_pca = pca.transform(test_X)\n",
    "    print(f\"  í…ŒìŠ¤íŠ¸ ë°ì´í„°: {test_X.shape} â†’ {test_X_pca.shape}\")\n",
    "    \n",
    "    # ì„¤ëª… ê°€ëŠ¥í•œ ë¶„ì‚° ë¹„ìœ¨\n",
    "    explained_variance = pca.explained_variance_ratio_.sum()\n",
    "    print(f\"  ì„¤ëª… ê°€ëŠ¥í•œ ë¶„ì‚° ë¹„ìœ¨: {explained_variance:.4f} ({explained_variance*100:.2f}%)\")\n",
    "    \n",
    "    # 2. Category1 ëª¨ë¸ í›ˆë ¨ (PCA ì ìš©)\n",
    "    print(f\"ğŸ¤– Category1 ëª¨ë¸ í›ˆë ¨ ì¤‘...\")\n",
    "    cat1_model_pca = xgb.XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cat1_model_pca.fit(X_pca, y_encoded)\n",
    "    \n",
    "    # Category1 ì˜ˆì¸¡\n",
    "    test_y_pred_cat1_pca_encoded = cat1_model_pca.predict(test_X_pca)\n",
    "    test_y_pred_cat1_pca = le.inverse_transform(test_y_pred_cat1_pca_encoded)\n",
    "    \n",
    "    # Category1 ì •í™•ë„\n",
    "    cat1_accuracy_pca = (test_y_pred_cat1_pca == test_y_actual).mean()\n",
    "    print(f\"  Category1 ì •í™•ë„: {cat1_accuracy_pca:.4f} ({cat1_accuracy_pca*100:.2f}%)\")\n",
    "    \n",
    "    # 3. Category2 ëª¨ë¸ í›ˆë ¨ (PCA ì ìš©)\n",
    "    print(f\"ğŸ¤– Category2 ëª¨ë¸ í›ˆë ¨ ì¤‘...\")\n",
    "    \n",
    "    # Category1 ì›í•« ì¸ì½”ë”© (PCA ì ìš©ëœ ì˜ˆì¸¡ê°’ ì‚¬ìš©)\n",
    "    cat1_onehot_pca = cat1_encoder.transform(test_y_pred_cat1_pca.reshape(-1, 1))\n",
    "    \n",
    "    # PCA ì ìš©ëœ ë²¡í„°ì™€ Category1 ì›í•« ê²°í•© (í›ˆë ¨ìš©)\n",
    "    y_cat1_onehot_pca = cat1_encoder.transform(y.reshape(-1, 1))\n",
    "    X_combined_pca = np.hstack([X_pca, y_cat1_onehot_pca])\n",
    "    \n",
    "    # PCA ì ìš©ëœ ë²¡í„°ì™€ Category1 ì˜ˆì¸¡ ì›í•« ê²°í•© (í…ŒìŠ¤íŠ¸ìš©)\n",
    "    test_X_combined_pca = np.hstack([test_X_pca, cat1_onehot_pca])\n",
    "    \n",
    "    cat2_model_pca = xgb.XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cat2_model_pca.fit(X_combined_pca, y_cat2_encoded)\n",
    "    \n",
    "    # Category2 ì˜ˆì¸¡\n",
    "    test_y_pred_cat2_pca_encoded = cat2_model_pca.predict(test_X_combined_pca)\n",
    "    test_y_pred_cat2_pca = le_cat2.inverse_transform(test_y_pred_cat2_pca_encoded)\n",
    "    \n",
    "    # Category2 ì •í™•ë„\n",
    "    cat2_accuracy_pca = (test_y_pred_cat2_pca == test_y_actual_cat2).mean()\n",
    "    print(f\"  Category2 ì •í™•ë„: {cat2_accuracy_pca:.4f} ({cat2_accuracy_pca*100:.2f}%)\")\n",
    "    \n",
    "    # 4. ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì •ë‹µì¸ ê²½ìš° ê³„ì‚°\n",
    "    both_correct_pca = (test_y_pred_cat1_pca == test_y_actual) & (test_y_pred_cat2_pca == test_y_actual_cat2)\n",
    "    both_accuracy_pca = both_correct_pca.mean()\n",
    "    both_count_pca = both_correct_pca.sum()\n",
    "    \n",
    "    print(f\"  ğŸ¯ ë‘ ì¹´í…Œê³ ë¦¬ ëª¨ë‘ ì •ë‹µ: {both_count_pca}/{len(test_y_actual)} ({both_accuracy_pca:.4f}, {both_accuracy_pca*100:.2f}%)\")\n",
    "    \n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    pca_results[n_components] = {\n",
    "        'explained_variance': explained_variance,\n",
    "        'cat1_accuracy': cat1_accuracy_pca,\n",
    "        'cat2_accuracy': cat2_accuracy_pca,\n",
    "        'both_accuracy': both_accuracy_pca,\n",
    "        'both_count': both_count_pca,\n",
    "        'cat1_predictions': test_y_pred_cat1_pca,\n",
    "        'cat2_predictions': test_y_pred_cat2_pca\n",
    "    }\n",
    "\n",
    "# 5. ì „ì²´ ê²°ê³¼ ë¹„êµ ë¶„ì„\n",
    "print(f\"\\n{'='*25} ê²°ê³¼ ë¹„êµ ë¶„ì„ {'='*25}\")\n",
    "print(f\"{'PCA ì°¨ì›':<10} {'ë¶„ì‚°ë¹„ìœ¨':<12} {'Cat1 ì •í™•ë„':<12} {'Cat2 ì •í™•ë„':<12} {'ì¢…í•© ì •í™•ë„':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# ì›ë³¸ ê²°ê³¼ (PCA ì—†ìŒ) ê³„ì‚°\n",
    "original_both_correct = (test_y_pred == test_y_actual) & (test_y_pred_cat2 == test_y_actual_cat2)\n",
    "original_both_accuracy = original_both_correct.mean()\n",
    "\n",
    "print(f\"{'ì›ë³¸':<10} {'100.00%':<12} {accuracy:<12.4f} {accuracy_cat2:<12.4f} {original_both_accuracy:<12.4f}\")\n",
    "\n",
    "# PCA ê²°ê³¼ë“¤\n",
    "for dim in pca_dimensions:\n",
    "    result = pca_results[dim]\n",
    "    print(f\"{dim:<10} {result['explained_variance']*100:<11.2f}% {result['cat1_accuracy']:<12.4f} {result['cat2_accuracy']:<12.4f} {result['both_accuracy']:<12.4f}\")\n",
    "\n",
    "# 6. ìµœê³  ì„±ëŠ¥ ì°¨ì› ì°¾ê¸°\n",
    "print(f\"\\nğŸ† ì„±ëŠ¥ ë¶„ì„:\")\n",
    "best_both_accuracy = max(result['both_accuracy'] for result in pca_results.values())\n",
    "best_pca_dim = max(pca_results.keys(), key=lambda k: pca_results[k]['both_accuracy'])\n",
    "\n",
    "print(f\"  ì›ë³¸ (1024ì°¨ì›) ì¢…í•© ì •í™•ë„: {original_both_accuracy:.4f} ({original_both_accuracy*100:.2f}%)\")\n",
    "print(f\"  ìµœê³  PCA ({best_pca_dim}ì°¨ì›) ì¢…í•© ì •í™•ë„: {best_both_accuracy:.4f} ({best_both_accuracy*100:.2f}%)\")\n",
    "\n",
    "if best_both_accuracy > original_both_accuracy:\n",
    "    improvement = (best_both_accuracy - original_both_accuracy) * 100\n",
    "    print(f\"  âœ… PCA {best_pca_dim}ì°¨ì›ì´ ì›ë³¸ë³´ë‹¤ {improvement:.2f}%p ë” ì¢‹ìŠµë‹ˆë‹¤!\")\n",
    "else:\n",
    "    decline = (original_both_accuracy - best_both_accuracy) * 100\n",
    "    print(f\"  âš ï¸ ì›ë³¸ì´ ìµœê³  PCAë³´ë‹¤ {decline:.2f}%p ë” ì¢‹ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# 7. ì°¨ì›ë³„ ì„±ëŠ¥ ë³€í™” ì‹œê°í™” (í…ìŠ¤íŠ¸)\n",
    "print(f\"\\nğŸ“Š ì°¨ì›ë³„ ì„±ëŠ¥ ë³€í™”:\")\n",
    "print(f\"PCA ì°¨ì›  â†’ ì¢…í•© ì •í™•ë„\")\n",
    "print(\"-\" * 25)\n",
    "for dim in sorted(pca_dimensions):\n",
    "    result = pca_results[dim]\n",
    "    bar_length = int(result['both_accuracy'] * 50)  # 50ì¹¸ ê¸°ì¤€\n",
    "    bar = \"â–ˆ\" * bar_length + \"â–‘\" * (50 - bar_length)\n",
    "    print(f\"{dim:>3}ì°¨ì›   â†’ {result['both_accuracy']:.3f} |{bar}|\")\n",
    "\n",
    "# 8. ìƒì„¸ ìƒ˜í”Œ ë¶„ì„ (ìµœê³  ì„±ëŠ¥ PCA ì°¨ì›)\n",
    "print(f\"\\nğŸ” ìµœê³  ì„±ëŠ¥ PCA {best_pca_dim}ì°¨ì› ìƒì„¸ ë¶„ì„:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "best_cat1_preds = pca_results[best_pca_dim]['cat1_predictions']\n",
    "best_cat2_preds = pca_results[best_pca_dim]['cat2_predictions']\n",
    "\n",
    "# ì›ë³¸ vs PCA ì˜ˆì¸¡ ë¹„êµ\n",
    "agreement_count = 0\n",
    "disagreement_examples = []\n",
    "\n",
    "for i in range(min(len(test_y_actual), 20)):  # ì²˜ìŒ 20ê°œ ìƒ˜í”Œë§Œ\n",
    "    original_both = (test_y_pred[i] == test_y_actual[i]) and (test_y_pred_cat2[i] == test_y_actual_cat2[i])\n",
    "    pca_both = (best_cat1_preds[i] == test_y_actual[i]) and (best_cat2_preds[i] == test_y_actual_cat2[i])\n",
    "    \n",
    "    if original_both == pca_both:\n",
    "        agreement_count += 1\n",
    "    else:\n",
    "        disagreement_examples.append({\n",
    "            'index': i,\n",
    "            'text': test_texts[i][:60] + \"...\" if len(test_texts[i]) > 60 else test_texts[i],\n",
    "            'actual_cat1': test_y_actual[i],\n",
    "            'actual_cat2': test_y_actual_cat2[i],\n",
    "            'original_both': original_both,\n",
    "            'pca_both': pca_both\n",
    "        })\n",
    "\n",
    "print(f\"ì²˜ìŒ 20ê°œ ìƒ˜í”Œì—ì„œ ì›ë³¸ê³¼ PCA ì˜ˆì¸¡ ì¼ì¹˜ìœ¨: {agreement_count}/20 ({agreement_count/20*100:.1f}%)\")\n",
    "\n",
    "if disagreement_examples:\n",
    "    print(f\"\\nì›ë³¸ vs PCA ì˜ˆì¸¡ì´ ë‹¤ë¥¸ ìƒ˜í”Œë“¤ (ì²˜ìŒ 5ê°œ):\")\n",
    "    for i, example in enumerate(disagreement_examples[:5]):\n",
    "        status_original = \"âœ…\" if example['original_both'] else \"âŒ\"\n",
    "        status_pca = \"âœ…\" if example['pca_both'] else \"âŒ\"\n",
    "        print(f\"{i+1}. ì›ë³¸: {status_original} | PCA: {status_pca}\")\n",
    "        print(f\"   ì‹¤ì œ: Cat1={example['actual_cat1']}, Cat2={example['actual_cat2']}\")\n",
    "        print(f\"   í…ìŠ¤íŠ¸: {example['text']}\")\n",
    "\n",
    "print(f\"\\nğŸ’¡ ê²°ë¡ : PCAë¥¼ í†µí•œ ì°¨ì› ì¶•ì†ŒëŠ” \")\n",
    "if best_both_accuracy > original_both_accuracy:\n",
    "    print(\"ì„±ëŠ¥ í–¥ìƒì— ë„ì›€ì´ ë©ë‹ˆë‹¤. ê³„ì‚° íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì„ ëª¨ë‘ ê°œì„ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"ì„±ëŠ¥ì„ ì•½ê°„ ì €í•˜ì‹œí‚¤ì§€ë§Œ, ê³„ì‚° íš¨ìœ¨ì„±ì€ í¬ê²Œ ê°œì„ ë©ë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49681c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3861528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skn_after_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
