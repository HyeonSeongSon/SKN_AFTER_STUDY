{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13495b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f72f27ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 필터링 전: 3360개\n",
      "re_category1에서 중립: 3개\n",
      "re_category2에서 중립: 1개\n",
      "데이터 필터링 후: 3359개\n",
      "제거된 데이터: 1개\n",
      "남은 re_category1 클래스 (10개): ['기쁨', '두려움', '미움(상대방)', '분노', '사랑', '수치심', '슬픔', '싫어함(상태)', '욕망', '중립']\n",
      "남은 re_category2 클래스 (64개): ['갈등', '감동', '걱정', '경멸', '고마움', '고통', '공감', '공포', '궁금함', '귀중함', '그리움', '기대감', '난처함', '날카로움', '냉담', '너그러움', '놀람', '다정함', '답답함', '동정(슬픔)', '두근거림', '만족감', '매력적', '무기력', '미안함', '반가움', '반감', '발열', '부끄러움', '불만', '불신감', '불쾌', '불편함', '비위상함', '사나움', '수치심', '시기심', '신뢰감', '신명남', '실망', '싫증', '심심함', '아쉬움', '아픔', '안정감', '억울함', '외로움', '외면', '욕심', '원망', '위축감', '자랑스러움', '자신감', '절망', '죄책감', '즐거움', '초조함', '치사함', '타오름', '통쾌함', '편안함', '허망', '호감', '후회']\n",
      "필터링 후 re_category1 중립: 2개\n",
      "필터링 후 re_category2 중립: 0개\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>generator_context</th>\n",
       "      <th>category1</th>\n",
       "      <th>category2</th>\n",
       "      <th>input_context</th>\n",
       "      <th>original_index</th>\n",
       "      <th>augmentation_index</th>\n",
       "      <th>re_category1</th>\n",
       "      <th>re_category2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>갑자기 내 책상 위에 놓인 따뜻한 손편지에 마음이 뭉클해졌다.</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "      <td>설탕 스틱 껴준거 센스 백점 만점에 천점</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>비가 오는데도 친구가 내 좋아하는 카페까지 우산 들고 따라와줘서 마음이 따뜻해졌어.</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "      <td>아쓰 산차이 기분 안 좋은 거 알아채고 산차이가 가고 싶다던 토끼집 데려온 거 감동</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>햇살 아래 반짝이는 아이의 눈동자가 마치 작은 보석처럼 빛났다. 그 순간, 세상 모...</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "      <td>신데렐라 드레스는 다시 봐도 너무 아름다워. 사람에게 꿈의 물결을 입히다니요.</td>\n",
       "      <td>104.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>이번 전시회 준비하면서 철저하게 세부까지 챙겨준 덕분에 모든 게 완벽하게 마무리돼서...</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "      <td>와 민희진 씨 애들 숙소 스타일링까지 맡기면서 신경써 준 거 진짜 좀 대단하네</td>\n",
       "      <td>107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>비 오는 날 낯선 사람이 내게 담요를 건네며 추위 걱정해 줬다. 마음이 따뜻해져서 ...</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "      <td>개감동인 거 자기가 쓰고 있던 우산 나 주고\\n자기가 비 맞아가면서 뒤집어준 거야\\...</td>\n",
       "      <td>137.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>기쁨</td>\n",
       "      <td>감동</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                  generator_context category1  \\\n",
       "0           0                 갑자기 내 책상 위에 놓인 따뜻한 손편지에 마음이 뭉클해졌다.        기쁨   \n",
       "1           1     비가 오는데도 친구가 내 좋아하는 카페까지 우산 들고 따라와줘서 마음이 따뜻해졌어.        기쁨   \n",
       "2           2  햇살 아래 반짝이는 아이의 눈동자가 마치 작은 보석처럼 빛났다. 그 순간, 세상 모...        기쁨   \n",
       "3           3  이번 전시회 준비하면서 철저하게 세부까지 챙겨준 덕분에 모든 게 완벽하게 마무리돼서...        기쁨   \n",
       "4           4  비 오는 날 낯선 사람이 내게 담요를 건네며 추위 걱정해 줬다. 마음이 따뜻해져서 ...        기쁨   \n",
       "\n",
       "  category2                                      input_context  \\\n",
       "0        감동                             설탕 스틱 껴준거 센스 백점 만점에 천점   \n",
       "1        감동     아쓰 산차이 기분 안 좋은 거 알아채고 산차이가 가고 싶다던 토끼집 데려온 거 감동   \n",
       "2        감동        신데렐라 드레스는 다시 봐도 너무 아름다워. 사람에게 꿈의 물결을 입히다니요.   \n",
       "3        감동        와 민희진 씨 애들 숙소 스타일링까지 맡기면서 신경써 준 거 진짜 좀 대단하네   \n",
       "4        감동  개감동인 거 자기가 쓰고 있던 우산 나 주고\\n자기가 비 맞아가면서 뒤집어준 거야\\...   \n",
       "\n",
       "   original_index  augmentation_index re_category1 re_category2  \n",
       "0            20.0                 NaN           기쁨           감동  \n",
       "1            79.0                 NaN           기쁨           감동  \n",
       "2           104.0                 NaN           기쁨           감동  \n",
       "3           107.0                 NaN           기쁨           감동  \n",
       "4           137.0                 NaN           기쁨           감동  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel(r'C:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\data\\retest_augmentation.xlsx')\n",
    "\n",
    "# re_category2에서만 중립 데이터 제거 (re_category1은 중립 유지)\n",
    "print(f\"데이터 필터링 전: {len(data)}개\")\n",
    "print(f\"re_category1에서 중립: {(data['re_category1'] == '중립').sum()}개\")\n",
    "print(f\"re_category2에서 중립: {(data['re_category2'] == '중립').sum()}개\")\n",
    "\n",
    "# re_category2에서만 중립 데이터 제거 (Category2에 중립이 없으므로 라벨 불일치 방지)\n",
    "original_count = len(data)\n",
    "data = data[data['re_category2'] != '중립'].copy()\n",
    "\n",
    "# 인덱스 재설정\n",
    "data = data.reset_index(drop=True)\n",
    "\n",
    "print(f\"데이터 필터링 후: {len(data)}개\")\n",
    "print(f\"제거된 데이터: {original_count - len(data)}개\")\n",
    "\n",
    "# 필터링된 데이터 확인\n",
    "print(f\"남은 re_category1 클래스 ({len(data['re_category1'].unique())}개): {sorted(data['re_category1'].unique())}\")\n",
    "print(f\"남은 re_category2 클래스 ({len(data['re_category2'].unique())}개): {sorted(data['re_category2'].unique())}\")\n",
    "\n",
    "# 중립 확인\n",
    "print(f\"필터링 후 re_category1 중립: {(data['re_category1'] == '중립').sum()}개\")\n",
    "print(f\"필터링 후 re_category2 중립: {(data['re_category2'] == '중립').sum()}개\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dbf27be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def embeddings_model():\n",
    "  \"\"\"\n",
    "  임베딩 모델 초기화\n",
    "  \"\"\"\n",
    "  model = SentenceTransformer(\"dragonkue/snowflake-arctic-embed-l-v2.0-ko\") \n",
    "  vec_dim = len(model.encode(\"dummy_text\"))\n",
    "  print(f\"모델 차원: {vec_dim}\")\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c873e343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 차원: 1024\n"
     ]
    }
   ],
   "source": [
    "embeddings_model = embeddings_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4926f06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 기존 변수들이 초기화되었습니다.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3359 entries, 0 to 3358\n",
      "Data columns (total 9 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Unnamed: 0          3359 non-null   int64  \n",
      " 1   generator_context   3359 non-null   object \n",
      " 2   category1           3359 non-null   object \n",
      " 3   category2           3359 non-null   object \n",
      " 4   input_context       3359 non-null   object \n",
      " 5   original_index      664 non-null    float64\n",
      " 6   augmentation_index  2695 non-null   float64\n",
      " 7   re_category1        3359 non-null   object \n",
      " 8   re_category2        3359 non-null   object \n",
      "dtypes: float64(2), int64(1), object(6)\n",
      "memory usage: 236.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# 기존 변수 초기화 (중립 데이터 제거로 인한 크기 불일치 방지)\n",
    "vars_to_reset = ['X', 'y', 'y_encoded', 'X_combined', 'y_cat2', 'y_cat2_encoded', 'le', 'le_cat2', 'cat1_encoder']\n",
    "for var_name in vars_to_reset:\n",
    "    if var_name in locals():\n",
    "        del locals()[var_name]\n",
    "        print(f\"변수 {var_name} 초기화됨\")\n",
    "\n",
    "print(\"✅ 기존 변수들이 초기화되었습니다.\")\n",
    "\n",
    "# 데이터 정보 확인\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd04d86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 필터링된 데이터로 벡터 생성...\n",
      "✅ 벡터 생성 완료: 3359개\n"
     ]
    }
   ],
   "source": [
    "# 중립 데이터 제거 후 벡터 생성\n",
    "print(\"📝 필터링된 데이터로 벡터 생성...\")\n",
    "data['vector'] = data['generator_context'].apply(lambda x: embeddings_model.encode(x).tolist())\n",
    "print(f\"✅ 벡터 생성 완료: {len(data)}개\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3b7dde",
   "metadata": {},
   "source": [
    "### category1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c27bb42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 상태 확인:\n",
      "필터링된 데이터 개수: 3359\n",
      "벡터 타입: <class 'list'>\n",
      "벡터 길이: 1024\n",
      "벡터가 리스트 형태입니다. 직접 변환합니다...\n",
      "X shape: (3359, 1024)\n",
      "y shape: (3359,)\n",
      "✅ X와 y의 크기가 일치합니다!\n",
      "✅ 성공적으로 변환되었습니다!\n"
     ]
    }
   ],
   "source": [
    "# 필터링된 데이터로 벡터와 라벨 생성\n",
    "print(\"데이터 상태 확인:\")\n",
    "print(f\"필터링된 데이터 개수: {len(data)}\")\n",
    "print(f\"벡터 타입: {type(data['vector'].iloc[0])}\")\n",
    "print(f\"벡터 길이: {len(data['vector'].iloc[0])}\")\n",
    "\n",
    "# 벡터가 이미 리스트 형태라면 직접 numpy array로 변환\n",
    "if isinstance(data['vector'].iloc[0], list):\n",
    "    print(\"벡터가 리스트 형태입니다. 직접 변환합니다...\")\n",
    "    X = np.vstack(data['vector'].values)\n",
    "    y = data['re_category1'].values  # 변경: category1 → re_category1\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    \n",
    "    # 크기 일치 확인\n",
    "    if X.shape[0] == y.shape[0]:\n",
    "        print(\"✅ X와 y의 크기가 일치합니다!\")\n",
    "    else:\n",
    "        print(f\"❌ 크기 불일치: X {X.shape[0]} vs y {y.shape[0]}\")\n",
    "    \n",
    "    print(\"✅ 성공적으로 변환되었습니다!\")\n",
    "else:\n",
    "    print(\"벡터 형태에 문제가 있습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "wqea3alqoni",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 실제 test_data 로드 및 평가\n",
      "\n",
      "테스트 데이터 기본 정보:\n",
      "데이터 크기: (664, 5)\n",
      "컬럼들: ['index', 'context', 'annotations_split', 'category1', 'category2']\n",
      "\n",
      "데이터 샘플:\n",
      "   index                                            context  \\\n",
      "0      0  보는동안 너무 행복했고 초콜렛이 너무 먹고싶었고 티모시가 잘생겼고 울어!!하는부분이...   \n",
      "1      1  어릴 때 가 보고 빕스는 거의 처음인데(기억에 없음) 지금 딸기축제 기간이라 만족스...   \n",
      "2      2  미리 계좌로 환전해둔 돈을 해외에서 환전수수료 없이 인출 가능한 트레블로그라는 카드...   \n",
      "3      3  요즘 번아웃도 자꾸 올라오고 무기력해서 종강하고 교류하기도 버거운 상태가 와부렀으요ㅠㅠ    \n",
      "4      4  크라임씬 장똥민이 범행 도구 찾으려고 화장실 탱크 뒤지는데 거기에 진짜 똥 넣어놓은...   \n",
      "\n",
      "                                   annotations_split category1 category2  \n",
      "0  [['기쁨', '만족감'], ['기쁨', '만족감'], ['기쁨', '감동'], [...        기쁨       만족감  \n",
      "1  [['기쁨', '만족감'], ['기쁨', '만족감'], ['기쁨', '만족감'], ...        기쁨       만족감  \n",
      "2  [['기쁨', '만족감'], ['기쁨', '만족감'], ['기쁨', '만족감'], ...        기쁨       만족감  \n",
      "3  [['슬픔', '무기력'], ['싫어함(상태)', '무기력'], ['슬픔', '무기...        슬픔       무기력  \n",
      "4  [['기쁨', '즐거움'], ['기쁨', '통쾌함'], ['기쁨', '통쾌함'], ...        기쁨       즐거움  \n",
      "\n",
      "test_data 컬럼 확인:\n",
      "- index: int64\n",
      "- context: object\n",
      "- annotations_split: object\n",
      "- category1: object\n",
      "- category2: object\n",
      "\n",
      "식별된 컬럼:\n",
      "텍스트 컬럼: context\n",
      "Category1 컬럼: category1\n",
      "\n",
      "✅ 필요한 컬럼들을 찾았습니다!\n",
      "테스트 데이터 개수: 664\n",
      "Category1 클래스들: ['기쁨' '슬픔' '싫어함(상태)' '미움(상대방)' '두려움' '수치심' '욕망' '분노' '사랑' '중립']\n"
     ]
    }
   ],
   "source": [
    "# 9. 실제 test_data로 모델 성능 평가\n",
    "\n",
    "print(\"📁 실제 test_data 로드 및 평가\\n\")\n",
    "\n",
    "# test_data 로드\n",
    "test_data = pd.read_excel(r'C:\\Users\\user\\Desktop\\SKN_AFTER_STUDY\\data\\증강할데이터33.xlsx')\n",
    "print(\"테스트 데이터 기본 정보:\")\n",
    "print(f\"데이터 크기: {test_data.shape}\")\n",
    "print(f\"컬럼들: {list(test_data.columns)}\")\n",
    "print(\"\\n데이터 샘플:\")\n",
    "print(test_data.head())\n",
    "\n",
    "# test_data에서 텍스트와 category1 컬럼 확인\n",
    "print(f\"\\ntest_data 컬럼 확인:\")\n",
    "for col in test_data.columns:\n",
    "    print(f\"- {col}: {test_data[col].dtype}\")\n",
    "\n",
    "# 텍스트 컬럼과 category1 컬럼 식별 (컬럼명에 따라 조정 필요)\n",
    "text_column = None\n",
    "category1_column = None\n",
    "\n",
    "# 가능한 텍스트 컬럼명들\n",
    "possible_text_columns = ['context', 'text', 'content', 'sentence', '내용', '문장']\n",
    "for col in test_data.columns:\n",
    "    if any(keyword in col.lower() for keyword in possible_text_columns):\n",
    "        text_column = col\n",
    "        break\n",
    "\n",
    "# 가능한 category1 컬럼명들\n",
    "possible_cat1_columns = ['category1', 'cat1', 'label', '감정', '카테고리1']\n",
    "for col in test_data.columns:\n",
    "    if any(keyword in col.lower() for keyword in possible_cat1_columns):\n",
    "        category1_column = col\n",
    "        break\n",
    "\n",
    "print(f\"\\n식별된 컬럼:\")\n",
    "print(f\"텍스트 컬럼: {text_column}\")\n",
    "print(f\"Category1 컬럼: {category1_column}\")\n",
    "\n",
    "if text_column and category1_column:\n",
    "    print(f\"\\n✅ 필요한 컬럼들을 찾았습니다!\")\n",
    "    print(f\"테스트 데이터 개수: {len(test_data)}\")\n",
    "    print(f\"Category1 클래스들: {test_data[category1_column].unique()}\")\n",
    "else:\n",
    "    print(f\"\\n❌ 필요한 컬럼을 찾을 수 없습니다. 수동으로 지정해주세요.\")\n",
    "    print(\"사용 가능한 컬럼들:\")\n",
    "    for i, col in enumerate(test_data.columns):\n",
    "        print(f\"{i}: {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fed4954f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 Category1 모델의 test_data 성능 평가\n",
      "\n",
      "y_encoded 변수를 재정의합니다...\n",
      "y_encoded shape: (3359,)\n",
      "📝 test_data 텍스트 임베딩 중...\n",
      "✅ 임베딩 완료: (664, 1024)\n",
      "실제 라벨: 664\n",
      "테스트 데이터 중립 개수: 5개\n",
      "테스트 데이터 category1 클래스 (10개): ['기쁨', '두려움', '미움(상대방)', '분노', '사랑', '수치심', '슬픔', '싫어함(상태)', '욕망', '중립']\n",
      "\n",
      "🔄 전체 학습 데이터로 최종 모델 학습...\n",
      "✅ 최종 모델 학습 완료!\n",
      "\n",
      "🎯 test_data 예측 수행...\n",
      "\n",
      "📋 클래스 정보:\n",
      "학습 클래스 수: 10\n",
      "학습 클래스: ['기쁨', '두려움', '미움(상대방)', '분노', '사랑', '수치심', '슬픔', '싫어함(상태)', '욕망', '중립']\n",
      "테스트 실제 클래스 수: 10\n",
      "테스트 실제 클래스: ['기쁨', '두려움', '미움(상대방)', '분노', '사랑', '수치심', '슬픔', '싫어함(상태)', '욕망', '중립']\n",
      "공통 클래스 수: 10\n",
      "✅ 훈련 데이터와 테스트 데이터의 Category1 클래스가 완벽히 일치합니다!\n",
      "\n",
      "📊 Classification Report:\n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          기쁨       0.65      0.78      0.71       188\n",
      "         두려움       0.92      0.15      0.26        72\n",
      "     미움(상대방)       0.37      0.70      0.48        43\n",
      "          분노       0.25      0.33      0.29        36\n",
      "          사랑       0.43      0.06      0.11        47\n",
      "         수치심       0.33      0.08      0.13        25\n",
      "          슬픔       0.52      0.65      0.58       117\n",
      "     싫어함(상태)       0.26      0.10      0.15        49\n",
      "          욕망       0.33      0.48      0.39        82\n",
      "          중립       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.49       664\n",
      "   macro avg       0.41      0.33      0.31       664\n",
      "weighted avg       0.51      0.49      0.45       664\n",
      "\n",
      "\n",
      "🎯 전체 정확도: 0.4880 (48.80%)\n",
      "평가 데이터: 664개 모두 평가\n",
      "\n",
      "🔍 예측 샘플 (처음 10개):\n",
      "------------------------------------------------------------------------------------------\n",
      " 1. ✅ 실제: 기쁨           예측: 기쁨          \n",
      "    텍스트: 보는동안 너무 행복했고 초콜렛이 너무 먹고싶었고 티모시가 잘생겼고 울어!!하는부분이 있어서 울었다네요\n",
      "\n",
      " 2. ✅ 실제: 기쁨           예측: 기쁨          \n",
      "    텍스트: 어릴 때 가 보고 빕스는 거의 처음인데(기억에 없음) 지금 딸기축제 기간이라 만족스러운 식사 하고 옴\n",
      "\n",
      " 3. ✅ 실제: 기쁨           예측: 기쁨          \n",
      "    텍스트: 미리 계좌로 환전해둔 돈을 해외에서 환전수수료 없이 인출 가능한 트레블로그라는 카드인데, 선택할 수 있는 디...\n",
      "\n",
      " 4. ❌ 실제: 슬픔           예측: 싫어함(상태)     \n",
      "    텍스트: 요즘 번아웃도 자꾸 올라오고 무기력해서 종강하고 교류하기도 버거운 상태가 와부렀으요ㅠㅠ \n",
      "\n",
      " 5. ❌ 실제: 기쁨           예측: 미움(상대방)     \n",
      "    텍스트: 크라임씬 장똥민이 범행 도구 찾으려고 화장실 탱크 뒤지는데 거기에 진짜 똥 넣어놓은 거 진짜 웃겨 뒤지겠음ㅋ...\n",
      "\n",
      " 6. ❌ 실제: 싫어함(상태)      예측: 슬픔          \n",
      "    텍스트: 가슴이 답답해짐 진짜 개답답해짐\n",
      "우리진짜투표잘하자\n",
      "\n",
      " 7. ❌ 실제: 기쁨           예측: 욕망          \n",
      "    텍스트: 지그재그랑 에이블리랑 할인 대결하나\n",
      "아 흐뭇해\n",
      "계속되길...\n",
      "영원히....\n",
      "\n",
      " 8. ❌ 실제: 기쁨           예측: 욕망          \n",
      "    텍스트: 첨으로 수제 초콜릿 만듬\n",
      "초콜릿을 5시간이나 만드는 사람이 있다??? 그게 바로 나\n",
      "\n",
      " 9. ❌ 실제: 슬픔           예측: 기쁨          \n",
      "    텍스트: 단톡방에 공지들 슬슬 올라오는거 보니까 곧 개강이라는게 실감나서 갑자기 재기하고싶고 인생이 다 끝난거처럼 암...\n",
      "\n",
      "10. ✅ 실제: 기쁨           예측: 기쁨          \n",
      "    텍스트: 장흥신 공손한 손가락질 개웃겨요\n",
      "애드립 미친것 같음\n",
      "\n",
      "\n",
      "📈 클래스별 성능 요약:\n",
      "------------------------------------------------------------\n",
      "클래스             전체       정답       정확도       \n",
      "--------------------------------------------------\n",
      "기쁨              188      146      0.7766\n",
      "두려움             72       11       0.1528\n",
      "미움(상대방)         43       30       0.6977\n",
      "분노              36       12       0.3333\n",
      "사랑              47       3        0.0638\n",
      "수치심             25       2        0.0800\n",
      "슬픔              117      76       0.6496\n",
      "싫어함(상태)         49       5        0.1020\n",
      "욕망              82       39       0.4756\n",
      "중립              5        0        0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# K-Fold로 평가한 Category1 모델로 test_data 예측 및 classification_report\n",
    "\n",
    "print(\"🎯 Category1 모델의 test_data 성능 평가\\n\")\n",
    "\n",
    "# 1. 학습 데이터 X, y 변수 정의 (필요시)\n",
    "if 'X' not in locals():\n",
    "    print(\"X 변수를 재정의합니다...\")\n",
    "    X = np.vstack(data['vector'].values)\n",
    "    y = data['re_category1'].values  # 변경: category1 → re_category1 (중립 포함)\n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    print(f\"훈련 데이터 re_category1 클래스 ({len(np.unique(y))}개): {sorted(np.unique(y))}\")\n",
    "\n",
    "# 2. y_encoded 정의 (필요시)\n",
    "if 'y_encoded' not in locals():\n",
    "    print(\"y_encoded 변수를 재정의합니다...\")\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    print(f\"y_encoded shape: {y_encoded.shape}\")\n",
    "\n",
    "# 3. test_data의 텍스트를 벡터로 변환\n",
    "print(\"📝 test_data 텍스트 임베딩 중...\")\n",
    "test_texts = test_data['context'].fillna('').astype(str).tolist()\n",
    "test_vectors = []\n",
    "\n",
    "for text in test_texts:\n",
    "    vector = embeddings_model.encode(text)\n",
    "    test_vectors.append(vector)\n",
    "\n",
    "test_X = np.vstack(test_vectors)\n",
    "test_y_actual = test_data['category1'].values\n",
    "\n",
    "print(f\"✅ 임베딩 완료: {test_X.shape}\")\n",
    "print(f\"실제 라벨: {len(test_y_actual)}\")\n",
    "\n",
    "# 테스트 데이터에서 중립 확인\n",
    "test_neutral_count = (test_y_actual == '중립').sum()\n",
    "print(f\"테스트 데이터 중립 개수: {test_neutral_count}개\")\n",
    "print(f\"테스트 데이터 category1 클래스 ({len(np.unique(test_y_actual))}개): {sorted(np.unique(test_y_actual))}\")\n",
    "\n",
    "# 4. 전체 학습 데이터로 최종 모델 학습\n",
    "print(\"\\n🔄 전체 학습 데이터로 최종 모델 학습...\")\n",
    "final_cat1_model = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 전체 학습 데이터로 모델 학습\n",
    "final_cat1_model.fit(X, y_encoded)\n",
    "print(\"✅ 최종 모델 학습 완료!\")\n",
    "\n",
    "# 5. test_data로 예측 수행\n",
    "print(\"\\n🎯 test_data 예측 수행...\")\n",
    "test_y_pred_encoded = final_cat1_model.predict(test_X)\n",
    "test_y_pred = le.inverse_transform(test_y_pred_encoded)\n",
    "\n",
    "# 6. 학습 클래스와 테스트 클래스 비교\n",
    "train_classes = set(le.classes_)\n",
    "test_actual_classes = set(test_y_actual)\n",
    "test_pred_classes = set(test_y_pred)\n",
    "\n",
    "print(f\"\\n📋 클래스 정보:\")\n",
    "print(f\"학습 클래스 수: {len(train_classes)}\")\n",
    "print(f\"학습 클래스: {sorted(train_classes)}\")\n",
    "print(f\"테스트 실제 클래스 수: {len(test_actual_classes)}\")  \n",
    "print(f\"테스트 실제 클래스: {sorted(test_actual_classes)}\")\n",
    "\n",
    "# 학습에 없는 클래스 확인\n",
    "unseen_classes = test_actual_classes - train_classes\n",
    "if unseen_classes:\n",
    "    print(f\"⚠️ 학습에 없던 클래스들: {unseen_classes}\")\n",
    "    \n",
    "common_classes = train_classes & test_actual_classes\n",
    "print(f\"공통 클래스 수: {len(common_classes)}\")\n",
    "\n",
    "# 클래스 매치 확인\n",
    "if len(train_classes) == len(test_actual_classes) == len(common_classes):\n",
    "    print(\"✅ 훈련 데이터와 테스트 데이터의 Category1 클래스가 완벽히 일치합니다!\")\n",
    "    perfect_match = True\n",
    "else:\n",
    "    print(\"❌ 클래스 불일치가 있습니다.\")\n",
    "    perfect_match = False\n",
    "\n",
    "# 7. classification_report 생성\n",
    "print(f\"\\n📊 Classification Report:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if perfect_match:\n",
    "    # 모든 클래스가 공통인 경우 - 전체 평가 가능\n",
    "    test_y_actual_encoded = le.transform(test_y_actual)\n",
    "    report = classification_report(\n",
    "        test_y_actual_encoded, \n",
    "        test_y_pred_encoded, \n",
    "        target_names=le.classes_\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    # 전체 정확도\n",
    "    accuracy = (test_y_pred == test_y_actual).mean()\n",
    "    print(f\"\\n🎯 전체 정확도: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"평가 데이터: {len(test_y_actual)}개 모두 평가\")\n",
    "    \n",
    "else:\n",
    "    # 공통 클래스만 필터링해서 평가\n",
    "    mask = np.array([actual in common_classes for actual in test_y_actual])\n",
    "    filtered_actual = test_y_actual[mask]\n",
    "    filtered_pred = test_y_pred[mask]\n",
    "    \n",
    "    print(f\"공통 클래스 평가: {len(filtered_actual)}/{len(test_y_actual)}개\")\n",
    "    \n",
    "    filtered_actual_encoded = le.transform(filtered_actual)\n",
    "    filtered_pred_encoded = le.transform(filtered_pred)\n",
    "    \n",
    "    # 공통 클래스에 대한 라벨과 인덱스 매핑\n",
    "    common_class_labels = [cls for cls in le.classes_ if cls in common_classes]\n",
    "    common_class_indices = [le.transform([cls])[0] for cls in common_class_labels]\n",
    "    \n",
    "    report = classification_report(\n",
    "        filtered_actual_encoded,\n",
    "        filtered_pred_encoded,\n",
    "        target_names=common_class_labels,\n",
    "        labels=common_class_indices\n",
    "    )\n",
    "    print(report)\n",
    "    \n",
    "    # 필터링된 데이터의 정확도\n",
    "    accuracy = (filtered_pred == filtered_actual).mean()\n",
    "    print(f\"\\n🎯 정확도 (공통 클래스만): {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    print(f\"평가 데이터: {len(filtered_actual)}/{len(test_y_actual)}개\")\n",
    "\n",
    "# 8. 예측 샘플 출력\n",
    "print(f\"\\n🔍 예측 샘플 (처음 10개):\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for i in range(min(10, len(test_texts))):\n",
    "    text = test_texts[i][:60] + \"...\" if len(test_texts[i]) > 60 else test_texts[i]\n",
    "    actual = test_y_actual[i]\n",
    "    predicted = test_y_pred[i]\n",
    "    status = \"✅\" if actual == predicted else \"❌\"\n",
    "    \n",
    "    print(f\"{i+1:2d}. {status} 실제: {actual:<12} 예측: {predicted:<12}\")\n",
    "    print(f\"    텍스트: {text}\")\n",
    "    print()\n",
    "\n",
    "# 9. 클래스별 성능 요약\n",
    "print(f\"\\n📈 클래스별 성능 요약:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "from collections import defaultdict\n",
    "class_stats = defaultdict(lambda: {'total': 0, 'correct': 0})\n",
    "\n",
    "for actual, pred in zip(test_y_actual, test_y_pred):\n",
    "    if actual in common_classes:  # 공통 클래스만 계산\n",
    "        class_stats[actual]['total'] += 1\n",
    "        if actual == pred:\n",
    "            class_stats[actual]['correct'] += 1\n",
    "\n",
    "print(f\"{'클래스':<15} {'전체':<8} {'정답':<8} {'정확도':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for class_name, stats in sorted(class_stats.items()):\n",
    "    if stats['total'] > 0:\n",
    "        class_accuracy = stats['correct'] / stats['total']\n",
    "        print(f\"{class_name:<15} {stats['total']:<8} {stats['correct']:<8} {class_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "53gspj90vxl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🎯 Category2 모델의 test_data 성능 평가\n",
      "================================================================================\n",
      "Category2 학습용 변수들을 재정의합니다...\n",
      "📊 Category2 데이터 확인:\n",
      "  - 전체 Category2 데이터: 3359개\n",
      "  - 고유 Category2 클래스: 64개\n",
      "  - Category2 클래스 목록: ['갈등', '감동', '걱정', '경멸', '고마움', '고통', '공감', '공포', '궁금함', '귀중함', '그리움', '기대감', '난처함', '날카로움', '냉담', '너그러움', '놀람', '다정함', '답답함', '동정(슬픔)', '두근거림', '만족감', '매력적', '무기력', '미안함', '반가움', '반감', '발열', '부끄러움', '불만', '불신감', '불쾌', '불편함', '비위상함', '사나움', '수치심', '시기심', '신뢰감', '신명남', '실망', '싫증', '심심함', '아쉬움', '아픔', '안정감', '억울함', '외로움', '외면', '욕심', '원망', '위축감', '자랑스러움', '자신감', '절망', '죄책감', '즐거움', '초조함', '치사함', '타오름', '통쾌함', '편안함', '허망', '호감', '후회']\n",
      "✅ Category2에서 중립이 성공적으로 제거되었습니다.\n",
      "  - 인코딩된 Category2 클래스: 64개\n",
      "X shape: (3359, 1024)\n",
      "y shape: (3359,)\n",
      "y_cat1_onehot shape: (3359, 10)\n",
      "X_combined shape: (3359, 1034)\n",
      "y_cat2 shape: (3359,)\n",
      "y_cat2_encoded shape: (3359,)\n",
      "\n",
      "📝 Category2 예측을 위한 데이터 준비...\n",
      "테스트 데이터:\n",
      "- Category1 실제값: 664개\n",
      "- Category2 실제값: 664개\n",
      "- 테스트 Category2 클래스: 64개\n",
      "- 테스트 데이터 중립: Category1=5개, Category2=0개\n",
      "\n",
      "🔧 Category1 예측값으로 Category2 예측용 특성 생성...\n",
      "test_X shape: (664, 1024)\n",
      "test_cat1_onehot shape: (664, 10)\n",
      "✅ 결합된 특성: (664, 1034)\n",
      "\n",
      "🔄 전체 학습 데이터로 Category2 최종 모델 학습...\n",
      "학습 데이터 확인: X_combined (3359, 1034), y_cat2_encoded (3359,)\n",
      "✅ Category2 최종 모델 학습 완료!\n",
      "\n",
      "🎯 test_data Category2 예측 수행...\n",
      "\n",
      "📋 Category2 클래스 정보:\n",
      "학습 클래스 수: 64\n",
      "테스트 실제 클래스 수: 64\n",
      "공통 클래스 수: 64\n",
      "✅ 훈련 데이터와 테스트 데이터의 Category2 클래스가 완벽히 일치합니다!\n",
      "\n",
      "📊 Category2 Classification Report:\n",
      "================================================================================\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          갈등       0.00      0.00      0.00         1\n",
      "          감동       0.29      0.40      0.34        30\n",
      "          걱정       0.43      0.13      0.20        23\n",
      "          경멸       0.20      0.44      0.27        18\n",
      "         고마움       0.46      0.63      0.53        19\n",
      "          고통       0.00      0.00      0.00         9\n",
      "          공감       0.00      0.00      0.00         7\n",
      "          공포       0.00      0.00      0.00        17\n",
      "         궁금함       0.12      0.56      0.20         9\n",
      "         귀중함       0.00      0.00      0.00         5\n",
      "         그리움       0.50      0.09      0.15        11\n",
      "         기대감       0.50      0.39      0.44        18\n",
      "         난처함       0.25      0.07      0.11        14\n",
      "        날카로움       0.00      0.00      0.00         3\n",
      "          냉담       0.00      0.00      0.00         3\n",
      "        너그러움       0.00      0.00      0.00         1\n",
      "          놀람       0.33      0.19      0.24        31\n",
      "         다정함       0.00      0.00      0.00         9\n",
      "         답답함       0.22      0.11      0.15        18\n",
      "      동정(슬픔)       0.57      0.48      0.52        27\n",
      "        두근거림       0.00      0.00      0.00         2\n",
      "         만족감       0.35      0.35      0.35        49\n",
      "         매력적       1.00      0.08      0.14        13\n",
      "         무기력       0.25      0.36      0.29        14\n",
      "         미안함       1.00      0.29      0.44         7\n",
      "         반가움       0.20      0.06      0.10        16\n",
      "          반감       0.20      0.20      0.20         5\n",
      "          발열       0.00      0.00      0.00         3\n",
      "        부끄러움       0.00      0.00      0.00        16\n",
      "          불만       0.20      0.12      0.15         8\n",
      "         불신감       0.20      0.12      0.15         8\n",
      "          불쾌       0.11      0.15      0.13        20\n",
      "         불편함       0.40      0.29      0.33         7\n",
      "        비위상함       0.00      0.00      0.00         1\n",
      "         사나움       0.20      0.25      0.22         4\n",
      "         수치심       0.00      0.00      0.00         3\n",
      "         시기심       0.20      0.50      0.29         2\n",
      "         신뢰감       0.00      0.00      0.00         1\n",
      "         신명남       1.00      0.20      0.33         5\n",
      "          실망       0.11      0.31      0.16        13\n",
      "          싫증       0.00      0.00      0.00         9\n",
      "         심심함       0.00      0.00      0.00         1\n",
      "         아쉬움       0.43      0.30      0.36        33\n",
      "          아픔       0.00      0.00      0.00         3\n",
      "         안정감       0.20      0.12      0.15         8\n",
      "         억울함       0.18      0.46      0.26        13\n",
      "         외로움       0.50      0.17      0.25         6\n",
      "          외면       0.00      0.00      0.00         1\n",
      "          욕심       0.21      0.44      0.29        18\n",
      "          원망       0.00      0.00      0.00         3\n",
      "         위축감       0.00      0.00      0.00         4\n",
      "       자랑스러움       0.16      0.42      0.23        12\n",
      "         자신감       0.00      0.00      0.00         1\n",
      "          절망       0.00      0.00      0.00         7\n",
      "         죄책감       0.00      0.00      0.00         2\n",
      "         즐거움       0.40      0.44      0.42        27\n",
      "         초조함       0.00      0.00      0.00         5\n",
      "         치사함       0.00      0.00      0.00         5\n",
      "         타오름       0.00      0.00      0.00         3\n",
      "         통쾌함       0.00      0.00      0.00         1\n",
      "         편안함       0.50      0.25      0.33         4\n",
      "          허망       0.30      0.27      0.29        11\n",
      "          호감       0.33      0.10      0.15        10\n",
      "          후회       0.33      0.29      0.31         7\n",
      "\n",
      "    accuracy                           0.24       664\n",
      "   macro avg       0.20      0.16      0.15       664\n",
      "weighted avg       0.28      0.24      0.23       664\n",
      "\n",
      "\n",
      "🎯 Category2 전체 정확도: 0.2425 (24.25%)\n",
      "평가 데이터: 664개 모두 평가\n",
      "\n",
      "🔍 Category2 예측 샘플 (처음 10개):\n",
      "----------------------------------------------------------------------------------------------------\n",
      " 1. ❌ Cat1: 기쁨 → 기쁨 | Cat2: 만족감          → 즐거움         \n",
      "    텍스트: 보는동안 너무 행복했고 초콜렛이 너무 먹고싶었고 티모시가 잘생겼고 울어!!하는부분이 있어서...\n",
      "\n",
      " 2. ❌ Cat1: 기쁨 → 기쁨 | Cat2: 만족감          → 기대감         \n",
      "    텍스트: 어릴 때 가 보고 빕스는 거의 처음인데(기억에 없음) 지금 딸기축제 기간이라 만족스러운 식...\n",
      "\n",
      " 3. ✅ Cat1: 기쁨 → 기쁨 | Cat2: 만족감          → 만족감         \n",
      "    텍스트: 미리 계좌로 환전해둔 돈을 해외에서 환전수수료 없이 인출 가능한 트레블로그라는 카드인데, ...\n",
      "\n",
      " 4. ❌ Cat1: 슬픔 → 싫어함(상태) | Cat2: 무기력          → 난처함         \n",
      "    텍스트: 요즘 번아웃도 자꾸 올라오고 무기력해서 종강하고 교류하기도 버거운 상태가 와부렀으요ㅠㅠ \n",
      "\n",
      " 5. ❌ Cat1: 기쁨 → 미움(상대방) | Cat2: 즐거움          → 비위상함        \n",
      "    텍스트: 크라임씬 장똥민이 범행 도구 찾으려고 화장실 탱크 뒤지는데 거기에 진짜 똥 넣어놓은 거 진...\n",
      "\n",
      " 6. ❌ Cat1: 싫어함(상태) → 슬픔 | Cat2: 답답함          → 무기력         \n",
      "    텍스트: 가슴이 답답해짐 진짜 개답답해짐\n",
      "우리진짜투표잘하자\n",
      "\n",
      " 7. ❌ Cat1: 기쁨 → 욕망 | Cat2: 만족감          → 욕심          \n",
      "    텍스트: 지그재그랑 에이블리랑 할인 대결하나\n",
      "아 흐뭇해\n",
      "계속되길...\n",
      "영원히....\n",
      "\n",
      " 8. ❌ Cat1: 기쁨 → 욕망 | Cat2: 자랑스러움        → 욕심          \n",
      "    텍스트: 첨으로 수제 초콜릿 만듬\n",
      "초콜릿을 5시간이나 만드는 사람이 있다??? 그게 바로 나\n",
      "\n",
      " 9. ❌ Cat1: 슬픔 → 기쁨 | Cat2: 절망           → 기대감         \n",
      "    텍스트: 단톡방에 공지들 슬슬 올라오는거 보니까 곧 개강이라는게 실감나서 갑자기 재기하고싶고 인생이...\n",
      "\n",
      "10. ❌ Cat1: 기쁨 → 기쁨 | Cat2: 즐거움          → 감동          \n",
      "    텍스트: 장흥신 공손한 손가락질 개웃겨요\n",
      "애드립 미친것 같음\n",
      "\n",
      "\n",
      "📈 Category2 클래스별 성능 요약:\n",
      "------------------------------------------------------------\n",
      "클래스             전체       정답       정확도       \n",
      "--------------------------------------------------\n",
      "갈등              1        0        0.0000\n",
      "감동              30       12       0.4000\n",
      "걱정              23       3        0.1304\n",
      "경멸              18       8        0.4444\n",
      "고마움             19       12       0.6316\n",
      "고통              9        0        0.0000\n",
      "공감              7        0        0.0000\n",
      "공포              17       0        0.0000\n",
      "궁금함             9        5        0.5556\n",
      "귀중함             5        0        0.0000\n",
      "그리움             11       1        0.0909\n",
      "기대감             18       7        0.3889\n",
      "난처함             14       1        0.0714\n",
      "날카로움            3        0        0.0000\n",
      "냉담              3        0        0.0000\n",
      "너그러움            1        0        0.0000\n",
      "놀람              31       6        0.1935\n",
      "다정함             9        0        0.0000\n",
      "답답함             18       2        0.1111\n",
      "동정(슬픔)          27       13       0.4815\n",
      "두근거림            2        0        0.0000\n",
      "만족감             49       17       0.3469\n",
      "매력적             13       1        0.0769\n",
      "무기력             14       5        0.3571\n",
      "미안함             7        2        0.2857\n",
      "반가움             16       1        0.0625\n",
      "반감              5        1        0.2000\n",
      "발열              3        0        0.0000\n",
      "부끄러움            16       0        0.0000\n",
      "불만              8        1        0.1250\n",
      "불신감             8        1        0.1250\n",
      "불쾌              20       3        0.1500\n",
      "불편함             7        2        0.2857\n",
      "비위상함            1        0        0.0000\n",
      "사나움             4        1        0.2500\n",
      "수치심             3        0        0.0000\n",
      "시기심             2        1        0.5000\n",
      "신뢰감             1        0        0.0000\n",
      "신명남             5        1        0.2000\n",
      "실망              13       4        0.3077\n",
      "싫증              9        0        0.0000\n",
      "심심함             1        0        0.0000\n",
      "아쉬움             33       10       0.3030\n",
      "아픔              3        0        0.0000\n",
      "안정감             8        1        0.1250\n",
      "억울함             13       6        0.4615\n",
      "외로움             6        1        0.1667\n",
      "외면              1        0        0.0000\n",
      "욕심              18       8        0.4444\n",
      "원망              3        0        0.0000\n",
      "위축감             4        0        0.0000\n",
      "자랑스러움           12       5        0.4167\n",
      "자신감             1        0        0.0000\n",
      "절망              7        0        0.0000\n",
      "죄책감             2        0        0.0000\n",
      "즐거움             27       12       0.4444\n",
      "초조함             5        0        0.0000\n",
      "치사함             5        0        0.0000\n",
      "타오름             3        0        0.0000\n",
      "통쾌함             1        0        0.0000\n",
      "편안함             4        1        0.2500\n",
      "허망              11       3        0.2727\n",
      "호감              10       1        0.1000\n",
      "후회              7        2        0.2857\n",
      "\n",
      "📊 최종 성능 비교:\n",
      "============================================================\n",
      "Category1 정확도: 0.4880 (48.80%)\n",
      "Category2 정확도: 0.2425 (24.25%)\n",
      "✅ Category1 분류가 더 정확합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\user\\anaconda3\\envs\\skn_after_study\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# Category2 모델로 test_data 예측 및 classification_report\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"🎯 Category2 모델의 test_data 성능 평가\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 1. 필요한 변수들 정의 (필요시)\n",
    "if 'X_combined' not in locals():\n",
    "    print(\"Category2 학습용 변수들을 재정의합니다...\")\n",
    "    \n",
    "    # OneHotEncoder for Category1\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    cat1_encoder = OneHotEncoder(sparse_output=False)\n",
    "    y_cat1_onehot = cat1_encoder.fit_transform(y.reshape(-1, 1))\n",
    "    \n",
    "    # Combined features for Category2\n",
    "    X_combined = np.hstack([X, y_cat1_onehot])\n",
    "    \n",
    "    # Category2 encoder - 변경: category2 → re_category2 (중립 제거된 데이터 사용)\n",
    "    y_cat2 = data['re_category2'].values\n",
    "    print(f\"📊 Category2 데이터 확인:\")\n",
    "    print(f\"  - 전체 Category2 데이터: {len(y_cat2)}개\")\n",
    "    print(f\"  - 고유 Category2 클래스: {len(np.unique(y_cat2))}개\")\n",
    "    print(f\"  - Category2 클래스 목록: {sorted(np.unique(y_cat2))}\")\n",
    "    \n",
    "    # 중립 제거 확인\n",
    "    neutral_count = (y_cat2 == '중립').sum()\n",
    "    if neutral_count > 0:\n",
    "        print(f\"⚠️ 경고: Category2에 여전히 중립이 {neutral_count}개 있습니다!\")\n",
    "    else:\n",
    "        print(\"✅ Category2에서 중립이 성공적으로 제거되었습니다.\")\n",
    "    \n",
    "    le_cat2 = LabelEncoder()\n",
    "    y_cat2_encoded = le_cat2.fit_transform(y_cat2)\n",
    "    \n",
    "    print(f\"  - 인코딩된 Category2 클래스: {len(le_cat2.classes_)}개\")\n",
    "    \n",
    "    print(f\"X shape: {X.shape}\")\n",
    "    print(f\"y shape: {y.shape}\")\n",
    "    print(f\"y_cat1_onehot shape: {y_cat1_onehot.shape}\")\n",
    "    print(f\"X_combined shape: {X_combined.shape}\")\n",
    "    print(f\"y_cat2 shape: {y_cat2.shape}\")\n",
    "    print(f\"y_cat2_encoded shape: {y_cat2_encoded.shape}\")\n",
    "    \n",
    "    # 크기 확인 및 수정\n",
    "    if X_combined.shape[0] != y_cat2_encoded.shape[0]:\n",
    "        print(f\"⚠️ 크기 불일치 감지: X_combined {X_combined.shape[0]} vs y_cat2_encoded {y_cat2_encoded.shape[0]}\")\n",
    "        min_size = min(X_combined.shape[0], y_cat2_encoded.shape[0])\n",
    "        X_combined = X_combined[:min_size]\n",
    "        y_cat2_encoded = y_cat2_encoded[:min_size]\n",
    "        print(f\"✅ 크기 조정 완료: {X_combined.shape[0]} rows\")\n",
    "\n",
    "# 2. Category1을 먼저 예측해야 Category2를 예측할 수 있음\n",
    "print(\"\\n📝 Category2 예측을 위한 데이터 준비...\")\n",
    "\n",
    "# test_data의 실제 category1과 category2\n",
    "test_y_actual_cat1 = test_data['category1'].values\n",
    "test_y_actual_cat2 = test_data['category2'].values\n",
    "\n",
    "print(f\"테스트 데이터:\")\n",
    "print(f\"- Category1 실제값: {len(test_y_actual_cat1)}개\")\n",
    "print(f\"- Category2 실제값: {len(test_y_actual_cat2)}개\")\n",
    "print(f\"- 테스트 Category2 클래스: {len(np.unique(test_y_actual_cat2))}개\")\n",
    "\n",
    "# 테스트 데이터에서 중립 확인 및 필터링 정보\n",
    "test_cat1_neutral_count = (test_y_actual_cat1 == '중립').sum()\n",
    "test_cat2_neutral_count = (test_y_actual_cat2 == '중립').sum()\n",
    "print(f\"- 테스트 데이터 중립: Category1={test_cat1_neutral_count}개, Category2={test_cat2_neutral_count}개\")\n",
    "\n",
    "# Category1 예측값을 사용하여 Category2 예측용 특성 생성\n",
    "print(\"\\n🔧 Category1 예측값으로 Category2 예측용 특성 생성...\")\n",
    "\n",
    "# Category1 예측값을 원핫인코딩\n",
    "test_cat1_onehot = cat1_encoder.transform(test_y_pred.reshape(-1, 1))\n",
    "test_X_combined = np.hstack([test_X, test_cat1_onehot])\n",
    "\n",
    "print(f\"test_X shape: {test_X.shape}\")\n",
    "print(f\"test_cat1_onehot shape: {test_cat1_onehot.shape}\")\n",
    "print(f\"✅ 결합된 특성: {test_X_combined.shape}\")\n",
    "\n",
    "# 3. 전체 학습 데이터로 Category2 최종 모델 학습\n",
    "print(\"\\n🔄 전체 학습 데이터로 Category2 최종 모델 학습...\")\n",
    "print(f\"학습 데이터 확인: X_combined {X_combined.shape}, y_cat2_encoded {y_cat2_encoded.shape}\")\n",
    "\n",
    "final_cat2_model = xgb.XGBClassifier(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=8,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    tree_method=\"hist\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 전체 학습 데이터로 Category2 모델 학습\n",
    "final_cat2_model.fit(X_combined, y_cat2_encoded)\n",
    "print(\"✅ Category2 최종 모델 학습 완료!\")\n",
    "\n",
    "# 4. test_data로 Category2 예측 수행\n",
    "print(\"\\n🎯 test_data Category2 예측 수행...\")\n",
    "test_y_pred_cat2_encoded = final_cat2_model.predict(test_X_combined)\n",
    "test_y_pred_cat2 = le_cat2.inverse_transform(test_y_pred_cat2_encoded)\n",
    "\n",
    "# 5. 학습 클래스와 테스트 클래스 비교 (Category2)\n",
    "train_classes_cat2 = set(le_cat2.classes_)\n",
    "test_actual_classes_cat2 = set(test_y_actual_cat2)\n",
    "\n",
    "print(f\"\\n📋 Category2 클래스 정보:\")\n",
    "print(f\"학습 클래스 수: {len(train_classes_cat2)}\")\n",
    "print(f\"테스트 실제 클래스 수: {len(test_actual_classes_cat2)}\")\n",
    "\n",
    "# 학습에 없는 클래스 확인\n",
    "unseen_classes_cat2 = test_actual_classes_cat2 - train_classes_cat2\n",
    "if unseen_classes_cat2:\n",
    "    print(f\"⚠️ 학습에 없던 Category2 클래스들: {unseen_classes_cat2}\")\n",
    "\n",
    "common_classes_cat2 = train_classes_cat2 & test_actual_classes_cat2\n",
    "print(f\"공통 클래스 수: {len(common_classes_cat2)}\")\n",
    "\n",
    "# 클래스 매치 확인\n",
    "if len(train_classes_cat2) == len(test_actual_classes_cat2) == len(common_classes_cat2):\n",
    "    print(\"✅ 훈련 데이터와 테스트 데이터의 Category2 클래스가 완벽히 일치합니다!\")\n",
    "else:\n",
    "    print(\"❌ 클래스 불일치가 있습니다.\")\n",
    "\n",
    "# 6. Category2 Classification Report 생성\n",
    "print(f\"\\n📊 Category2 Classification Report:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 모든 클래스가 일치하므로 전체 평가 가능\n",
    "test_y_actual_cat2_encoded = le_cat2.transform(test_y_actual_cat2)\n",
    "report = classification_report(\n",
    "    test_y_actual_cat2_encoded,\n",
    "    test_y_pred_cat2_encoded,\n",
    "    target_names=le_cat2.classes_\n",
    ")\n",
    "print(report)\n",
    "\n",
    "# 전체 정확도\n",
    "accuracy_cat2 = (test_y_pred_cat2 == test_y_actual_cat2).mean()\n",
    "print(f\"\\n🎯 Category2 전체 정확도: {accuracy_cat2:.4f} ({accuracy_cat2*100:.2f}%)\")\n",
    "print(f\"평가 데이터: {len(test_y_actual_cat2)}개 모두 평가\")\n",
    "\n",
    "# 7. Category2 예측 샘플 출력\n",
    "print(f\"\\n🔍 Category2 예측 샘플 (처음 10개):\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for i in range(min(10, len(test_texts))):\n",
    "    text = test_texts[i][:50] + \"...\" if len(test_texts[i]) > 50 else test_texts[i]\n",
    "    actual_cat1 = test_y_actual_cat1[i]\n",
    "    pred_cat1 = test_y_pred[i]\n",
    "    actual_cat2 = test_y_actual_cat2[i]\n",
    "    pred_cat2 = test_y_pred_cat2[i]\n",
    "    status_cat2 = \"✅\" if actual_cat2 == pred_cat2 else \"❌\"\n",
    "    \n",
    "    print(f\"{i+1:2d}. {status_cat2} Cat1: {actual_cat1} → {pred_cat1} | Cat2: {actual_cat2:<12} → {pred_cat2:<12}\")\n",
    "    print(f\"    텍스트: {text}\")\n",
    "    print()\n",
    "\n",
    "# 8. Category2 클래스별 성능 요약\n",
    "print(f\"\\n📈 Category2 클래스별 성능 요약:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "class_stats_cat2 = defaultdict(lambda: {'total': 0, 'correct': 0})\n",
    "\n",
    "for actual, pred in zip(test_y_actual_cat2, test_y_pred_cat2):\n",
    "    class_stats_cat2[actual]['total'] += 1\n",
    "    if actual == pred:\n",
    "        class_stats_cat2[actual]['correct'] += 1\n",
    "\n",
    "print(f\"{'클래스':<15} {'전체':<8} {'정답':<8} {'정확도':<10}\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for class_name, stats in sorted(class_stats_cat2.items()):\n",
    "    if stats['total'] > 0:\n",
    "        class_accuracy = stats['correct'] / stats['total']\n",
    "        print(f\"{class_name:<15} {stats['total']:<8} {stats['correct']:<8} {class_accuracy:.4f}\")\n",
    "\n",
    "# 9. Category1 vs Category2 성능 비교\n",
    "print(f\"\\n📊 최종 성능 비교:\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Category1 정확도: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "print(f\"Category2 정확도: {accuracy_cat2:.4f} ({accuracy_cat2*100:.2f}%)\")\n",
    "\n",
    "if accuracy > accuracy_cat2:\n",
    "    print(\"✅ Category1 분류가 더 정확합니다.\")\n",
    "else:\n",
    "    print(\"✅ Category2 분류가 더 정확합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "404da083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "얘들아 딸기축제인가 딸기장례식인가는 뭐 가지마라\n",
      "어우 별로를 넘어서 아깝다 그냥\n",
      "핸드폰 바꿨는데.. 어찌나 전뇌이식이 잘되는지 이전 폰에서 듣던 음악 멈춰둔 부분까지 살려놔서 새로 산 기분이 전혀 안남..\n",
      "친구가 만들어줬어 어이없어서 받자마자 오열함\n",
      "아니 맞긴한데\n",
      "솔직히 주말 껴서 4일…연휴라기엔 너무 눈속임임…사실상 이틀 쉰 거잖아\n",
      "소인 편의점에서 매일우유 크림빵을 만원 어치 사려고 갔는데 3개를 사기에는 부족한 돈이라 슬펐소이다. 물가가 너무 비싼것 같소.\n",
      "연휴 이틀이 다 주말에 겹쳐져 있었는데 왜 대체 공휴일은 하루만 주는거야. 부족해, 주말 상관없이 설 연휴 3일 다 완벽하게 보장해 줘.\n",
      "이렇게 자극적인 드라마 아이들도 다 접할텐데 이젠 수위조절도 안하고 막찍는거같아서 좀 안타까움이 생기네요… ㅠㅠ\n",
      "이천 햅살 커피프라프치노~! 왠지 고소한 커피맛일꺼란 기대를 엄청안고 주문했는데.. 자그마치 6300원ㅜㅜ 비싼 금액인데 만족스럽진 못했다눈ㅜㅜ\n"
     ]
    }
   ],
   "source": [
    "for context in test_data[test_data['category2']=='불만']['context']:\n",
    "  print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "448dfaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 감정 분류 파이프라인 초기화...\n",
      "✅ 파이프라인 초기화 완료!\n"
     ]
    }
   ],
   "source": [
    "# 10. 통합 예측 파이프라인 구현\n",
    "\n",
    "class EmotionClassificationPipeline:\n",
    "    \"\"\"\n",
    "    텍스트 입력 → Category1 예측 → Category2 예측 → 종합 평가 파이프라인\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, embeddings_model, cat1_model, cat2_model, \n",
    "                 cat1_encoder, cat2_encoder, cat1_onehot_encoder):\n",
    "        self.embeddings_model = embeddings_model\n",
    "        self.cat1_model = cat1_model\n",
    "        self.cat2_model = cat2_model\n",
    "        self.cat1_encoder = cat1_encoder\n",
    "        self.cat2_encoder = cat2_encoder\n",
    "        self.cat1_onehot_encoder = cat1_onehot_encoder\n",
    "        \n",
    "    def predict_single(self, text):\n",
    "        \"\"\"\n",
    "        단일 텍스트에 대해 카테고리1과 카테고리2를 예측\n",
    "        \n",
    "        Args:\n",
    "            text (str): 예측할 텍스트\n",
    "        \n",
    "        Returns:\n",
    "            dict: 예측 결과 딕셔너리\n",
    "        \"\"\"\n",
    "        # 1. 텍스트 임베딩\n",
    "        text_vector = self.embeddings_model.encode(text).reshape(1, -1)\n",
    "        \n",
    "        # 2. Category1 예측\n",
    "        cat1_pred_encoded = self.cat1_model.predict(text_vector)[0]\n",
    "        cat1_pred = self.cat1_encoder.inverse_transform([cat1_pred_encoded])[0]\n",
    "        cat1_prob = self.cat1_model.predict_proba(text_vector)[0].max()\n",
    "        \n",
    "        # 3. Category1 예측값을 사용하여 Category2 예측용 특성 생성\n",
    "        cat1_onehot = self.cat1_onehot_encoder.transform([[cat1_pred]])\n",
    "        combined_features = np.hstack([text_vector, cat1_onehot])\n",
    "        \n",
    "        # 4. Category2 예측\n",
    "        cat2_pred_encoded = self.cat2_model.predict(combined_features)[0]\n",
    "        cat2_pred = self.cat2_encoder.inverse_transform([cat2_pred_encoded])[0]\n",
    "        cat2_prob = self.cat2_model.predict_proba(combined_features)[0].max()\n",
    "        \n",
    "        return {\n",
    "            'text': text,\n",
    "            'category1_predicted': cat1_pred,\n",
    "            'category1_confidence': cat1_prob,\n",
    "            'category2_predicted': cat2_pred,\n",
    "            'category2_confidence': cat2_prob\n",
    "        }\n",
    "    \n",
    "    def predict_batch(self, texts):\n",
    "        \"\"\"\n",
    "        여러 텍스트에 대해 배치 예측\n",
    "        \n",
    "        Args:\n",
    "            texts (list): 예측할 텍스트 리스트\n",
    "        \n",
    "        Returns:\n",
    "            list: 예측 결과 리스트\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        for text in texts:\n",
    "            result = self.predict_single(text)\n",
    "            results.append(result)\n",
    "        return results\n",
    "    \n",
    "    def evaluate_with_ground_truth(self, texts, true_cat1, true_cat2):\n",
    "        \"\"\"\n",
    "        실제 정답과 비교하여 성능 평가\n",
    "        두 카테고리가 모두 맞은 경우만 정답으로 처리\n",
    "        \n",
    "        Args:\n",
    "            texts (list): 예측할 텍스트 리스트\n",
    "            true_cat1 (list): 실제 category1 라벨\n",
    "            true_cat2 (list): 실제 category2 라벨\n",
    "        \n",
    "        Returns:\n",
    "            dict: 평가 결과\n",
    "        \"\"\"\n",
    "        predictions = self.predict_batch(texts)\n",
    "        \n",
    "        total_count = len(texts)\n",
    "        cat1_correct = 0\n",
    "        cat2_correct = 0\n",
    "        both_correct = 0\n",
    "        \n",
    "        detailed_results = []\n",
    "        \n",
    "        for i, (pred, actual_cat1, actual_cat2) in enumerate(zip(predictions, true_cat1, true_cat2)):\n",
    "            cat1_match = pred['category1_predicted'] == actual_cat1\n",
    "            cat2_match = pred['category2_predicted'] == actual_cat2\n",
    "            both_match = cat1_match and cat2_match\n",
    "            \n",
    "            if cat1_match:\n",
    "                cat1_correct += 1\n",
    "            if cat2_match:\n",
    "                cat2_correct += 1\n",
    "            if both_match:\n",
    "                both_correct += 1\n",
    "            \n",
    "            detailed_results.append({\n",
    "                'index': i,\n",
    "                'text': pred['text'],\n",
    "                'actual_cat1': actual_cat1,\n",
    "                'predicted_cat1': pred['category1_predicted'],\n",
    "                'cat1_match': cat1_match,\n",
    "                'cat1_confidence': pred['category1_confidence'],\n",
    "                'actual_cat2': actual_cat2,\n",
    "                'predicted_cat2': pred['category2_predicted'],\n",
    "                'cat2_match': cat2_match,\n",
    "                'cat2_confidence': pred['category2_confidence'],\n",
    "                'both_correct': both_match\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            'total_samples': total_count,\n",
    "            'category1_accuracy': cat1_correct / total_count,\n",
    "            'category2_accuracy': cat2_correct / total_count,\n",
    "            'both_correct_accuracy': both_correct / total_count,  # 핵심 지표\n",
    "            'category1_correct_count': cat1_correct,\n",
    "            'category2_correct_count': cat2_correct,\n",
    "            'both_correct_count': both_correct,\n",
    "            'detailed_results': detailed_results\n",
    "        }\n",
    "\n",
    "# 변수 초기화 확인 및 파이프라인 객체 생성\n",
    "print(\"🚀 감정 분류 파이프라인 초기화...\")\n",
    "\n",
    "# 필요한 변수들이 정의되었는지 확인\n",
    "required_vars = ['final_cat1_model', 'final_cat2_model', 'le', 'le_cat2', 'cat1_encoder']\n",
    "missing_vars = [var for var in required_vars if var not in locals()]\n",
    "\n",
    "if missing_vars:\n",
    "    print(f\"⚠️ 다음 변수들이 정의되지 않았습니다: {missing_vars}\")\n",
    "    print(\"모델을 먼저 학습시켜주세요.\")\n",
    "else:\n",
    "    pipeline = EmotionClassificationPipeline(\n",
    "        embeddings_model=embeddings_model,\n",
    "        cat1_model=final_cat1_model,\n",
    "        cat2_model=final_cat2_model,\n",
    "        cat1_encoder=le,\n",
    "        cat2_encoder=le_cat2,\n",
    "        cat1_onehot_encoder=cat1_encoder\n",
    "    )\n",
    "    print(\"✅ 파이프라인 초기화 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c20c6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 파이프라인으로 test_data 종합 평가\n",
      "================================================================================\n",
      "평가 데이터: 664개\n",
      "Category1 클래스 수: 10\n",
      "Category2 클래스 수: 64\n",
      "테스트 데이터 중립: Category1=5개, Category2=0개\n",
      "\n",
      "🔄 파이프라인 평가 실행 중...\n",
      "Category1: 중립 포함하여 평가\n",
      "Category2: 중립 없음 (테스트 데이터에도 없음)\n",
      "\n",
      "📊 파이프라인 종합 평가 결과:\n",
      "============================================================\n",
      "전체 테스트 샘플 수: 664\n",
      "\n",
      "📈 개별 정확도:\n",
      "  Category1 정확도: 0.4880 (324/664)\n",
      "  Category2 정확도: 0.2425 (161/664)\n",
      "\n",
      "🎯 핵심 지표 - 두 카테고리 모두 정답:\n",
      "  종합 정확도: 0.2244 (149/664)\n",
      "  종합 정확도: 22.44%\n",
      "\n",
      "🔍 상세 분석:\n",
      "------------------------------------------------------------\n",
      "두 카테고리 모두 정답: 149개 (22.44%)\n",
      "Category1만 정답: 175개 (26.36%)\n",
      "Category2만 정답: 12개 (1.81%)\n",
      "둘 다 틀림: 328개 (49.40%)\n",
      "\n",
      "✅ 두 카테고리 모두 정답인 샘플들 (처음 10개):\n",
      "====================================================================================================\n",
      " 1. Cat1: 기쁨 ✓ | Cat2: 만족감 ✓\n",
      "    신뢰도: Cat1=0.467, Cat2=0.208\n",
      "    텍스트: 미리 계좌로 환전해둔 돈을 해외에서 환전수수료 없이 인출 가능한 트레블로그라는 카드인데, 선택할 수 있는 디...\n",
      "\n",
      " 2. Cat1: 기쁨 ✓ | Cat2: 만족감 ✓\n",
      "    신뢰도: Cat1=0.943, Cat2=0.283\n",
      "    텍스트: 우연히 보게 된 영상인데, 노래가 너무 좋아서 플리에도 추가하고, 카카오톡 프뮤로도 해놨음. 음원도 좋긴 한...\n",
      "\n",
      " 3. Cat1: 욕망 ✓ | Cat2: 궁금함 ✓\n",
      "    신뢰도: Cat1=0.653, Cat2=0.422\n",
      "    텍스트: 일본은 근무시간에 개인메세지 안 한다고??? 신기\n",
      "애초에 개인 메세지 도구인 카카오톡으로 업무를 하는데 친구...\n",
      "\n",
      " 4. Cat1: 기쁨 ✓ | Cat2: 즐거움 ✓\n",
      "    신뢰도: Cat1=0.415, Cat2=0.367\n",
      "    텍스트: 이렇게까지 재밌을줄은 몰랐음\n",
      "헉 엠씨 없이 진행하나??\n",
      "했는데 둘의 티키타카가 미쳤음\n",
      "\n",
      " 5. Cat1: 기쁨 ✓ | Cat2: 만족감 ✓\n",
      "    신뢰도: Cat1=0.756, Cat2=0.262\n",
      "    텍스트: 초대박 귀여운 강아디도 있음 우리 자리 와서 인사도 해줌 .. 🥹\n",
      "좌석이 약간 당황스러운 것 말고 다 좋았던...\n",
      "\n",
      " 6. Cat1: 기쁨 ✓ | Cat2: 만족감 ✓\n",
      "    신뢰도: Cat1=0.641, Cat2=0.773\n",
      "    텍스트: 편의점 초콜릿 중 가장 맛있는 초콜릿이라고 생각하오. 입에 넣자마자 기분 좋아지는 맛이오. \n",
      "\n",
      " 7. Cat1: 두려움 ✓ | Cat2: 놀람 ✓\n",
      "    신뢰도: Cat1=0.304, Cat2=0.517\n",
      "    텍스트: 아니 비였는데!!! 영상8도였는데!!!! 눈으로 바뀌었다니까!!!!! 내가 과몰입을 하는게 아니라!!!! 2...\n",
      "\n",
      " 8. Cat1: 두려움 ✓ | Cat2: 걱정 ✓\n",
      "    신뢰도: Cat1=0.249, Cat2=0.648\n",
      "    텍스트: 내가 아니라 네가 다칠까봐 걱정돼\n",
      "\n",
      " 9. Cat1: 슬픔 ✓ | Cat2: 후회 ✓\n",
      "    신뢰도: Cat1=0.476, Cat2=0.167\n",
      "    텍스트: 너랑 또 그렇게 헤어지기 싫어 그때로 충분해\n",
      "\n",
      "10. Cat1: 욕망 ✓ | Cat2: 욕심 ✓\n",
      "    신뢰도: Cat1=0.706, Cat2=0.293\n",
      "    텍스트: 유주언니 환연고정 패널로 섭외해야 한다고 봄\n",
      "제발요 내가 하고 싶은 말 유주언니가 다 해주심\n",
      "\n",
      "\n",
      "❌ 두 카테고리 모두 틀린 샘플들 (처음 10개):\n",
      "====================================================================================================\n",
      " 1. Cat1: 슬픔 → 싫어함(상태) | Cat2: 무기력 → 난처함\n",
      "    신뢰도: Cat1=0.428, Cat2=0.295\n",
      "    텍스트: 요즘 번아웃도 자꾸 올라오고 무기력해서 종강하고 교류하기도 버거운 상태가 와부렀으요ㅠㅠ \n",
      "\n",
      " 2. Cat1: 기쁨 → 미움(상대방) | Cat2: 즐거움 → 비위상함\n",
      "    신뢰도: Cat1=0.515, Cat2=0.677\n",
      "    텍스트: 크라임씬 장똥민이 범행 도구 찾으려고 화장실 탱크 뒤지는데 거기에 진짜 똥 넣어놓은 거 진짜 웃겨 뒤지겠음ㅋ...\n",
      "\n",
      " 3. Cat1: 싫어함(상태) → 슬픔 | Cat2: 답답함 → 무기력\n",
      "    신뢰도: Cat1=0.476, Cat2=0.244\n",
      "    텍스트: 가슴이 답답해짐 진짜 개답답해짐\n",
      "우리진짜투표잘하자\n",
      "\n",
      " 4. Cat1: 기쁨 → 욕망 | Cat2: 만족감 → 욕심\n",
      "    신뢰도: Cat1=0.463, Cat2=0.417\n",
      "    텍스트: 지그재그랑 에이블리랑 할인 대결하나\n",
      "아 흐뭇해\n",
      "계속되길...\n",
      "영원히....\n",
      "\n",
      " 5. Cat1: 기쁨 → 욕망 | Cat2: 자랑스러움 → 욕심\n",
      "    신뢰도: Cat1=0.798, Cat2=0.434\n",
      "    텍스트: 첨으로 수제 초콜릿 만듬\n",
      "초콜릿을 5시간이나 만드는 사람이 있다??? 그게 바로 나\n",
      "\n",
      " 6. Cat1: 슬픔 → 기쁨 | Cat2: 절망 → 기대감\n",
      "    신뢰도: Cat1=0.689, Cat2=0.471\n",
      "    텍스트: 단톡방에 공지들 슬슬 올라오는거 보니까 곧 개강이라는게 실감나서 갑자기 재기하고싶고 인생이 다 끝난거처럼 암...\n",
      "\n",
      " 7. Cat1: 미움(상대방) → 분노 | Cat2: 치사함 → 원망\n",
      "    신뢰도: Cat1=0.667, Cat2=0.336\n",
      "    텍스트: 미친새끼 4강전만 안좋았던거 아니고 그전부터 안좋았던걸 사람들이 다봤는데 지 책임 없다고 쏙 빠져나가려고 지...\n",
      "\n",
      " 8. Cat1: 두려움 → 싫어함(상태) | Cat2: 걱정 → 답답함\n",
      "    신뢰도: Cat1=0.518, Cat2=0.882\n",
      "    텍스트: 나 현장에서 엄청 헤맬 거 같은데 ㅠ\n",
      "\n",
      " 9. Cat1: 수치심 → 욕망 | Cat2: 부끄러움 → 궁금함\n",
      "    신뢰도: Cat1=0.500, Cat2=0.817\n",
      "    텍스트: 보라색 교복 치니까 이런거만 뜨는데 지금 이걸 입으라는거예요?\n",
      "\n",
      "10. Cat1: 분노 → 미움(상대방) | Cat2: 불쾌 → 치사함\n",
      "    신뢰도: Cat1=0.465, Cat2=0.450\n",
      "    텍스트: 그냥 국대 제외 아무도 몰랐어야 할 사실을 알게 돼서 이 꼬락서니 난 게 짜증남\n",
      "\n",
      "\n",
      "⚖️ 중립 데이터 분석 (Category1):\n",
      "------------------------------------------------------------\n",
      "중립 데이터 총 5개 중 0개 정답 (0.0%)\n",
      "\n",
      "중립 샘플 예측 결과 (처음 5개):\n",
      "1. ❌ 예측: 욕망 (신뢰도: 0.667)\n",
      "   텍스트: 가면 쓴 사람의 의상이 일본군 제복에서 바뀌었네요 옛날처럼 일본내 성적만 올리면 그만이던 ...\n",
      "2. ❌ 예측: 기쁨 (신뢰도: 0.337)\n",
      "   텍스트: 살인자ㅇ난감 살인장면중 가장 새롭고 신선한 연출이라 감독님이 말한 팝하다는 연출 뭔지 알꺼...\n",
      "3. ❌ 예측: 기쁨 (신뢰도: 0.912)\n",
      "   텍스트: 100일도안된 아기꺼 한복이 있다는게 놀랍다\n",
      "4. ❌ 예측: 미움(상대방) (신뢰도: 0.424)\n",
      "   텍스트: 잘만 물던 쪽쪽이를 하루 아침에 거부하니 엄마는 당황스럽다\n",
      "5. ❌ 예측: 기쁨 (신뢰도: 0.771)\n",
      "   텍스트: 나만 놀라운 건가요? 몰입을 쓰신 황농문교수님께 메일보냈다는 것!?? 대단한 행동력이시네요...\n",
      "\n",
      "🔥 결론:\n",
      "이 파이프라인에서 두 카테고리가 모두 정확하게 예측된 경우는 전체의 22.44%입니다.\n",
      "※ Category1은 중립을 포함하여 평가, Category2는 중립이 없어 일치합니다.\n"
     ]
    }
   ],
   "source": [
    "# 11. 파이프라인으로 test_data 평가 (두 카테고리 모두 맞은 경우만 정답 처리)\n",
    "\n",
    "print(\"🎯 파이프라인으로 test_data 종합 평가\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# test_data 준비\n",
    "test_texts = test_data['context'].fillna('').astype(str).tolist()\n",
    "test_true_cat1 = test_data['category1'].values\n",
    "test_true_cat2 = test_data['category2'].values\n",
    "\n",
    "print(f\"평가 데이터: {len(test_texts)}개\")\n",
    "print(f\"Category1 클래스 수: {len(np.unique(test_true_cat1))}\")\n",
    "print(f\"Category2 클래스 수: {len(np.unique(test_true_cat2))}\")\n",
    "\n",
    "# 중립 데이터 확인\n",
    "neutral_cat1_count = (test_true_cat1 == '중립').sum()\n",
    "neutral_cat2_count = (test_true_cat2 == '중립').sum()\n",
    "print(f\"테스트 데이터 중립: Category1={neutral_cat1_count}개, Category2={neutral_cat2_count}개\")\n",
    "\n",
    "# 파이프라인으로 종합 평가 실행 (모든 데이터 사용 - Category1에 중립 포함)\n",
    "print(f\"\\n🔄 파이프라인 평가 실행 중...\")\n",
    "print(f\"Category1: 중립 포함하여 평가\")\n",
    "print(f\"Category2: 중립 없음 (테스트 데이터에도 없음)\")\n",
    "\n",
    "evaluation_results = pipeline.evaluate_with_ground_truth(\n",
    "    test_texts, test_true_cat1, test_true_cat2\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"\\n📊 파이프라인 종합 평가 결과:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"전체 테스트 샘플 수: {evaluation_results['total_samples']}\")\n",
    "print(f\"\")\n",
    "print(f\"📈 개별 정확도:\")\n",
    "print(f\"  Category1 정확도: {evaluation_results['category1_accuracy']:.4f} ({evaluation_results['category1_correct_count']}/{evaluation_results['total_samples']})\")\n",
    "print(f\"  Category2 정확도: {evaluation_results['category2_accuracy']:.4f} ({evaluation_results['category2_correct_count']}/{evaluation_results['total_samples']})\")\n",
    "print(f\"\")\n",
    "print(f\"🎯 핵심 지표 - 두 카테고리 모두 정답:\")\n",
    "print(f\"  종합 정확도: {evaluation_results['both_correct_accuracy']:.4f} ({evaluation_results['both_correct_count']}/{evaluation_results['total_samples']})\")\n",
    "print(f\"  종합 정확도: {evaluation_results['both_correct_accuracy']*100:.2f}%\")\n",
    "\n",
    "# 상세 분석\n",
    "print(f\"\\n🔍 상세 분석:\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# 카테고리별 매치 패턴 분석\n",
    "both_correct = sum(1 for r in evaluation_results['detailed_results'] if r['both_correct'])\n",
    "only_cat1_correct = sum(1 for r in evaluation_results['detailed_results'] if r['cat1_match'] and not r['cat2_match'])\n",
    "only_cat2_correct = sum(1 for r in evaluation_results['detailed_results'] if not r['cat1_match'] and r['cat2_match'])\n",
    "both_wrong = sum(1 for r in evaluation_results['detailed_results'] if not r['cat1_match'] and not r['cat2_match'])\n",
    "\n",
    "print(f\"두 카테고리 모두 정답: {both_correct}개 ({both_correct/evaluation_results['total_samples']*100:.2f}%)\")\n",
    "print(f\"Category1만 정답: {only_cat1_correct}개 ({only_cat1_correct/evaluation_results['total_samples']*100:.2f}%)\")\n",
    "print(f\"Category2만 정답: {only_cat2_correct}개 ({only_cat2_correct/evaluation_results['total_samples']*100:.2f}%)\")\n",
    "print(f\"둘 다 틀림: {both_wrong}개 ({both_wrong/evaluation_results['total_samples']*100:.2f}%)\")\n",
    "\n",
    "# 샘플 출력 - 두 카테고리 모두 맞은 케이스\n",
    "print(f\"\\n✅ 두 카테고리 모두 정답인 샘플들 (처음 10개):\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "correct_samples = [r for r in evaluation_results['detailed_results'] if r['both_correct']]\n",
    "for i, result in enumerate(correct_samples[:10]):\n",
    "    text = result['text'][:60] + \"...\" if len(result['text']) > 60 else result['text']\n",
    "    print(f\"{i+1:2d}. Cat1: {result['actual_cat1']} ✓ | Cat2: {result['actual_cat2']} ✓\")\n",
    "    print(f\"    신뢰도: Cat1={result['cat1_confidence']:.3f}, Cat2={result['cat2_confidence']:.3f}\")\n",
    "    print(f\"    텍스트: {text}\")\n",
    "    print()\n",
    "\n",
    "# 샘플 출력 - 둘 다 틀린 케이스  \n",
    "print(f\"\\n❌ 두 카테고리 모두 틀린 샘플들 (처음 10개):\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "wrong_samples = [r for r in evaluation_results['detailed_results'] if not r['both_correct'] and not r['cat1_match'] and not r['cat2_match']]\n",
    "for i, result in enumerate(wrong_samples[:10]):\n",
    "    text = result['text'][:60] + \"...\" if len(result['text']) > 60 else result['text']\n",
    "    print(f\"{i+1:2d}. Cat1: {result['actual_cat1']} → {result['predicted_cat1']} | Cat2: {result['actual_cat2']} → {result['predicted_cat2']}\")\n",
    "    print(f\"    신뢰도: Cat1={result['cat1_confidence']:.3f}, Cat2={result['cat2_confidence']:.3f}\")\n",
    "    print(f\"    텍스트: {text}\")\n",
    "    print()\n",
    "\n",
    "# 중립 데이터 특별 분석\n",
    "print(f\"\\n⚖️ 중립 데이터 분석 (Category1):\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "neutral_results = [r for r in evaluation_results['detailed_results'] if r['actual_cat1'] == '중립']\n",
    "if len(neutral_results) > 0:\n",
    "    neutral_correct = sum(1 for r in neutral_results if r['cat1_match'])\n",
    "    print(f\"중립 데이터 총 {len(neutral_results)}개 중 {neutral_correct}개 정답 ({neutral_correct/len(neutral_results)*100:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n중립 샘플 예측 결과 (처음 5개):\")\n",
    "    for i, result in enumerate(neutral_results[:5]):\n",
    "        text = result['text'][:50] + \"...\" if len(result['text']) > 50 else result['text']\n",
    "        status = \"✅\" if result['cat1_match'] else \"❌\"\n",
    "        print(f\"{i+1}. {status} 예측: {result['predicted_cat1']} (신뢰도: {result['cat1_confidence']:.3f})\")\n",
    "        print(f\"   텍스트: {text}\")\n",
    "else:\n",
    "    print(\"테스트 데이터에 중립이 없습니다.\")\n",
    "\n",
    "print(f\"\\n🔥 결론:\")\n",
    "print(f\"이 파이프라인에서 두 카테고리가 모두 정확하게 예측된 경우는 전체의 {evaluation_results['both_correct_accuracy']*100:.2f}%입니다.\")\n",
    "print(f\"※ Category1은 중립을 포함하여 평가, Category2는 중립이 없어 일치합니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "623b7374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 파이프라인 예측 시연\n",
      "================================================================================\n",
      "\n",
      "📝 예제 1: 친구가 생일 파티를 준비해줘서 너무 감동받았어\n",
      "------------------------------------------------------------\n",
      "🎯 예측 결과:\n",
      "  Category1: 기쁨 (신뢰도: 0.994)\n",
      "  Category2: 고마움 (신뢰도: 0.495)\n",
      "\n",
      "📝 예제 2: 시험 결과가 나쁘게 나와서 정말 실망스럽다\n",
      "------------------------------------------------------------\n",
      "🎯 예측 결과:\n",
      "  Category1: 슬픔 (신뢰도: 0.584)\n",
      "  Category2: 실망 (신뢰도: 0.804)\n",
      "\n",
      "📝 예제 3: 새로운 직장이 확정되어서 설레고 기대된다\n",
      "------------------------------------------------------------\n",
      "🎯 예측 결과:\n",
      "  Category1: 기쁨 (신뢰도: 0.983)\n",
      "  Category2: 기대감 (신뢰도: 0.978)\n",
      "\n",
      "📝 예제 4: 누군가 내 뒷담화를 하는 걸 들어서 화가 난다\n",
      "------------------------------------------------------------\n",
      "🎯 예측 결과:\n",
      "  Category1: 분노 (신뢰도: 0.578)\n",
      "  Category2: 불쾌 (신뢰도: 0.826)\n"
     ]
    }
   ],
   "source": [
    "# 12. 새로운 텍스트 예측 데모 함수\n",
    "\n",
    "def demo_pipeline_prediction():\n",
    "    \"\"\"\n",
    "    새로운 텍스트들에 대해 파이프라인 예측 시연\n",
    "    \"\"\"\n",
    "    print(\"🚀 파이프라인 예측 시연\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # 예제 텍스트들\n",
    "    demo_texts = [\n",
    "        \"친구가 생일 파티를 준비해줘서 너무 감동받았어\",\n",
    "        \"시험 결과가 나쁘게 나와서 정말 실망스럽다\", \n",
    "        \"새로운 직장이 확정되어서 설레고 기대된다\",\n",
    "        \"누군가 내 뒷담화를 하는 걸 들어서 화가 난다\"\n",
    "    ]\n",
    "    \n",
    "    for i, text in enumerate(demo_texts, 1):\n",
    "        print(f\"\\n📝 예제 {i}: {text}\")\n",
    "        print(\"-\"*60)\n",
    "        \n",
    "        # 파이프라인으로 예측\n",
    "        result = pipeline.predict_single(text)\n",
    "        \n",
    "        print(f\"🎯 예측 결과:\")\n",
    "        print(f\"  Category1: {result['category1_predicted']} (신뢰도: {result['category1_confidence']:.3f})\")\n",
    "        print(f\"  Category2: {result['category2_predicted']} (신뢰도: {result['category2_confidence']:.3f})\")\n",
    "\n",
    "# 시연 실행\n",
    "demo_pipeline_prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "i821u6i92xl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 PCA 차원 축소 파이프라인 평가\n",
      "================================================================================\n",
      "원본 벡터 차원: 1024\n",
      "평가할 PCA 차원: [128, 256, 512, 768]\n",
      "훈련 데이터: 3359개, 테스트 데이터: 664개\n",
      "\n",
      "\n",
      "==================== PCA 128차원 평가 ====================\n",
      "📐 PCA 128차원으로 축소 중...\n",
      "  훈련 데이터: (3359, 1024) → (3359, 128)\n",
      "  테스트 데이터: (664, 1024) → (664, 128)\n",
      "  설명 가능한 분산 비율: 0.8185 (81.85%)\n",
      "🤖 Category1 모델 훈련 중...\n",
      "  Category1 정확도: 0.5015 (50.15%)\n",
      "🤖 Category2 모델 훈련 중...\n",
      "  Category2 정확도: 0.2485 (24.85%)\n",
      "  🎯 두 카테고리 모두 정답: 152/664 (0.2289, 22.89%)\n",
      "\n",
      "==================== PCA 256차원 평가 ====================\n",
      "📐 PCA 256차원으로 축소 중...\n",
      "  훈련 데이터: (3359, 1024) → (3359, 256)\n",
      "  테스트 데이터: (664, 1024) → (664, 256)\n",
      "  설명 가능한 분산 비율: 0.9409 (94.09%)\n",
      "🤖 Category1 모델 훈련 중...\n",
      "  Category1 정확도: 0.4880 (48.80%)\n",
      "🤖 Category2 모델 훈련 중...\n",
      "  Category2 정확도: 0.2199 (21.99%)\n",
      "  🎯 두 카테고리 모두 정답: 133/664 (0.2003, 20.03%)\n",
      "\n",
      "==================== PCA 512차원 평가 ====================\n",
      "📐 PCA 512차원으로 축소 중...\n",
      "  훈련 데이터: (3359, 1024) → (3359, 512)\n",
      "  테스트 데이터: (664, 1024) → (664, 512)\n",
      "  설명 가능한 분산 비율: 0.9961 (99.61%)\n",
      "🤖 Category1 모델 훈련 중...\n",
      "  Category1 정확도: 0.4880 (48.80%)\n",
      "🤖 Category2 모델 훈련 중...\n",
      "  Category2 정확도: 0.2139 (21.39%)\n",
      "  🎯 두 카테고리 모두 정답: 130/664 (0.1958, 19.58%)\n",
      "\n",
      "==================== PCA 768차원 평가 ====================\n",
      "📐 PCA 768차원으로 축소 중...\n",
      "  훈련 데이터: (3359, 1024) → (3359, 768)\n",
      "  테스트 데이터: (664, 1024) → (664, 768)\n",
      "  설명 가능한 분산 비율: 0.9994 (99.94%)\n",
      "🤖 Category1 모델 훈련 중...\n",
      "  Category1 정확도: 0.4895 (48.95%)\n",
      "🤖 Category2 모델 훈련 중...\n",
      "  Category2 정확도: 0.2184 (21.84%)\n",
      "  🎯 두 카테고리 모두 정답: 134/664 (0.2018, 20.18%)\n",
      "\n",
      "========================= 결과 비교 분석 =========================\n",
      "PCA 차원     분산비율         Cat1 정확도     Cat2 정확도     종합 정확도      \n",
      "----------------------------------------------------------------------\n",
      "원본         100.00%      0.4880       0.2425       0.2244      \n",
      "128        81.85      % 0.5015       0.2485       0.2289      \n",
      "256        94.09      % 0.4880       0.2199       0.2003      \n",
      "512        99.61      % 0.4880       0.2139       0.1958      \n",
      "768        99.94      % 0.4895       0.2184       0.2018      \n",
      "\n",
      "🏆 성능 분석:\n",
      "  원본 (1024차원) 종합 정확도: 0.2244 (22.44%)\n",
      "  최고 PCA (128차원) 종합 정확도: 0.2289 (22.89%)\n",
      "  ✅ PCA 128차원이 원본보다 0.45%p 더 좋습니다!\n",
      "\n",
      "📊 차원별 성능 변화:\n",
      "PCA 차원  → 종합 정확도\n",
      "-------------------------\n",
      "128차원   → 0.229 |███████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░|\n",
      "256차원   → 0.200 |██████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░|\n",
      "512차원   → 0.196 |█████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░|\n",
      "768차원   → 0.202 |██████████░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░|\n",
      "\n",
      "🔍 최고 성능 PCA 128차원 상세 분석:\n",
      "--------------------------------------------------------------------------------\n",
      "처음 20개 샘플에서 원본과 PCA 예측 일치율: 17/20 (85.0%)\n",
      "\n",
      "원본 vs PCA 예측이 다른 샘플들 (처음 5개):\n",
      "1. 원본: ❌ | PCA: ✅\n",
      "   실제: Cat1=기쁨, Cat2=만족감\n",
      "   텍스트: 어릴 때 가 보고 빕스는 거의 처음인데(기억에 없음) 지금 딸기축제 기간이라 만족스러운 식사 하고 옴\n",
      "2. 원본: ❌ | PCA: ✅\n",
      "   실제: Cat1=싫어함(상태), Cat2=답답함\n",
      "   텍스트: 가슴이 답답해짐 진짜 개답답해짐\n",
      "우리진짜투표잘하자\n",
      "3. 원본: ✅ | PCA: ❌\n",
      "   실제: Cat1=기쁨, Cat2=만족감\n",
      "   텍스트: 우연히 보게 된 영상인데, 노래가 너무 좋아서 플리에도 추가하고, 카카오톡 프뮤로도 해놨음. 음원도 좋긴 한...\n",
      "\n",
      "💡 결론: PCA를 통한 차원 축소는 \n",
      "성능 향상에 도움이 됩니다. 계산 효율성과 성능을 모두 개선할 수 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# 13. PCA 차원 축소 파이프라인 - 두 카테고리 모두 정답 정확도 비교\n",
    "\n",
    "print(\"🔍 PCA 차원 축소 파이프라인 평가\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# PCA 차원 리스트 정의\n",
    "pca_dimensions = [128, 256, 512, 768]\n",
    "\n",
    "# 결과 저장용 딕셔너리\n",
    "pca_results = {}\n",
    "\n",
    "# 원본 벡터 크기 확인\n",
    "original_dim = X.shape[1]\n",
    "print(f\"원본 벡터 차원: {original_dim}\")\n",
    "print(f\"평가할 PCA 차원: {pca_dimensions}\")\n",
    "print(f\"훈련 데이터: {X.shape[0]}개, 테스트 데이터: {len(test_texts)}개\")\n",
    "print()\n",
    "\n",
    "# 각 PCA 차원에 대해 평가\n",
    "for n_components in pca_dimensions:\n",
    "    print(f\"\\n{'='*20} PCA {n_components}차원 평가 {'='*20}\")\n",
    "    \n",
    "    # 1. PCA 적용\n",
    "    print(f\"📐 PCA {n_components}차원으로 축소 중...\")\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    \n",
    "    # 훈련 데이터 PCA 변환\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    print(f\"  훈련 데이터: {X.shape} → {X_pca.shape}\")\n",
    "    \n",
    "    # 테스트 데이터 PCA 변환\n",
    "    test_X_pca = pca.transform(test_X)\n",
    "    print(f\"  테스트 데이터: {test_X.shape} → {test_X_pca.shape}\")\n",
    "    \n",
    "    # 설명 가능한 분산 비율\n",
    "    explained_variance = pca.explained_variance_ratio_.sum()\n",
    "    print(f\"  설명 가능한 분산 비율: {explained_variance:.4f} ({explained_variance*100:.2f}%)\")\n",
    "    \n",
    "    # 2. Category1 모델 훈련 (PCA 적용)\n",
    "    print(f\"🤖 Category1 모델 훈련 중...\")\n",
    "    cat1_model_pca = xgb.XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cat1_model_pca.fit(X_pca, y_encoded)\n",
    "    \n",
    "    # Category1 예측\n",
    "    test_y_pred_cat1_pca_encoded = cat1_model_pca.predict(test_X_pca)\n",
    "    test_y_pred_cat1_pca = le.inverse_transform(test_y_pred_cat1_pca_encoded)\n",
    "    \n",
    "    # Category1 정확도\n",
    "    cat1_accuracy_pca = (test_y_pred_cat1_pca == test_y_actual).mean()\n",
    "    print(f\"  Category1 정확도: {cat1_accuracy_pca:.4f} ({cat1_accuracy_pca*100:.2f}%)\")\n",
    "    \n",
    "    # 3. Category2 모델 훈련 (PCA 적용)\n",
    "    print(f\"🤖 Category2 모델 훈련 중...\")\n",
    "    \n",
    "    # Category1 원핫 인코딩 (PCA 적용된 예측값 사용)\n",
    "    cat1_onehot_pca = cat1_encoder.transform(test_y_pred_cat1_pca.reshape(-1, 1))\n",
    "    \n",
    "    # PCA 적용된 벡터와 Category1 원핫 결합 (훈련용)\n",
    "    y_cat1_onehot_pca = cat1_encoder.transform(y.reshape(-1, 1))\n",
    "    X_combined_pca = np.hstack([X_pca, y_cat1_onehot_pca])\n",
    "    \n",
    "    # PCA 적용된 벡터와 Category1 예측 원핫 결합 (테스트용)\n",
    "    test_X_combined_pca = np.hstack([test_X_pca, cat1_onehot_pca])\n",
    "    \n",
    "    cat2_model_pca = xgb.XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=8,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=42,\n",
    "        tree_method=\"hist\",\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    cat2_model_pca.fit(X_combined_pca, y_cat2_encoded)\n",
    "    \n",
    "    # Category2 예측\n",
    "    test_y_pred_cat2_pca_encoded = cat2_model_pca.predict(test_X_combined_pca)\n",
    "    test_y_pred_cat2_pca = le_cat2.inverse_transform(test_y_pred_cat2_pca_encoded)\n",
    "    \n",
    "    # Category2 정확도\n",
    "    cat2_accuracy_pca = (test_y_pred_cat2_pca == test_y_actual_cat2).mean()\n",
    "    print(f\"  Category2 정확도: {cat2_accuracy_pca:.4f} ({cat2_accuracy_pca*100:.2f}%)\")\n",
    "    \n",
    "    # 4. 두 카테고리 모두 정답인 경우 계산\n",
    "    both_correct_pca = (test_y_pred_cat1_pca == test_y_actual) & (test_y_pred_cat2_pca == test_y_actual_cat2)\n",
    "    both_accuracy_pca = both_correct_pca.mean()\n",
    "    both_count_pca = both_correct_pca.sum()\n",
    "    \n",
    "    print(f\"  🎯 두 카테고리 모두 정답: {both_count_pca}/{len(test_y_actual)} ({both_accuracy_pca:.4f}, {both_accuracy_pca*100:.2f}%)\")\n",
    "    \n",
    "    # 결과 저장\n",
    "    pca_results[n_components] = {\n",
    "        'explained_variance': explained_variance,\n",
    "        'cat1_accuracy': cat1_accuracy_pca,\n",
    "        'cat2_accuracy': cat2_accuracy_pca,\n",
    "        'both_accuracy': both_accuracy_pca,\n",
    "        'both_count': both_count_pca,\n",
    "        'cat1_predictions': test_y_pred_cat1_pca,\n",
    "        'cat2_predictions': test_y_pred_cat2_pca\n",
    "    }\n",
    "\n",
    "# 5. 전체 결과 비교 분석\n",
    "print(f\"\\n{'='*25} 결과 비교 분석 {'='*25}\")\n",
    "print(f\"{'PCA 차원':<10} {'분산비율':<12} {'Cat1 정확도':<12} {'Cat2 정확도':<12} {'종합 정확도':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "# 원본 결과 (PCA 없음) 계산\n",
    "original_both_correct = (test_y_pred == test_y_actual) & (test_y_pred_cat2 == test_y_actual_cat2)\n",
    "original_both_accuracy = original_both_correct.mean()\n",
    "\n",
    "print(f\"{'원본':<10} {'100.00%':<12} {accuracy:<12.4f} {accuracy_cat2:<12.4f} {original_both_accuracy:<12.4f}\")\n",
    "\n",
    "# PCA 결과들\n",
    "for dim in pca_dimensions:\n",
    "    result = pca_results[dim]\n",
    "    print(f\"{dim:<10} {result['explained_variance']*100:<11.2f}% {result['cat1_accuracy']:<12.4f} {result['cat2_accuracy']:<12.4f} {result['both_accuracy']:<12.4f}\")\n",
    "\n",
    "# 6. 최고 성능 차원 찾기\n",
    "print(f\"\\n🏆 성능 분석:\")\n",
    "best_both_accuracy = max(result['both_accuracy'] for result in pca_results.values())\n",
    "best_pca_dim = max(pca_results.keys(), key=lambda k: pca_results[k]['both_accuracy'])\n",
    "\n",
    "print(f\"  원본 (1024차원) 종합 정확도: {original_both_accuracy:.4f} ({original_both_accuracy*100:.2f}%)\")\n",
    "print(f\"  최고 PCA ({best_pca_dim}차원) 종합 정확도: {best_both_accuracy:.4f} ({best_both_accuracy*100:.2f}%)\")\n",
    "\n",
    "if best_both_accuracy > original_both_accuracy:\n",
    "    improvement = (best_both_accuracy - original_both_accuracy) * 100\n",
    "    print(f\"  ✅ PCA {best_pca_dim}차원이 원본보다 {improvement:.2f}%p 더 좋습니다!\")\n",
    "else:\n",
    "    decline = (original_both_accuracy - best_both_accuracy) * 100\n",
    "    print(f\"  ⚠️ 원본이 최고 PCA보다 {decline:.2f}%p 더 좋습니다.\")\n",
    "\n",
    "# 7. 차원별 성능 변화 시각화 (텍스트)\n",
    "print(f\"\\n📊 차원별 성능 변화:\")\n",
    "print(f\"PCA 차원  → 종합 정확도\")\n",
    "print(\"-\" * 25)\n",
    "for dim in sorted(pca_dimensions):\n",
    "    result = pca_results[dim]\n",
    "    bar_length = int(result['both_accuracy'] * 50)  # 50칸 기준\n",
    "    bar = \"█\" * bar_length + \"░\" * (50 - bar_length)\n",
    "    print(f\"{dim:>3}차원   → {result['both_accuracy']:.3f} |{bar}|\")\n",
    "\n",
    "# 8. 상세 샘플 분석 (최고 성능 PCA 차원)\n",
    "print(f\"\\n🔍 최고 성능 PCA {best_pca_dim}차원 상세 분석:\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "best_cat1_preds = pca_results[best_pca_dim]['cat1_predictions']\n",
    "best_cat2_preds = pca_results[best_pca_dim]['cat2_predictions']\n",
    "\n",
    "# 원본 vs PCA 예측 비교\n",
    "agreement_count = 0\n",
    "disagreement_examples = []\n",
    "\n",
    "for i in range(min(len(test_y_actual), 20)):  # 처음 20개 샘플만\n",
    "    original_both = (test_y_pred[i] == test_y_actual[i]) and (test_y_pred_cat2[i] == test_y_actual_cat2[i])\n",
    "    pca_both = (best_cat1_preds[i] == test_y_actual[i]) and (best_cat2_preds[i] == test_y_actual_cat2[i])\n",
    "    \n",
    "    if original_both == pca_both:\n",
    "        agreement_count += 1\n",
    "    else:\n",
    "        disagreement_examples.append({\n",
    "            'index': i,\n",
    "            'text': test_texts[i][:60] + \"...\" if len(test_texts[i]) > 60 else test_texts[i],\n",
    "            'actual_cat1': test_y_actual[i],\n",
    "            'actual_cat2': test_y_actual_cat2[i],\n",
    "            'original_both': original_both,\n",
    "            'pca_both': pca_both\n",
    "        })\n",
    "\n",
    "print(f\"처음 20개 샘플에서 원본과 PCA 예측 일치율: {agreement_count}/20 ({agreement_count/20*100:.1f}%)\")\n",
    "\n",
    "if disagreement_examples:\n",
    "    print(f\"\\n원본 vs PCA 예측이 다른 샘플들 (처음 5개):\")\n",
    "    for i, example in enumerate(disagreement_examples[:5]):\n",
    "        status_original = \"✅\" if example['original_both'] else \"❌\"\n",
    "        status_pca = \"✅\" if example['pca_both'] else \"❌\"\n",
    "        print(f\"{i+1}. 원본: {status_original} | PCA: {status_pca}\")\n",
    "        print(f\"   실제: Cat1={example['actual_cat1']}, Cat2={example['actual_cat2']}\")\n",
    "        print(f\"   텍스트: {example['text']}\")\n",
    "\n",
    "print(f\"\\n💡 결론: PCA를 통한 차원 축소는 \")\n",
    "if best_both_accuracy > original_both_accuracy:\n",
    "    print(\"성능 향상에 도움이 됩니다. 계산 효율성과 성능을 모두 개선할 수 있습니다.\")\n",
    "else:\n",
    "    print(\"성능을 약간 저하시키지만, 계산 효율성은 크게 개선됩니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49681c8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3861528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skn_after_study",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
